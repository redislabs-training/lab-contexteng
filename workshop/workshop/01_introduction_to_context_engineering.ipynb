{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Redis](https://redis.io/wp-content/uploads/2024/04/Logotype.svg?auto=webp&quality=85,75&width=120)\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/redislabs-training/ce-redis-langchain/blob/main/section-1-context-engineering-foundations/01_Introduction_to_context_engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "# What Is Context Engineering?\n",
    "\n",
    "## The Problem\n",
    "\n",
    "Imagine you walk into a doctor's office. The doctor has never met you before, doesn't have access to your medical records, and can't remember anything you said five minutes ago. Every time you visit, it's like the first time all over again.\n",
    "\n",
    "Sound frustrating? That's what AI agents are like without context engineering.\n",
    "\n",
    "\n",
    "**Context engineering** is the discipline of designing, shaping, and delivering the right information to an AI model, via prompts, retrieval, memory, schemas, system instructions, grounding data, and constraints, so the model behaves predictably, accurately, and safely.\n",
    "\n",
    "\n",
    "**The quality of an AI system‚Äôs output is directly determined by the quality, completeness, and structure of the information (context) you give it**. \n",
    "\n",
    "- As models become more capable\n",
    "- The competitive differentiator shifts from the model itself to \n",
    "- how well you can control and feed it the right information at the right time\n",
    "\n",
    "**Context engineering matters because it:**\n",
    "\n",
    "1. Gives AI the information it needs to be accurate\n",
    "2. Specializes general models for your domain\n",
    "3. Reduces hallucinations\n",
    "4. Ensures consistency and reliability\n",
    "5. Enables complex AI applications\n",
    "6. Reduces cost and increases efficiency\n",
    "7. Enforces safety and governance\n",
    "\n",
    "---\n",
    "Visually, context can contain something like this:\n",
    "\n",
    "![Context engineering overview](../public/ce-overview.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context Engineering in Action\n",
    "\n",
    "Lets explore this through a common scenario we want the agent to deal with: \n",
    "- A student seeking advice on what classes to take to help build a career in AI. \n",
    "\n",
    "We'll use a sample student profile as our base in the LLM's context: \n",
    "\n",
    "- **Name**: Olivia Jansen\n",
    "- **Major**: Computer Science\n",
    "- **Year**: Sophomore\n",
    "- **Completed**: Intro to Programming (CS101), Data Structures (CS201), Calculus I\n",
    "- **Interests**: Machine learning, Data science\n",
    "- **Preferences**: Prefers online courses, learns best with hands-on projects\n",
    "- **Goal**: Build a career in AI\n",
    "\n",
    "Olivia goes ahead and interacts with the agent and has the following results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>üî∂ Click the dropdown to review the conversation with the agent</summary>\n",
    "  \n",
    "**Turn 1:**\n",
    "\n",
    "*Student:* \"I'm interested in machine learning courses\"\n",
    "\n",
    "*Agent:* \"Here are all machine learning courses available:\n",
    "- CS301: Introduction to Machine Learning\n",
    "- CS401: Advanced Machine Learning\n",
    "- CS402: Deep Learning\n",
    "- CS403: Natural Language Processing\n",
    "- CS404: Computer Vision\n",
    "\n",
    "All courses meet twice per week on campus.\"\n",
    "\n",
    "---\n",
    "\n",
    "**Turn 2:**\n",
    "\n",
    "*Student:* \"I prefer online courses.\"\n",
    "\n",
    "*Agent:* \"Here are all machine learning courses available:\n",
    "- CS301: Introduction to Machine Learning\n",
    "- CS401: Advanced Machine Learning\n",
    "...\"\n",
    "\n",
    "Notice that the result is the same list, ignoring Olivia's preferences.\n",
    "\n",
    "---\n",
    "\n",
    "**Turn 3:**\n",
    "\n",
    "*Student:* \"Can I take CS401?\"\n",
    "\n",
    "*Agent:* \"CS401 requires CS301 as a prerequisite. Do you meet this requirement?\"\n",
    "\n",
    "The agent does not respond adequately as it doesn't know what courses the student has completed\n",
    "\n",
    "---\n",
    "\n",
    "**Turn 4:**\n",
    "\n",
    "*Student:* \"What about that intro course you mentioned earlier?\"\n",
    "\n",
    "*Agent:* \"I'm not sure which course you're referring to. Could you provide more details?\"\n",
    "\n",
    "The agent does not remember its old replies and has no context on what intro course was mentioned. \n",
    "\n",
    "---\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Problems Are Clear\n",
    "\n",
    "**No Memory:**\n",
    "- Can't remember what it just said\n",
    "- Can't reference earlier parts of the conversation\n",
    "- Forces the user to repeat information\n",
    "\n",
    "**No Personalization:**\n",
    "- Ignores user preferences and background\n",
    "- Gives generic responses regardless of the user's situation\n",
    "- Can't tailor recommendations\n",
    "\n",
    "**No Awareness:**\n",
    "- Doesn't know the user's history or capabilities\n",
    "- Can't check prerequisites or eligibility\n",
    "- Can't connect to other relevant information\n",
    "\n",
    "**Result:** A frustrating experience that wastes time and provides little value.\n",
    "\n",
    "## With Context Engineering\n",
    "\n",
    "Now, let's examine the agent, but with proper context management: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>üî∂ Click the dropdown to review the conversation with the agent with proper context management </summary>\n",
    "\n",
    "**Turn 1:**\n",
    "\n",
    "*Student:* \"I'm interested in machine learning courses.\"\n",
    "\n",
    "*Agent:* \"Great! Based on your Computer Science major and the courses you've completed (CS101 and CS201), you're ready for CS301: Introduction to Machine Learning.\n",
    "\n",
    "Since you prefer online courses and hands-on learning, I should mention that CS301 has:\n",
    "- A fully online section is available\n",
    "- Weekly programming assignments with real datasets\n",
    "- A final project where you build your own ML system\n",
    "\n",
    "This course aligns perfectly with your goal of building an AI career and serves as the foundation for more advanced ML courses.\"\n",
    "\n",
    "---\n",
    "\n",
    "**Turn 2:**\n",
    "\n",
    "*Student:* \"That sounds perfect! What comes after that?\"\n",
    "\n",
    "*Agent:* \"After completing CS301, you'll have several great options:\n",
    "\n",
    "**Immediately Available:**\n",
    "- CS402: Deep Learning (Online, project-based)\n",
    "  Focus: Neural networks, CNNs, RNNs\n",
    "  \n",
    "- CS403: Natural Language Processing (Online, project-based)\n",
    "  Focus: Text analysis, transformers, LLMs\n",
    "\n",
    "**Recommended Path for AI Career:**\n",
    "1. CS301 (Introduction) ‚Üê Start here\n",
    "2. CS402 (Deep Learning) ‚Üê Most relevant to modern AI\n",
    "3. CS403 (NLP) or CS404 (Computer Vision) ‚Üê Specialize\n",
    "\n",
    "Given your interest in data science, I'd especially recommend the NLP path - it combines well with your data structures background.\"\n",
    "\n",
    "---\n",
    "\n",
    "**Turn 3:**\n",
    "\n",
    "*Student:* \"How long will that path take?\"\n",
    "\n",
    "*Agent:* \"Let me break it down for you:\n",
    "\n",
    "**CS301:** 14 weeks (3 credits)\n",
    "**CS402:** 14 weeks (3 credits)  \n",
    "**CS403:** 14 weeks (3 credits)\n",
    "\n",
    "If you take one course per semester:\n",
    "- Fall 2024: CS301\n",
    "- Spring 2025: CS402\n",
    "- Fall 2025: CS403\n",
    "\n",
    "Since you're currently a Junior, this timeline would have you completing this sequence before graduation, with one semester remaining for an internship or capstone project.\n",
    "\n",
    "Alternatively, since these are online courses, you could potentially take CS301 this fall and CS402 in a winter intersession to accelerate your path.\"\n",
    "\n",
    "---\n",
    "\n",
    "**Turn 4:**\n",
    "\n",
    "*Student:* \"I like that accelerated option. Can I register now?\"\n",
    "\n",
    "*Agent:* \"Yes! Since you've met the prerequisites for CS301, I can guide you through registration. The online section (CS301-W01) has 15 seats remaining.\n",
    "\n",
    "Would you like me to:\n",
    "1. Reserve a seat for you in CS301-W01 for Fall 2024?\n",
    "2. Add you to the notification list for the Winter CS402 section (registration opens in October)?\n",
    "3. Send you the course syllabus and professor information?\"\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With context engineering:**\n",
    "\n",
    "- it remembers who the student is (major, completions, preferences)\n",
    "- filters to relevant options (online, project-based ML)\n",
    "- checks prerequisites automatically,\n",
    "- turns choices into a sequenced plan and timeline\n",
    "- can even propose recommended actions (register, notify, send syllabi).\n",
    "\n",
    "**Result:** The result is a fast, personalized, high-confidence experience that actually delivers value.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a complete context: the four pillars\n",
    "\n",
    "We can breakdown the context that goes into an AI application into four distinct types: \n",
    "\n",
    "1. System context\n",
    "2. User context\n",
    "3. Conversation context\n",
    "4. Retrieved context \n",
    "\n",
    "Each of these types plays a crucial role in making sure that an AI system has what it needs to properly respond. In this section, we'll explore each context type in more detail and setup a sample context to call a LLM (OpenAI). As you go through, make sure to run each code block that is provided as we build up the context and send it to a LLM at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. System Context: \"What Am I?\"\n",
    "\n",
    "The system context defines the AI's identity, capabilities, and knowledge. It is static, universal, and always present.\n",
    "\n",
    "It typically contains: \n",
    "- A role definition (\"You are a course advisor\")\n",
    "- Available tools and actions (`search_courses(query)`)\n",
    "- Domain knowledge and business rules (\"CS401 requires CS301\")\n",
    "- Behavioral guidelines (\"Ask one clarifying question at a time\")\n",
    "\n",
    "Below is an example of system context (also commonly called the system prompt) for our Redis University agent. Run the codeblock to create the context. We'll use it shortly when we assemble the full context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T23:08:05.910676Z",
     "start_time": "2025-12-03T23:08:05.908025Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System context created successfully!\n",
      "You are a Redis University course advisor.\n",
      "\n",
      "Guidelines:\n",
      "1. Always provide specific course recommendations with clear reasoning\n",
      "2. Consider the student's background, completed courses, and interests\n",
      "3. Ensure prerequisites are met before recommending advanced courses\n",
      "4. Be encouraging and supportive in your guidance\n",
      "5. Do not offer courses that are not part of the curriculum\n",
      "\n"
     ]
    }
   ],
   "source": [
    "system_context = \"\"\"You are a Redis University course advisor.\n",
    "\n",
    "Guidelines:\n",
    "1. Always provide specific course recommendations with clear reasoning\n",
    "2. Consider the student's background, completed courses, and interests\n",
    "3. Ensure prerequisites are met before recommending advanced courses\n",
    "4. Be encouraging and supportive in your guidance\n",
    "5. Do not offer courses that are not part of the curriculum\n",
    "\"\"\"\n",
    "\n",
    "print(\"System context created successfully!\")\n",
    "print(system_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. User Context: \"Who Are You?\"\n",
    "\n",
    "The user context contains personal information about the specific user. It is typically dynamic, personalized, and retrieved from storage.\n",
    "\n",
    "**Retrieval Methods:**\n",
    "- **Direct lookup** - Fetch user profile by user ID (structured data like name, major, year)\n",
    "- **Search (RAG)** - Find relevant user facts using semantic search over long-term memories (Module 4)\n",
    "\n",
    "It typically contains:\n",
    "- Profile information (major, year, background)\n",
    "- Preferences and learning style (\"prefers online/asynchronous\")\n",
    "- History and achievements (\"completed CS101/CS201/Calc I\")\n",
    "- Goals and constraints (\"Tue/Thu availability\")\n",
    "- Long-term memories (facts learned about the user over time)\n",
    "\n",
    "We have already seen an example of user context when we defined the user profile and preferences for Olivia earlier. Run the code block below to create the sample profile in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T23:08:10.248769Z",
     "start_time": "2025-12-03T23:08:10.246634Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User context for Olivia created successfully!\n",
      "{'name': 'Olivia Jansen', 'background': 'Python developer, 2 years experience', 'completed_courses': ['RU101'], 'interests': ['machine learning', 'data science', 'vector search'], 'time_availability': 'evenings and weekends', 'goal': \"Build a RAG system for my company's documentation\"}\n"
     ]
    }
   ],
   "source": [
    "olivia_profile = {\n",
    "    \"name\": \"Olivia Jansen\",\n",
    "    \"background\": \"Python developer, 2 years experience\",\n",
    "    \"completed_courses\": [\"RU101\"],\n",
    "    \"interests\": [\"machine learning\", \"data science\", \"vector search\"],\n",
    "    \"time_availability\": \"evenings and weekends\",\n",
    "    \"goal\": \"Build a RAG system for my company's documentation\",\n",
    "}\n",
    "\n",
    "print(\"User context for Olivia created successfully!\")\n",
    "print(olivia_profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in production, the above context would likely come from a database, but we have hardcoded it above for demonstration purposes. \n",
    "\n",
    "LLM API's usually require message content to be a string, so we need to convert our dictionary to text. We have two options:\n",
    "\n",
    "1. Send it as JSON string: `json.dumps(olivia_profile)`\n",
    "2. Format it as natural language: Use a formatting function for better readability and control\n",
    "\n",
    "We'll use option 2 because it's more readable and gives us precise control over how the information is presented to the LLM. This type of data transformation ‚Äî converting structured data into LLM-friendly formats ‚Äî is actually a core context engineering technique that we'll explore in further detail throughout this course.\n",
    "\n",
    "Now, run the code block below to create the function and format Olivia's profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T23:08:16.139331Z",
     "start_time": "2025-12-03T23:08:16.133495Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted Context: Student Profile:\n",
      "    - Name: Olivia Jansen\n",
      "    - Background: Python developer, 2 years experience\n",
      "    - Completed Courses: RU101\n",
      "    - Interests: machine learning, data science, vector search\n",
      "    - Availability: evenings and weekends\n",
      "    - Goal: Build a RAG system for my company's documentation\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "def format_user_context(profile):\n",
    "    \"\"\"Convert user profile dictionary to formatted context string\"\"\"\n",
    "    return f\"\"\"Student Profile:\n",
    "    - Name: {profile['name']}\n",
    "    - Background: {profile['background']}\n",
    "    - Completed Courses: {', '.join(profile['completed_courses'])}\n",
    "    - Interests: {', '.join(profile['interests'])}\n",
    "    - Availability: {profile['time_availability']}\n",
    "    - Goal: {profile['goal']}\n",
    "    \"\"\"\n",
    "\n",
    "user_context = format_user_context(olivia_profile)\n",
    "print(\"Formatted Context:\", user_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Conversation Context: \"What Have We Discussed?\"\n",
    "\n",
    "Conversation context is one of the most important parts of context since it represents the history of the current conversation. Typically this is implemented in the form of memory. It is dynamic, session-specific, and will grow over time.\n",
    "\n",
    "**Retrieval Methods:**\n",
    "- **Direct lookup** - Fetch all messages by session ID (working memory - Module 4)\n",
    "- **Search (RAG)** - Find relevant past exchanges using semantic search over conversation history (advanced)\n",
    "\n",
    "It typically contains:\n",
    "- Previous user messages\n",
    "- Previous AI responses\n",
    "- Decisions and commitments made\n",
    "- Topics explored\n",
    "\n",
    "We have also seen an example of conversation context earlier:\n",
    "```\n",
    "Turn 1:\n",
    "User: \"I'm interested in machine learning courses.\"\n",
    "AI: \"I recommend CS301: Introduction to Machine Learning...\"\n",
    "\n",
    "Turn 2:\n",
    "User: \"What comes after that course?\"\n",
    "[Current query - needs context from Turn 1 to understand \"that course\"]\n",
    "AI: \"After CS301, you can take CS402 or CS403...\"\n",
    "\n",
    "Turn 3:\n",
    "User: \"How long will that path take?\"\n",
    "[Current query - needs context from Turn 2 to understand \"that path\"]\n",
    "```\n",
    "\n",
    "In this notebook, since we don't have a chat interface, we're going to simulate conversation history by manually creating a list of message dictionaries. In a real application, this list would be dynamically built as users interact with the system, but here we'll pre-populate it to demonstrate how conversation context works.\n",
    "\n",
    "Examine and then run the following codeblock (it will execute silently as we will observe it in the next codeblock):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T23:21:49.954592Z",
     "start_time": "2025-12-03T23:21:49.950979Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 1: Start with an empty conversation history\n",
    "conversation_history = []\n",
    "\n",
    "# Step 2: Add the first user message\n",
    "conversation_history.append(\n",
    "    {\"role\": \"user\", \"content\": \"What Redis course should I take next?\"}\n",
    ")\n",
    "\n",
    "# Step 3: Add the AI's response (simulated)\n",
    "conversation_history.append(\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"\"\"Based on your Python background and completion of RU101, \n",
    "I recommend RU201: Redis for Python Developers. This course will teach you \n",
    "how to build Redis applications using redis-py, which aligns perfectly with \n",
    "your goal of building a RAG system.\"\"\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Step 4: Add a follow-up question that references previous context\n",
    "conversation_history.append(\n",
    "    {\"role\": \"user\", \"content\": \"How long will that take me to complete?\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the user said \"that\" instead of \"RU201\". The AI needs the conversation history to understand what \"that\" refers to. Let's view the complete conversation history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T23:21:50.596947Z",
     "start_time": "2025-12-03T23:21:50.595242Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn 1 (user):\n",
      "What Redis course should I take next?\n",
      "\n",
      "Turn 2 (assistant):\n",
      "Based on your Python background and completion of RU101, \n",
      "I recommend RU201: Redis for Python Developers. This course will teach you \n",
      "how to build Redis applications using redis-py, which aligns perfectly with \n",
      "your goal of building a RAG system.\n",
      "\n",
      "Turn 3 (user):\n",
      "How long will that take me to complete?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, msg in enumerate(conversation_history, 1):\n",
    "    print(f\"Turn {i} ({msg['role']}):\")\n",
    "    print(f\"{msg['content']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Retrieved Context: \"What Information Is Relevant?\"\n",
    "\n",
    "Lastly, there is retrieved context. This is information fetched on-demand based on the current query using search or lookup operations.\n",
    "\n",
    "**Retrieval Methods:**\n",
    "- **Direct lookup** - Fetch specific records by ID (e.g., \"Get course CS301\")\n",
    "- **Search (RAG)** - Find relevant information using semantic/keyword search (e.g., \"Find courses about machine learning\")\n",
    "\n",
    "It typically contains:\n",
    "- Database records (course details, schedules)\n",
    "- Search results (relevant documents, FAQs)\n",
    "- API responses (real-time data, availability)\n",
    "- Computed information (eligibility checks, recommendations)\n",
    "\n",
    "For example, if a student asked the Redis University agent about \"machine learning courses\", the system would need to find relevant context to respond to the query. It would search the course catalog using semantic similarity, find ML-related courses, and retrieve information like course details (description, prerequisites, format), current availability (seats in sections), and instructor information.\n",
    "\n",
    "**Note:** In Module 2, you'll learn how to implement Retrieved Context using RAG (Retrieval Augmented Generation) - a powerful pattern for semantic and keyword search over large knowledge bases.\n",
    "\n",
    "Let's simulate what retrieved context will look like by hard-coding course content. Run the codeblock below (it will execute silently):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T23:21:51.314066Z",
     "start_time": "2025-12-03T23:21:51.311276Z"
    }
   },
   "outputs": [],
   "source": [
    "course_database = {\n",
    "    \"RU101\": {\n",
    "        \"title\": \"Introduction to Redis Data Structures\",\n",
    "        \"level\": \"Beginner\",\n",
    "        \"description\": \"Master Redis fundamentals: strings, hashes, lists, sets, and sorted sets\",\n",
    "        \"duration\": \"4-6 hours\",\n",
    "        \"prerequisites\": [],\n",
    "        \"topics\": [\"Data structures\", \"Basic commands\", \"Use cases\"],\n",
    "    },\n",
    "    \"RU201\": {\n",
    "        \"title\": \"Redis for Python Developers\",\n",
    "        \"level\": \"Intermediate\",\n",
    "        \"description\": \"Build production Redis applications with Python and redis-py\",\n",
    "        \"duration\": \"6-8 hours\",\n",
    "        \"prerequisites\": [\"RU101\", \"Python experience\"],\n",
    "        \"topics\": [\"redis-py library\", \"Connection pooling\", \"Pipelining\", \"Pub/Sub\"],\n",
    "    },\n",
    "    \"RU202\": {\n",
    "        \"title\": \"Redis for Java Developers\",\n",
    "        \"level\": \"Intermediate\",\n",
    "        \"description\": \"Build production Redis applications with Java and Jedis\",\n",
    "        \"duration\": \"6-8 hours\",\n",
    "        \"prerequisites\": [\"RU101\", \"Java experience\"],\n",
    "        \"topics\": [\n",
    "            \"Jedis library\",\n",
    "            \"Connection pooling\",\n",
    "            \"Transactions\",\n",
    "            \"Redis Streams\",\n",
    "        ],\n",
    "    },\n",
    "    \"RU301\": {\n",
    "        \"title\": \"Vector Similarity Search with Redis\",\n",
    "        \"level\": \"Advanced\",\n",
    "        \"description\": \"Implement semantic search and RAG systems with Redis vector capabilities\",\n",
    "        \"duration\": \"8-10 hours\",\n",
    "        \"prerequisites\": [\"RU201 or RU202\", \"ML/AI interest\"],\n",
    "        \"topics\": [\n",
    "            \"Vector embeddings\",\n",
    "            \"Semantic search\",\n",
    "            \"RAG architecture\",\n",
    "            \"Hybrid search\",\n",
    "        ],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's simulate retrieving course information based on a query. Just like before, we'll need to transform the data. Run the code block below to create the function and simulate the retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T23:21:52.040792Z",
     "start_time": "2025-12-03T23:21:52.038317Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Course Details:\n",
      "        Code: RU201\n",
      "        Title: Redis for Python Developers\n",
      "        Level: Intermediate\n",
      "        Description: Build production Redis applications with Python and redis-py\n",
      "        Duration: 6-8 hours\n",
      "        Prerequisites: RU101, Python experience\n",
      "        Topics Covered: redis-py library, Connection pooling, Pipelining, Pub/Sub\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Step 2: Create a retrieval function\n",
    "\n",
    "def retrieve_course_info(course_code):\n",
    "    \"\"\"Retrieve detailed information about a specific course\"\"\"\n",
    "    course = course_database.get(course_code)\n",
    "    if not course:\n",
    "        return None\n",
    "\n",
    "    return f\"\"\"Course Details:\n",
    "        Code: {course_code}\n",
    "        Title: {course['title']}\n",
    "        Level: {course['level']}\n",
    "        Description: {course['description']}\n",
    "        Duration: {course['duration']}\n",
    "        Prerequisites: {', '.join(course['prerequisites']) if course['prerequisites'] else 'None'}\n",
    "        Topics Covered: {', '.join(course['topics'])}\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "# Retrieve information about RU201\n",
    "retrieved_context = retrieve_course_info(\"RU201\")\n",
    "print(retrieved_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Retrieval Methods Across Context Types\n",
    "\n",
    "Now that we've seen all four context types, let's clarify how information is retrieved for each:\n",
    "\n",
    "| Context Type | What It Contains | How It's Retrieved | When RAG Applies |\n",
    "|--------------|------------------|-------------------|------------------|\n",
    "| **System Context** | Role, instructions, rules | Static (hardcoded) | Never - always included |\n",
    "| **User Context** | Profile + memories | **Lookup** (profile by user ID)<br>**+ RAG** (search memories) | When searching long-term memories (Module 4) |\n",
    "| **Conversation Context** | Chat history | **Lookup** (messages by session ID)<br>**+ RAG** (search history) | When searching long conversations (advanced) |\n",
    "| **Retrieved Context** | Domain knowledge | **RAG** (semantic/keyword search) | Always - this is the primary RAG use case (Module 2) |\n",
    "\n",
    "**Key Insight:**\n",
    "- **Lookup** = \"Get me the record with this ID\" (direct, fast, returns one specific item)\n",
    "- **RAG** = \"Find me the most relevant items for this query\" (search, returns top-k matches)\n",
    "\n",
    "**In this module**, we use simple lookup for User Context (hardcoded profile) and Conversation Context (hardcoded history).\n",
    "\n",
    "**In Module 2**, you'll implement RAG for Retrieved Context (search over courses).\n",
    "\n",
    "**In Module 4**, you'll see RAG applied to User Context (search over long-term memories).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T23:21:52.865996Z",
     "start_time": "2025-12-03T23:21:52.863806Z"
    }
   },
   "source": [
    "### Bringing It All Together: Complete Context Integration\n",
    "\n",
    "Now that we understand each context type individually, let's see how they work together to create an intelligent, personalized response.\n",
    "\n",
    "Here's how all four context types combine in a single LLM call:\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ           COMPLETE LLM REQUEST              ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ 1. SYSTEM CONTEXT (Static)                  ‚îÇ\n",
    "‚îÇ    - Role: \"You are a course advisor\"       ‚îÇ\n",
    "‚îÇ    - Domain: Available courses              ‚îÇ\n",
    "‚îÇ    - Rules: Guidelines and constraints      ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ 2. USER CONTEXT (Dynamic - User Specific)   ‚îÇ\n",
    "‚îÇ    - Profile: Sarah Chen, Python dev        ‚îÇ\n",
    "‚îÇ    - History: Completed RU101               ‚îÇ\n",
    "‚îÇ    - Goal: Build RAG system                 ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ 3. CONVERSATION CONTEXT (Dynamic - Session) ‚îÇ\n",
    "‚îÇ    - User: \"What course should I take?\"     ‚îÇ\n",
    "‚îÇ    - AI: \"I recommend RU201...\"             ‚îÇ\n",
    "‚îÇ    - User: \"How long will that take?\"       ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ 4. RETRIEVED CONTEXT (Dynamic - Query)      ‚îÇ\n",
    "‚îÇ    - RU201 course details                   ‚îÇ\n",
    "‚îÇ    - Duration, prerequisites, topics        ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ RESULT: Personalized, context-aware answer  ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "Let's add them together into a messages list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Start with system context\n",
    "messages = [{\"role\": \"system\", \"content\": system_context}]\n",
    "\n",
    "# Step 2: Add user context\n",
    "messages.append({\"role\": \"system\", \"content\": user_context})\n",
    "\n",
    "# Step 3: Add conversation history\n",
    "messages.extend(conversation_history)\n",
    "\n",
    "# Step 4: Add retrieved context\n",
    "messages.append({\"role\": \"system\", \"content\": retrieved_context})\n",
    "\n",
    "# Check the final messages structure\n",
    "for i, msg in enumerate(messages, 1):\n",
    "    print(f\"Message {i} ({msg['role']}):\")\n",
    "    print(f\"{msg['content']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-03T23:26:55.721294Z",
     "start_time": "2025-12-03T23:26:53.559489Z"
    }
   },
   "source": [
    "Finally, we can use the context to call the LLM:\n",
    "\n",
    "> ‚ö†Ô∏è Note: You'll need your own [OpenAI API](https://platform.openai.com/api-keys) key to make the LLM call. Make sure to replace it in the code block below before running it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI()  # Uses OPENAI_API_KEY from environment\n",
    "\n",
    "# Make the LLM call with complete context\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\", messages=messages, temperature=0.7\n",
    ")\n",
    "\n",
    "answer = response.choices[0].message.content\n",
    "print(\"AI Response:\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To recap what just happened, we sent an assembled context to the LLM. It received all four context types and used them to generate a personalized response:\n",
    "\n",
    "1. **System Context** told it to act as a course advisor and provided course information\n",
    "2. **User Context** gave it Sarah's background, interests, and goals\n",
    "3. **Conversation Context** showed that \"that\" refers to RU201\n",
    "4. **Retrieved Context** provided detailed information about RU201's duration and topics\n",
    "\n",
    "The result is a response that:\n",
    "- Understands what course \"that\" refers to\n",
    "- Considers Sarah's available time (evenings and weekends)\n",
    "- Relates the duration to her specific situation\n",
    "- Stays aligned with her goal of building a RAG system\n",
    "\n",
    "While this was a simple example, it demonstrated all four layers of context that we will be managing throughout this course. As we build more complex agents, these same principles will apply ‚Äî but the techniques for managing, optimizing, and orchestrating these contexts will become increasingly sophisticated.\n",
    "\n",
    "Yet even with perfect context engineering, every AI system hits the same wall: the finite size of the model's context window. Let's explore this fundamental constraint next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Token Usage\n",
    "\n",
    "Before we discuss context windows, let's build a practical tool to measure how many tokens our context actually uses. Understanding token consumption is essential for staying within limits and optimizing your context strategy.\n",
    "\n",
    "Run the following code to create token estimation and analysis functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_tokens(text):\n",
    "    \"\"\"Rough token estimation (approximately 4 characters per token for English)\"\"\"\n",
    "    return len(text) // 4\n",
    "\n",
    "\n",
    "def analyze_context_usage(messages, model_limit=128000):\n",
    "    \"\"\"Analyze token usage across different context types in our messages\"\"\"\n",
    "    usage = {\"system\": 0, \"user\": 0, \"assistant\": 0}\n",
    "\n",
    "    for msg in messages:\n",
    "        role = msg[\"role\"]\n",
    "        tokens = estimate_tokens(msg[\"content\"])\n",
    "        usage[role] += tokens\n",
    "\n",
    "    total = sum(usage.values())\n",
    "    remaining = model_limit - total\n",
    "    percent_used = (total / model_limit) * 100\n",
    "\n",
    "    print(\"=\" * 50)\n",
    "    print(\"CONTEXT TOKEN ANALYSIS\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"\\nToken Usage by Role:\")\n",
    "    print(f\"  System context:      {usage['system']:,} tokens\")\n",
    "    print(f\"  User messages:       {usage['user']:,} tokens\")\n",
    "    print(f\"  Assistant messages:  {usage['assistant']:,} tokens\")\n",
    "    print(f\"\\n  TOTAL:               {total:,} tokens\")\n",
    "    print(f\"  Model limit:         {model_limit:,} tokens\")\n",
    "    print(f\"  Remaining:           {remaining:,} tokens\")\n",
    "    print(f\"  Usage:               {percent_used:.2f}%\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    return usage, total, remaining\n",
    "\n",
    "\n",
    "# Analyze our current context\n",
    "analyze_context_usage(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This simple analysis shows that our current context uses only a small fraction of the available tokens. However, as conversations grow longer and we retrieve more documents, token usage can quickly balloon. Monitoring this helps you make informed decisions about what context to include or compress."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Fundamental Challenge: Context Windows\n",
    "\n",
    "Even the most powerful AI models can only process a fixed amount of text in a single request. This is called the **context window**, which is essentially the size of our anecdotal clerk's desk. Here are the context window sizes of some of the most popular models available:\n",
    "\n",
    "| Model | Context Window |\n",
    "|-------|----------------|\n",
    "| GPT-4o | 128,000 tokens (~96,000 words) |\n",
    "| GPT-4o-mini | 128,000 tokens (~96,000 words) |\n",
    "| Claude 3.5 Sonnet | 200,000 tokens (~150,000 words) |\n",
    "\n",
    "This limit might look generous, but when we break it down, we have a ton of different context competing for space. Here is an example context budget breakdown for a single turn using a modeL:\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ   CONTEXT WINDOW - 128K tokens      ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ System Context    ‚îÇ 2,000 tokens    ‚îÇ  ‚Üê AI's role and rules\n",
    "‚îÇ User Context      ‚îÇ 1,000 tokens    ‚îÇ  ‚Üê Your profile\n",
    "‚îÇ Conversation      ‚îÇ 4,000 tokens    ‚îÇ  ‚Üê What we've discussed\n",
    "‚îÇ Retrieved Info    ‚îÇ 5,000 tokens    ‚îÇ  ‚Üê Relevant data\n",
    "‚îÇ Your Query        ‚îÇ 100 tokens      ‚îÇ  ‚Üê Current question\n",
    "‚îÇ Response Space    ‚îÇ 4,000 tokens    ‚îÇ  ‚Üê AI's answer\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ TOTAL TOKENS      ‚îÇ 16,100 tokens   ‚îÇ\n",
    "‚îÇ REMAINING TOKENS  ‚îÇ 111,900 tokens  ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "That remaining space (111,900) might look comforting but remember this is just one turn. \n",
    "\n",
    "![Context engineering overview](../public/agents-token-hungry.png)\n",
    "\n",
    "\n",
    "- Our inputs will likely only grow longer (especially around conversation history), and as they do models have a harder time producing effective results.\n",
    "\n",
    "\n",
    "Additionally, [Chroma](https://www.trychroma.com/) revealed a critical challenge in working with LLMs: [context rot](https://research.trychroma.com/context-rot)\n",
    "  - the phenomenon where LLM performance degrades non-uniformly as input context length increases, even on simple tasks.\n",
    "\n",
    "If we summarized the research findings around the size of context in a AI system, it would break out into the following: \n",
    "\n",
    "1. **Longer context ‚â† better context**: Reliability drops and accelerates as inputs grow. This means we should treat the window like working memory; budget tokens when possible and keep the slice small.\n",
    "\n",
    "2. **Relevance rules**: High semantic match drives accuracy; loosely related text hurts. We should prioritize optimizing retrieval precision (rerank, tighten filters, rewrite queries).\n",
    "\n",
    "3. **Distractors are toxic**: Similar but wrong snippets do disproportionate damage as length increases. To reduce distractors, we should aggressively filter/threshold, dedupe, and avoid ‚Äújust in case‚Äù context.\n",
    "\n",
    "4. **Placement & structure matter**: Models attend unevenly across the window; key facts can be missed when buried. We should surface essentials early, chunk clearly, and summarize instead of pasting raw dumps. \n",
    "\n",
    "\n",
    "![Context engineering overview](../public/chroma_distractors.png)\n",
    "\n",
    "**Figure**: Performance degradation with context length.  \n",
    "*Source: Adapted from \"Many-Shot In-Context Learning in Multimodal Foundation Models\" \n",
    "(Chroma Research, 2025). [Link to paper](https://research.trychroma.com/context-rot)*\n",
    "\n",
    "\n",
    "Remember, every token spent on one thing is a token NOT available for another. This means you must constantly decide:\n",
    "\n",
    "- Which context is most relevant?\n",
    "- What can be omitted without hurting quality?\n",
    "- When to retrieve more vs. use what you have?\n",
    "- How to compress long conversations?\n",
    "\n",
    "This makes context engineering a practice of optimization within constraints. As conversations grow longer, systems accumulate more data, and applications become more sophisticated, context management becomes increasingly critical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Challenges\n",
    "\n",
    "\n",
    "![Context engineering overview](../public/context-problems.png)\n",
    "\n",
    "While managing the size of your context window is critical, simply fitting everything in isn't the only hurdle. As D. Breunig highlights in [How Contexts Fail (and How to Fix Them)](https://www.dbreunig.com/2025/06/22/how-contexts-fail-and-how-to-fix-them.html), there are several other ways that context can degrade the performance of your agent, even when you are well within the token limits.\n",
    "\n",
    "He mentions four key failure modes to watch out for:\n",
    "\n",
    "1.  **Context Poisoning**: This occurs when an error or hallucination makes its way into your context (e.g., conversation history) and is then treated as fact in subsequent turns. The model \"learns\" the wrong information from its own previous output, leading to a loop of compounding errors.\n",
    "\n",
    "2.  **Context Distraction**: As highlighted also by Chroma, sometimes, having *too much* history can be detrimental. If an agent has a massive log of past actions, it may start to over-focus on repeating those past behaviors rather than reasoning about the current, novel situation. It relies on its \"contextual habit\" instead of its training.\n",
    "\n",
    "3.  **Context Confusion**: This happens when the context is cluttered with superfluous information‚Äîsuch as too many available tools or irrelevant document snippets. Even if the model *could* ignore them, the mere presence of these \"distractors\" increases the probability of the model getting confused or trying to use a tool that isn't needed.\n",
    "\n",
    "4.  **Context Clash**: This is when different parts of your context contradict each other. For example, your system prompt might say one thing, but a retrieved document or an early turn in the conversation history says the opposite. When the model faces this internal conflict, its reasoning capabilities often degrade significantly.\n",
    "\n",
    "Understanding these failure modes reinforces why context engineering is not just about *compression*‚Äîit's about *curation*. We must actively manage, clean, and sometimes even \"forget\" context to keep our agents sharp.\n",
    "\n",
    "In this course, we will not solve every one of these failure modes. Some, like context poisoning, remain as complex open research problems in AI. However, we will systematically dismantle the most common ones by building a series of \"progressive agents,\" each designed to overcome specific context limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Context Strategies\n",
    "\n",
    "To see the real impact of context engineering, let's compare how the same query performs with different amounts of context. This demonstrates why adding the right context matters.\n",
    "\n",
    "We'll test three strategies:\n",
    "1. **Minimal** - System context only (generic responses)\n",
    "2. **With User** - System + User context (personalized responses)\n",
    "3. **With Retrieval** - System + User + Retrieved context (expert responses)\n",
    "\n",
    "Run the following code to compare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_context_strategies(user_profile, test_query):\n",
    "    \"\"\"Compare responses with different context strategies\"\"\"\n",
    "\n",
    "    strategies = {\n",
    "        \"minimal\": [\n",
    "            {\"role\": \"system\", \"content\": system_context},\n",
    "            {\"role\": \"user\", \"content\": test_query},\n",
    "        ],\n",
    "        \"with_user\": [\n",
    "            {\"role\": \"system\", \"content\": system_context},\n",
    "            {\"role\": \"system\", \"content\": format_user_context(user_profile)},\n",
    "            {\"role\": \"user\", \"content\": test_query},\n",
    "        ],\n",
    "        \"with_retrieval\": [\n",
    "            {\"role\": \"system\", \"content\": system_context},\n",
    "            {\"role\": \"system\", \"content\": format_user_context(user_profile)},\n",
    "            {\"role\": \"system\", \"content\": retrieve_course_info(\"RU201\")},\n",
    "            {\"role\": \"system\", \"content\": retrieve_course_info(\"RU301\")},\n",
    "            {\"role\": \"user\", \"content\": test_query},\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    print(f\"Query: {test_query}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    for strategy_name, messages in strategies.items():\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\", messages=messages, max_tokens=150\n",
    "        )\n",
    "\n",
    "        print(f\"\\nüîπ {strategy_name.upper()} strategy:\")\n",
    "        print(response.choices[0].message.content)\n",
    "        print()\n",
    "\n",
    "\n",
    "# Test with a sample query\n",
    "test_context_strategies(olivia_profile, \"What course should I take next?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What We Observed\n",
    "\n",
    "Notice the dramatic difference in response quality:\n",
    "\n",
    "| Strategy | Behavior | Result |\n",
    "|----------|----------|--------|\n",
    "| **Minimal** | Asks clarifying questions | \"What's your background? What are your goals?\" |\n",
    "| **With User** | Personalizes immediately | \"Based on your Python experience and RU101...\" |\n",
    "| **With Retrieval** | Provides specific details | Includes course duration, topics, prerequisites |\n",
    "\n",
    "**Key Insight:** More relevant context = fewer back-and-forth interactions = better user experience.\n",
    "\n",
    "- **Minimal context** requires 3-4 interactions to gather enough information\n",
    "- **Rich context** provides a complete answer in 1 interaction\n",
    "\n",
    "The challenge becomes: determining what context is \"relevant\" while managing token budgets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices for Context Engineering\n",
    "\n",
    "Based on what we've learned, here are five essential practices to follow:\n",
    "\n",
    "1. **Start simple, add complexity gradually** \n",
    "   - Begin with system context only\n",
    "   - Add user context when you have it\n",
    "   - Retrieve additional context only when needed\n",
    "\n",
    "2. **Measure token usage continuously**\n",
    "   - Track how much of your context window is being used\n",
    "   - Set alerts before hitting limits\n",
    "   - Monitor growth patterns over conversation length\n",
    "\n",
    "3. **Optimize for relevance, not completeness**\n",
    "   - Don't dump all available information into context\n",
    "   - Retrieve only what's relevant to the current query\n",
    "   - Filter and rank retrieved content by relevance\n",
    "\n",
    "4. **Use clear, structured formatting**\n",
    "   - Organize context with headers and sections\n",
    "   - Use bullet points and key-value pairs\n",
    "   - Make it easy for the model to find information\n",
    "\n",
    "5. **Test different context combinations**\n",
    "   - Experiment with what to include vs. exclude\n",
    "   - Measure response quality with different strategies\n",
    "   - Iterate based on real user interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap Up\n",
    "\n",
    "In this introduction, we started to explore how real AI applications depend on carefully constructed context. More specifically we covered the following:\n",
    "\n",
    "1. Context engineering is the practice of deliberately shaping the information surrounding an application, rather than just crafting individual prompts.\n",
    "2. There are four types of context we will focus on: system context, user context, conversation context, and retrieved context.\n",
    "3. All LLMs have fixed context windows, creating a fundamental constraint where every token used for one purpose is unavailable for another.\n",
    "4. Context rot is a phenomenon where LLM performance degrades as input context length increases, even on simple tasks.\n",
    "5. Context failures such as distraction, confusion, and clash occur when irrelevant or contradictory information is present in the context window.\n",
    "\n",
    "We are now ready to start building. In **Module 2: Data Engineering for Context**, we will learn how to prepare data for LLM consumption‚Äîthe critical step before implementing RAG. We'll cover the data pipeline, chunking decisions, and see how context engineering can achieve 91% token reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
