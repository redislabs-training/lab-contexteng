{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a93fd8d7bb4a873",
   "metadata": {},
   "source": [
    "![Redis](https://redis.io/wp-content/uploads/2024/04/Logotype.svg?auto=webp&quality=85,75&width=120)\n",
    "\n",
    "# Data Engineering for Context Systems: A Theoretical Foundation\n",
    "\n",
    "**A Comprehensive Guide to Chunking, Data Modeling, and Retrieval Optimization**\n",
    "\n",
    "## ðŸŽ¯ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will understand:\n",
    "\n",
    "1. **The fundamental question**: When to chunk vs. when not to chunk\n",
    "2. **Data modeling principles**: How to structure data for optimal retrieval\n",
    "3. **Chunking strategies**: Document-based, fixed-size, and semantic approaches\n",
    "4. **Context engineering impact**: How data engineering decisions affect what reaches the LLM\n",
    "5. **Production patterns**: Real-world decision frameworks and trade-offs\n",
    "6. **Multimodal content**: Handling tables, formulas, and figures in documents\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“– Table of Contents\n",
    "\n",
    "**Part 1: The Foundation - Data Modeling for RAG**\n",
    "- The critical first question: What is your natural retrieval unit?\n",
    "- When NOT to chunk (structured records)\n",
    "- The hierarchical pattern: Summaries + Details\n",
    "\n",
    "**Part 2: When Chunking Matters**\n",
    "- Document types that benefit from chunking\n",
    "- Research foundations: Lost in the Middle, Context Rot\n",
    "- The retrieval precision problem\n",
    "\n",
    "**Part 3: Core Chunking Strategies**\n",
    "- Strategy 1: Document-Based (Structure-Aware)\n",
    "- Strategy 2: Fixed-Size (Token-Based)\n",
    "- Strategy 3: Semantic (Meaning-Based)\n",
    "- Comparative analysis and decision framework\n",
    "\n",
    "**Part 4: Advanced Topics**\n",
    "- Multimodal content (tables, formulas, figures)\n",
    "- Complex documents (legal contracts, knowledge graphs)\n",
    "- Troubleshooting common chunking failures\n",
    "\n",
    "**Part 5: Context Engineering Principles**\n",
    "- How chunking affects context quality\n",
    "- Token efficiency vs. retrieval precision\n",
    "- Production-ready decision frameworks\n",
    "\n",
    "**â±ï¸ Estimated Time:** 45-60 minutes\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Understanding of vector embeddings and semantic search\n",
    "- Familiarity with RAG (Retrieval-Augmented Generation) concepts\n",
    "- Basic knowledge of LLM context windows\n",
    "\n",
    "---\n",
    "\n",
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cead7cfab5a840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Handle both running from notebooks/ directory and from project root\n",
    "if Path.cwd().name == \"notebooks\":\n",
    "    project_root = Path.cwd().parent\n",
    "else:\n",
    "    project_root = Path.cwd()\n",
    "\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Load environment variables\n",
    "env_path = project_root / \".env\"\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "# Verify required environment variables\n",
    "required_vars = [\"OPENAI_API_KEY\"]\n",
    "missing_vars = [var for var in required_vars if not os.getenv(var)]\n",
    "\n",
    "if missing_vars:\n",
    "    print(f\"\"\"âš ï¸  Missing required environment variables: {', '.join(missing_vars)}\n",
    "\n",
    "Please create a .env file with:\n",
    "OPENAI_API_KEY=your_openai_api_key\n",
    "REDIS_URL=redis://localhost:6379\n",
    "\"\"\")\n",
    "    sys.exit(1)\n",
    "\n",
    "REDIS_URL = os.getenv(\"REDIS_URL\", \"redis://localhost:6379\")\n",
    "print(\"âœ… Environment variables loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814169618882af67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "import redis\n",
    "import tiktoken\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Import hierarchical components\n",
    "from redis_context_course.hierarchical_manager import HierarchicalCourseManager\n",
    "from redis_context_course.hierarchical_context import HierarchicalContextAssembler\n",
    "\n",
    "# Initialize\n",
    "hierarchical_manager = HierarchicalCourseManager(redis_client=redis.from_url(REDIS_URL, decode_responses=True))\n",
    "context_assembler = HierarchicalContextAssembler()\n",
    "redis_client = redis.from_url(REDIS_URL, decode_responses=True)\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# Token counter\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "\n",
    "\n",
    "def count_tokens(text: str) -> int:\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "\n",
    "print(\"âœ… Dependencies loaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28681da3699cd19",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: The Foundation - Data Modeling for RAG\n",
    "\n",
    "### ðŸŽ¯ The Critical First Question\n",
    "\n",
    "Before thinking about chunking, you must ask:\n",
    "\n",
    "> **\"What is the natural unit of information I want to retrieve?\"**\n",
    "\n",
    "This is the most important question in data engineering for RAG systems. Just like database schema design, how you structure your knowledge base dramatically affects:\n",
    "- **Retrieval quality**: Can you find the right information?\n",
    "- **Token efficiency**: Are you wasting context on irrelevant data?\n",
    "- **System performance**: How fast can you retrieve and process?\n",
    "\n",
    "### ðŸ”‘ Why This Matters for Context Engineering\n",
    "\n",
    "**Context engineering is about controlling what information reaches the LLM.** Your data modeling decisions directly impact:\n",
    "\n",
    "1. **Precision**: Does the retrieved context contain exactly what's needed?\n",
    "2. **Completeness**: Is all necessary information included?\n",
    "3. **Efficiency**: Are you minimizing irrelevant tokens?\n",
    "\n",
    "**The Wrong Approach:**\n",
    "```\n",
    "\"I have documents â†’ I need to chunk them â†’ What chunk size should I use?\"\n",
    "```\n",
    "\n",
    "**The Right Approach:**\n",
    "```\n",
    "\"What is my natural retrieval unit? â†’ Does it need chunking? â†’ If yes, which strategy?\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bb35eac0917066",
   "metadata": {},
   "source": [
    "### ðŸ“Š Natural Retrieval Units: Examples Across Domains\n",
    "\n",
    "Understanding your natural retrieval unit is domain-specific. Here are common patterns:\n",
    "\n",
    "| Domain | Natural Unit | Why | Chunking Needed? |\n",
    "|--------|-------------|-----|------------------|\n",
    "| **Course Catalog** | Individual course | Each course is self-contained, complete | âŒ No |\n",
    "| **Product Catalog** | Individual product | All product info should be retrieved together | âŒ No |\n",
    "| **FAQ Database** | Question + Answer pair | Q&A is an atomic unit | âŒ No |\n",
    "| **Research Papers** | Section or paragraph | Different sections answer different queries | âœ… Yes |\n",
    "| **Legal Contracts** | Clause or section | Need clause-level precision | âœ… Yes |\n",
    "| **Support Tickets** | Individual ticket | Single issue with context | âŒ No |\n",
    "| **Technical Docs** | Topic/section | Each section covers distinct functionality | âœ… Yes |\n",
    "| **Code Repositories** | Function/class | Semantic boundaries at code structure | âœ… Yes |\n",
    "\n",
    "**Key Insight:** Many structured data types (catalogs, FAQs, tickets) are already at optimal granularity. Chunking them would **reduce** retrieval quality.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca4e203c490385",
   "metadata": {},
   "source": [
    "### ðŸŽ“ Theory: \n",
    "\n",
    "The \"Don't Chunk\" Strategy\n",
    "**Concept:** For structured records with natural boundaries, chunking is counterproductive.\n",
    "\n",
    "**When to Use:**- Data is already organized into discrete, self-contained units- Each unit represents a complete semantic entity- Query patterns align with unit boundaries- Units are reasonably sized (typically 100-500 tokens)\n",
    "\n",
    "**Example: Course Catalog**Let's examine why a course catalog doesn't need chunking:>\n",
    "\n",
    "**Note**: The following code cell demonstrates hierarchical retrieval with Redis. If you don't have Redis running with course data loaded, you can skip this cell and continue reading - the concepts are explained in the markdown cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c4b7470732429e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sample course to analyzeasync def show_course_example():    sample_courses = await hierarchical_manager.search_summaries(        query=\"programming courses\", limit=3    )    sample_course = sample_courses[0]        # Generate embedding text if not present    if not sample_course.embedding_text:        sample_course.generate_embedding_text()        # Display the course structure    print(f\"\"\"ðŸ“š Sample Course: {sample_course.course_code}{'=' * 80}Title: {sample_course.title}Department: {sample_course.department}Level: {sample_course.difficulty_level.value}Credits: {sample_course.credits}Instructor: {sample_course.instructor}Description:{sample_course.short_description}Prerequisites: {', '.join(sample_course.prerequisite_codes) if sample_course.prerequisite_codes else 'None'}Tags: {', '.join(sample_course.tags) if sample_course.tags else 'None'}{'=' * 80}Token count: {count_tokens(sample_course.embedding_text)}\"\"\")# Run the exampleawait show_course_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7333f9bf8897be",
   "metadata": {},
   "source": [
    "### ðŸ“Š Analysis: Why Courses Don't Need Chunking\n",
    "\n",
    "Let's evaluate this course against chunking criteria:\n",
    "\n",
    "**1. Semantic Completeness:** âœ…\n",
    "- All information about the course is in one record\n",
    "- No cross-references to other sections\n",
    "- Natural boundary exists (one course = one retrieval unit)\n",
    "\n",
    "**2. Query Patterns:** âœ…\n",
    "- Users ask about specific courses or course types:\n",
    "  - \"What machine learning courses are available?\"\n",
    "  - \"Tell me about CS016\"\n",
    "  - \"What are the prerequisites for RU102JS?\"\n",
    "- Each query expects a complete course record, not fragments\n",
    "\n",
    "**3. Retrieval Precision:** âœ…\n",
    "- When a user asks about a course, they need ALL the information\n",
    "- Splitting would fragment related information:\n",
    "  - Separating prerequisites from description\n",
    "  - Splitting instructor from course content\n",
    "  - Breaking apart tags from topics\n",
    "- Each course is already the optimal retrieval unit\n",
    "\n",
    "**4. Token Efficiency:** âœ…\n",
    "- Courses are reasonably sized (~150-200 tokens each)\n",
    "- Not too large (no wasted context)\n",
    "- Not too small (no fragmentation overhead)\n",
    "\n",
    "**5. Context Engineering Impact:**\n",
    "- **Without chunking**: Retrieve complete, coherent course information\n",
    "- **With chunking**: Risk fragmenting related data, requiring multiple retrievals\n",
    "- **Result**: Don't chunk - preserve natural boundaries\n",
    "\n",
    "**Decision:** âŒ **Don't chunk course data** - it's already optimally structured!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d973d46f52786527",
   "metadata": {},
   "source": [
    "### ðŸ—ï¸ The Hierarchical Pattern: A Better Data Model\n",
    "\n",
    "Instead of chunking structured records, use a **hierarchical pattern** with multiple tiers:\n",
    "\n",
    "**Architecture:**\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ Tier 1: Summaries (Lightweight, Searchable)                â”‚\n",
    "â”‚ - Stored in vector index                                    â”‚\n",
    "â”‚ - ~150-200 tokens each                                      â”‚\n",
    "â”‚ - Fast semantic search                                      â”‚\n",
    "â”‚ - Returns: Top-k matches                                    â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                            â†“\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ Tier 2: Details (On-Demand, Complete)                      â”‚\n",
    "â”‚ - Stored as plain Redis keys                                â”‚\n",
    "â”‚ - Full information with all fields                          â”‚\n",
    "â”‚ - Retrieved only when needed                                â”‚\n",
    "â”‚ - Returns: Complete records for top matches                 â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "**Why This Works:**\n",
    "\n",
    "1. **Separation of Concerns**:\n",
    "   - Search uses lightweight summaries (fast, efficient)\n",
    "   - Context assembly uses full details (complete, accurate)\n",
    "\n",
    "2. **Token Efficiency**:\n",
    "   - Search 100 summaries = ~20,000 tokens\n",
    "   - Retrieve 3 full details = ~1,500 tokens\n",
    "   - Total context = ~1,500 tokens (not 20,000!)\n",
    "\n",
    "3. **Retrieval Quality**:\n",
    "   - Summaries optimized for semantic matching\n",
    "   - Details optimized for completeness\n",
    "   - No information fragmentation\n",
    "\n",
    "**This is data modeling, not chunking** - we're structuring data for optimal retrieval patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc715bb45377c486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hierarchical retrieval exampleasync def demonstrate_hierarchical_retrieval():    query = \"beginner programming courses\"        # Tier 1: Search summaries (lightweight, fast)    print(f\"ðŸ” Query: '{query}'\\n\")    print(\"Tier 1: Searching summaries...\")    summaries = await hierarchical_manager.search_summaries(query, limit=5)        print(f\"Found {len(summaries)} relevant courses\\n\")    for i, course in enumerate(summaries, 1):        print(f\"{i}. {course.course_code}: {course.title}\")        print(f\"   Level: {course.difficulty_level.value} | Credits: {course.credits}\")        print()        # Tier 2: Get full details for top matches    print(\"\\nTier 2: Fetching full details for top 3 courses...\")    top_course_ids = [c.course_code for c in summaries[:3]]    full_details = await hierarchical_manager.get_full_details(top_course_ids)        print(f\"\\nðŸ“š Full Details Retrieved:\\n\")    for course in full_details:        print(f\"{course.course_code}: {course.title}\")        print(f\"Description: {course.short_description[:100]}...\")        print(f\"Prerequisites: {', '.join(course.prerequisite_codes) if course.prerequisite_codes else 'None'}\")        print(f\"Instructor: {course.instructor}\")        print()        # Show token efficiency    summary_tokens = sum(count_tokens(c.embedding_text) for c in summaries)    detail_tokens = sum(count_tokens(c.embedding_text) for c in full_details)        print(f\"\"\"ðŸ“Š Token Efficiency:{'=' * 80}Tier 1 (5 summaries): {summary_tokens} tokensTier 2 (3 full details): {detail_tokens} tokensTotal: {summary_tokens + detail_tokens} tokensvs. retrieving 5 full courses: {sum(count_tokens(c.embedding_text) for c in summaries)} tokensSavings: {100 * (1 - (summary_tokens + detail_tokens) / sum(count_tokens(c.embedding_text) for c in summaries)):.1f}%\"\"\")# Run the demonstrationawait demonstrate_hierarchical_retrieval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ae84a3c8b0c32e",
   "metadata": {},
   "source": [
    "### ðŸ”‘ Key Takeaway: Part 1\n",
    "\n",
    "> **For structured records like courses, products, or FAQs, the hierarchical pattern (summaries + details) is superior to chunking because it respects natural data boundaries and retrieval patterns.**\n",
    "\n",
    "**Context Engineering Principle:**\n",
    "- **Chunking** = Breaking apart what should stay together\n",
    "- **Hierarchical modeling** = Organizing data at appropriate granularity levels\n",
    "- **Result**: Better retrieval precision, lower token costs, clearer context\n",
    "\n",
    "---\n",
    "\n",
    "## Part 2: When Documents DO Need Chunking\n",
    "\n",
    "Now let's examine the opposite case: **long-form documents** with multiple distinct topics.\n",
    "\n",
    "### ðŸŽ¯ The Problem: Information Overload\n",
    "\n",
    "Some documents are fundamentally different from structured records:\n",
    "- They contain multiple distinct topics\n",
    "- Different sections answer different queries\n",
    "- Retrieving the entire document wastes tokens and reduces precision\n",
    "\n",
    "**Example: Research Papers**\n",
    "\n",
    "Let's load a real research paper to understand the problem:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8111348bbf239b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the actual research paper PDF\n",
    "import pypdf\n",
    "\n",
    "pdf_path = project_root / \"data\" / \"arxiv_2504_02268.pdf\"\n",
    "reader = pypdf.PdfReader(pdf_path)\n",
    "\n",
    "# Extract text from all pages\n",
    "research_paper = \"\"\n",
    "for page in reader.pages:\n",
    "    research_paper += page.extract_text() + \"\\n\"\n",
    "\n",
    "paper_tokens = count_tokens(research_paper)\n",
    "print(f\"\"\"ðŸ“„ Real Research Paper\n",
    "{'=' * 80}\n",
    "Title: \"Advancing Semantic Caching for LLMs with Domain-Specific Embeddings\"\n",
    "Authors: Waris Gill et al. (Redis & Virginia Tech, 2025)\n",
    "Source: arXiv:2504.02268\n",
    "\n",
    "Structure:\n",
    "- Abstract\n",
    "- Introduction\n",
    "- Background and Related Work\n",
    "- Methodology (Synthetic Data Generation)\n",
    "- Evaluation and Results\n",
    "- Conclusion\n",
    "\n",
    "Pages: {len(reader.pages)}\n",
    "Token count: {paper_tokens:,}\n",
    "Characters: {len(research_paper):,}\n",
    "{'=' * 80}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a061a23e931ef06",
   "metadata": {},
   "source": [
    "### ðŸ“Š Comparative Analysis: Course vs. Research Paper\n",
    "\n",
    "Let's compare the course catalog (doesn't need chunking) with the research paper (does need chunking):\n",
    "\n",
    "| Factor | Course Catalog | Research Paper |\n",
    "|--------|---------------|----------------|\n",
    "| **Document Structure** | Single topic per record | Multiple distinct sections |\n",
    "| **Semantic Completeness** | Each course is self-contained | Sections cover different topics |\n",
    "| **Query Patterns** | \"Show me CS courses\" | \"How is synthetic data generated?\" |\n",
    "| **Optimal Retrieval Unit** | Whole course | Specific section |\n",
    "| **Token Count** | ~150-200 per course | ~6,000 for entire paper |\n",
    "| **Chunking Decision** | âŒ Don't chunk | âœ… Chunk by section |\n",
    "\n",
    "### ðŸŽ“ Theory: Why Research Papers Need Chunking\n",
    "\n",
    "**1. Multiple Distinct Topics:**\n",
    "- Abstract, Introduction, Methodology, Evaluation, Conclusion each cover different aspects\n",
    "- A query about \"synthetic data generation\" only needs the Methodology section, not the entire paper\n",
    "\n",
    "**2. Retrieval Precision Problem:**\n",
    "\n",
    "| Query | Needs | Without Chunking | With Chunking | Improvement |\n",
    "|-------|-------|------------------|---------------|-------------|\n",
    "| \"How is synthetic data generated?\" | Methodology section | Entire paper (~6,000 tokens) | Methodology (~500 tokens) | **92% reduction** |\n",
    "| \"What were the hit rate results?\" | Evaluation + Tables | Entire paper (~6,000 tokens) | Evaluation (~400 tokens) | **93% reduction** |\n",
    "| \"What embedding models were tested?\" | Results section | Entire paper (~6,000 tokens) | Results (~300 tokens) | **95% reduction** |\n",
    "| \"What is semantic caching?\" | Introduction + Background | Entire paper (~6,000 tokens) | Intro+Background (~600 tokens) | **90% reduction** |\n",
    "\n",
    "**Impact:** 8-12x reduction in irrelevant context, leading to:\n",
    "- Faster response times (less processing)\n",
    "- Better answer quality (less noise)\n",
    "- Lower costs (fewer tokens)\n",
    "\n",
    "**3. Context Engineering Impact:**\n",
    "\n",
    "Without chunking:\n",
    "```\n",
    "Query: \"How is synthetic data generated?\"\n",
    "Retrieved: [Entire 6,000-token paper]\n",
    "Problem: 5,500 tokens are irrelevant (Abstract, Intro, Evaluation, Conclusion)\n",
    "Result: LLM must filter through noise to find answer\n",
    "```\n",
    "\n",
    "With chunking:\n",
    "```\n",
    "Query: \"How is synthetic data generated?\"\n",
    "Retrieved: [Methodology section, 500 tokens]\n",
    "Benefit: Only relevant content in context\n",
    "Result: LLM gets precise, focused information\n",
    "```\n",
    "\n",
    "**ðŸ’¡ Key Insight:** Chunking isn't about fitting in context windows - it's about **data modeling for retrieval**. Just like you wouldn't store all customer data in one database row, you shouldn't embed all document content in one vector when sections serve different purposes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8fb844e30190a",
   "metadata": {},
   "source": [
    "### ðŸ“š Research Background: Why Chunking Matters\n",
    "\n",
    "Even with large context windows (128K+ tokens), research shows that **how you structure context matters more than fitting everything in**.\n",
    "\n",
    "**Key Research Findings:**\n",
    "\n",
    "**1. \"Lost in the Middle\" (Stanford/UC Berkeley, 2023)** - [arXiv:2307.03172](https://arxiv.org/abs/2307.03172)\n",
    "\n",
    "**Finding:** LLMs exhibit **U-shaped attention** - high recall at beginning/end, degraded in middle\n",
    "\n",
    "**Implication for Chunking:**\n",
    "- Chunking ensures relevant sections are retrieved and placed prominently\n",
    "- Avoids burying critical information in the middle of long context\n",
    "- Enables strategic placement of most relevant chunks\n",
    "\n",
    "**2. \"Context Rot\" (Chroma Research, 2025)** - [research.trychroma.com/context-rot](https://research.trychroma.com/context-rot)\n",
    "\n",
    "**Finding:** Performance degrades as input length increases, even when relevant info is present\n",
    "\n",
    "**Key Observations:**\n",
    "- **Distractor effect**: Irrelevant content actively hurts model performance\n",
    "- Longer context â‰  better performance\n",
    "- Quality of context > quantity of context\n",
    "\n",
    "**Implication for Chunking:**\n",
    "- Smaller, focused chunks reduce \"distractor tokens\"\n",
    "- Precision retrieval beats comprehensive retrieval\n",
    "- Token efficiency improves answer quality\n",
    "\n",
    "**3. Needle in the Haystack (NIAH)** - [github.com/gkamradt/LLMTest_NeedleInAHaystack](https://github.com/gkamradt/LLMTest_NeedleInAHaystack)\n",
    "\n",
    "**Finding:** Models often fail to retrieve information buried in long context\n",
    "\n",
    "**Implication for Chunking:**\n",
    "- For structured data, NIAH is irrelevantâ€”each record IS the needle\n",
    "- For long documents, chunking creates multiple small haystacks\n",
    "- Semantic search finds the right haystack, avoiding the needle problem\n",
    "\n",
    "**The Takeaway:** These findings inform design decisions but don't prescribe universal rules:\n",
    "- **Structured records** (courses, products) don't need chunking\n",
    "- **Long-form documents** (papers, books) benefit from chunking\n",
    "- **Experiment with YOUR data** to find optimal approach\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cab6cc3b179f5b4",
   "metadata": {},
   "source": [
    "### ðŸ”‘ Key Takeaway: Part 2\n",
    "\n",
    "> **Long-form documents with multiple distinct topics benefit from chunking because it enables precision retrieval, reduces irrelevant context, and improves answer quality.**\n",
    "\n",
    "**Context Engineering Principle:**\n",
    "- **Problem**: Entire document = too much irrelevant information\n",
    "- **Solution**: Chunk by semantic boundaries (sections, topics)\n",
    "- **Result**: Retrieve only what's needed, minimize noise\n",
    "\n",
    "---\n",
    "\n",
    "## Part 3: Core Chunking Strategies\n",
    "\n",
    "Now that we understand **when** to chunk (long-form documents) and **when not to** (structured records), let's explore **how** to chunk effectively.\n",
    "\n",
    "**There's no single \"best\" strategy** - the optimal approach depends on:\n",
    "- Document structure (structured vs. unstructured)\n",
    "- Content type (text, tables, code, formulas)\n",
    "- Query patterns (specific facts vs. summaries)\n",
    "- Token budget (how much context can you afford?)\n",
    "\n",
    "We'll explore three core approaches with theoretical foundations and practical examples:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614da61dff520815",
   "metadata": {},
   "source": [
    "### Strategy 1: Document-Based Chunking (Structure-Aware)\n",
    "\n",
    "**ðŸŽ“ Theory:**\n",
    "\n",
    "Split documents based on their inherent structure (sections, paragraphs, headings) rather than arbitrary token counts.\n",
    "\n",
    "**Core Principle:** Respect semantic boundaries that authors created\n",
    "\n",
    "**How It Works:**\n",
    "1. Identify structural markers (markdown headers, section numbers, page breaks)\n",
    "2. Split at these boundaries\n",
    "3. Keep each section intact as a chunk\n",
    "4. Preserve context (headers, section titles)\n",
    "\n",
    "**Best For:**\n",
    "- Research papers with clear sections\n",
    "- Technical documentation with headers\n",
    "- Books with chapters/sections\n",
    "- Any document with explicit structure\n",
    "\n",
    "**Context Engineering Impact:**\n",
    "- âœ… Preserves semantic coherence (sections stay together)\n",
    "- âœ… Keeps tables, formulas, and code WITH their context\n",
    "- âœ… Natural alignment with query patterns (\"What does the methodology section say?\")\n",
    "- âš ï¸ Variable chunk sizes (some sections longer than others)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80043a9275a4d15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy 1: Document-Based Chunking\n",
    "# Split research paper by sections (using markdown headers)\n",
    "\n",
    "\n",
    "def chunk_by_structure(text: str, separator: str = \"\\n## \") -> List[str]:\n",
    "    \"\"\"\n",
    "    Split text by structural markers (e.g., markdown headers).\n",
    "\n",
    "    This respects the document's inherent organization, preserving\n",
    "    semantic boundaries created by the author.\n",
    "    \"\"\"\n",
    "    # Split by headers\n",
    "    sections = text.split(separator)\n",
    "\n",
    "    # Clean and format chunks\n",
    "    chunks = []\n",
    "    for i, section in enumerate(sections):\n",
    "        if section.strip():\n",
    "            # Add header back (except for first chunk which is title)\n",
    "            if i > 0:\n",
    "                chunk = \"## \" + section\n",
    "            else:\n",
    "                chunk = section\n",
    "            chunks.append(chunk.strip())\n",
    "\n",
    "    return chunks\n",
    "\n",
    "\n",
    "# Apply to research paper\n",
    "structure_chunks = chunk_by_structure(research_paper)\n",
    "\n",
    "print(f\"\"\"ðŸ“Š Strategy 1: Document-Based (Structure-Aware) Chunking\n",
    "{'=' * 80}\n",
    "Original document: {paper_tokens:,} tokens\n",
    "Number of chunks: {len(structure_chunks)}\n",
    "\n",
    "Chunk breakdown:\n",
    "\"\"\")\n",
    "\n",
    "for i, chunk in enumerate(structure_chunks[:5]):  # Show first 5\n",
    "    chunk_tokens = count_tokens(chunk)\n",
    "    # Show first 100 chars of each chunk\n",
    "    preview = chunk[:200].replace(\"\\n\", \" \")\n",
    "    print(f\"   Chunk {i+1}: {chunk_tokens:,} tokens - {preview}...\\n\")\n",
    "\n",
    "if len(structure_chunks) > 5:\n",
    "    print(f\"... ({len(structure_chunks) - 5} more chunks)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20641e01e62a9dea",
   "metadata": {},
   "source": [
    "**Strategy 1 Analysis:**\n",
    "\n",
    "âœ… **Advantages:**\n",
    "- **Semantic coherence**: Each chunk is a complete section with related content\n",
    "- **Context preservation**: Tables, formulas, and code stay WITH their explanations\n",
    "- **Query alignment**: Matches how users think about documents (\"What's in the methodology?\")\n",
    "- **Easy implementation**: Simple to implement for structured documents\n",
    "- **Author intent**: Respects the structure the author designed\n",
    "\n",
    "âš ï¸ **Trade-offs:**\n",
    "- **Variable sizes**: Some sections may be very long or very short\n",
    "- **Requires structure**: Only works for documents with clear structural markers\n",
    "- **May need refinement**: Very long sections might still need sub-chunking\n",
    "\n",
    "ðŸŽ¯ **Best Use Cases:**\n",
    "- Research papers with clear sections (Abstract, Introduction, Methods, Results)\n",
    "- Technical documentation with hierarchical headers\n",
    "- Books with chapters and subsections\n",
    "- Any document where structure aligns with semantic boundaries\n",
    "\n",
    "**Context Engineering Principle:**\n",
    "> Structure-aware chunking optimizes for **semantic completeness** - each chunk contains a complete thought or topic, minimizing the need for cross-chunk references.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15568e04b065366",
   "metadata": {},
   "source": [
    "### Strategy 2: Fixed-Size Chunking (Token-Based)\n",
    "\n",
    "**ðŸŽ“ Theory:**\n",
    "\n",
    "Split text into chunks of a predetermined size (e.g., 512 tokens) with overlap to preserve context across boundaries.\n",
    "\n",
    "**Core Principle:** Consistent, predictable chunk sizes for uniform processing\n",
    "\n",
    "**How It Works:**\n",
    "1. Define target chunk size (e.g., 800 characters, ~200 tokens)\n",
    "2. Define overlap (e.g., 100 characters) to preserve context\n",
    "3. Use smart separators (try paragraphs â†’ sentences â†’ words â†’ characters)\n",
    "4. Split text while respecting natural boundaries when possible\n",
    "\n",
    "**Best For:**\n",
    "- Unstructured text without clear sections\n",
    "- Quick prototyping and baselines\n",
    "- When consistent chunk sizes are required\n",
    "- Documents where structure doesn't align with semantics\n",
    "\n",
    "**Context Engineering Impact:**\n",
    "- âœ… Predictable token usage (easier to budget context)\n",
    "- âœ… Works on any text (structured or unstructured)\n",
    "- âœ… Smart boundary detection (doesn't split mid-sentence)\n",
    "- âš ï¸ May break semantic coherence (splits related content)\n",
    "- âš ï¸ Overlap creates redundancy (increases storage/cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8383618ac4c36d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy 2: Fixed-Size Chunking (Using LangChain)\n",
    "# Industry-standard approach with smart boundary detection\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Create text splitter with smart boundary detection\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=800,  # Target chunk size in characters\n",
    "    chunk_overlap=100,  # Overlap to preserve context\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],  # Try these in order\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "print(\"ðŸ”„ Running fixed-size chunking with LangChain...\")\n",
    "print(\"   Trying to split on: paragraphs â†’ sentences â†’ words â†’ characters\\n\")\n",
    "\n",
    "# Apply to research paper\n",
    "fixed_chunks_docs = text_splitter.create_documents([research_paper])\n",
    "fixed_chunks = [doc.page_content for doc in fixed_chunks_docs]\n",
    "\n",
    "print(f\"\"\"ðŸ“Š Strategy 2: Fixed-Size (LangChain) Chunking\n",
    "{'=' * 80}\n",
    "Original document: {paper_tokens:,} tokens\n",
    "Target chunk size: 800 characters (~200 words)\n",
    "Overlap: 100 characters\n",
    "Number of chunks: {len(fixed_chunks)}\n",
    "\n",
    "Chunk breakdown:\n",
    "\"\"\")\n",
    "\n",
    "for i, chunk in enumerate(fixed_chunks[:5]):  # Show first 5\n",
    "    chunk_tokens = count_tokens(chunk)\n",
    "    preview = chunk[:100].replace(\"\\n\", \" \")\n",
    "    print(f\"   Chunk {i+1}: {chunk_tokens:,} tokens - {preview}...\")\n",
    "\n",
    "print(f\"... ({len(fixed_chunks) - 5} more chunks)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac14dc0c132fde91",
   "metadata": {},
   "source": [
    "**Strategy 2 Analysis:**\n",
    "\n",
    "âœ… **Advantages:**\n",
    "- **Consistent sizes**: Predictable token usage for context budgeting\n",
    "- **Universal applicability**: Works on any text, structured or not\n",
    "- **Smart boundaries**: Tries to split at natural points (paragraphs, sentences)\n",
    "- **Overlap**: Preserves context across chunk boundaries\n",
    "- **Battle-tested**: Industry-standard approach with proven libraries\n",
    "\n",
    "âš ï¸ **Trade-offs:**\n",
    "- **Ignores structure**: Doesn't understand document organization\n",
    "- **May break coherence**: Can split related content (table from caption, formula from explanation)\n",
    "- **Redundancy**: Overlap increases storage and processing costs\n",
    "- **Arbitrary boundaries**: Splits based on size, not semantics\n",
    "\n",
    "ðŸŽ¯ **Best Use Cases:**\n",
    "- Unstructured text (novels, articles without clear sections)\n",
    "- Quick prototyping and baseline implementations\n",
    "- When you need consistent chunk sizes for processing\n",
    "- Documents where structure doesn't provide semantic boundaries\n",
    "\n",
    "**Context Engineering Principle:**\n",
    "> Fixed-size chunking optimizes for **predictability** - you know exactly how much context each chunk will consume, making it easier to manage token budgets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0bb31379a1d03d",
   "metadata": {},
   "source": [
    "### Strategy 3: Semantic Chunking (Meaning-Based)\n",
    "\n",
    "**ðŸŽ“ Theory:**\n",
    "\n",
    "Split text based on semantic similarity using embeddings - create new chunks when topic changes significantly.\n",
    "\n",
    "**Core Principle:** Let meaning, not structure or size, determine boundaries\n",
    "\n",
    "**How It Works:**\n",
    "1. Split text into sentences or paragraphs\n",
    "2. Generate embeddings for each segment\n",
    "3. Calculate similarity between consecutive segments\n",
    "4. Create chunk boundaries where similarity drops (topic shift detected)\n",
    "5. Group similar consecutive segments into chunks\n",
    "\n",
    "**Best For:**\n",
    "- Dense academic text where topics shift gradually\n",
    "- Legal documents with complex clause relationships\n",
    "- Narratives and stories where semantic boundaries don't align with structure\n",
    "- Content where you want adaptive chunk sizes based on coherence\n",
    "\n",
    "**Context Engineering Impact:**\n",
    "- âœ… Meaning-aware: Chunks based on topic shifts, not arbitrary boundaries\n",
    "- âœ… Adaptive: Chunk sizes vary based on content coherence\n",
    "- âœ… Better retrieval: Each chunk is semantically focused\n",
    "- âœ… Free: Uses local embeddings (no API costs)\n",
    "- âš ï¸ Slower processing: Requires embedding generation for all segments\n",
    "- âš ï¸ Variable sizes: Harder to predict token usage\n",
    "- âš ï¸ May ignore structure: Doesn't respect document organization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a676f7918ea0315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy 3: Semantic Chunking (Using LangChain)\n",
    "# Industry-standard approach with local embeddings (no API costs!)\n",
    "\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "import os\n",
    "\n",
    "# Suppress tokenizer warnings\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Initialize local embeddings (no API costs!)\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    model_kwargs={\"device\": \"cpu\"},\n",
    "    encode_kwargs={\"normalize_embeddings\": True},\n",
    ")\n",
    "\n",
    "# Create semantic chunker with percentile-based breakpoint detection\n",
    "semantic_chunker = SemanticChunker(\n",
    "    embeddings=embeddings,\n",
    "    breakpoint_threshold_type=\"percentile\",  # Split at bottom 25% of similarities\n",
    "    breakpoint_threshold_amount=25,  # 25th percentile\n",
    "    buffer_size=1,  # Compare consecutive sentences\n",
    ")\n",
    "\n",
    "print(\"ðŸ”„ Running semantic chunking with LangChain...\")\n",
    "print(\"   Using local embeddings (sentence-transformers/all-MiniLM-L6-v2)\")\n",
    "print(\"   Breakpoint detection: 25th percentile of similarity scores\\n\")\n",
    "\n",
    "# Apply to research paper\n",
    "semantic_chunks_docs = semantic_chunker.create_documents([research_paper])\n",
    "\n",
    "# Extract text from Document objects\n",
    "semantic_chunks = [doc.page_content for doc in semantic_chunks_docs]\n",
    "\n",
    "print(f\"\"\"ðŸ“Š Strategy 3: Semantic (LangChain) Chunking\n",
    "{'=' * 80}\n",
    "Original document: {paper_tokens:,} tokens\n",
    "Number of chunks: {len(semantic_chunks)}\n",
    "\n",
    "Chunk breakdown:\n",
    "\"\"\")\n",
    "\n",
    "for i, chunk in enumerate(semantic_chunks[:5]):  # Show first 5\n",
    "    chunk_tokens = count_tokens(chunk)\n",
    "    preview = chunk[:100].replace(\"\\n\", \" \")\n",
    "    print(f\"   Chunk {i+1}: {chunk_tokens:,} tokens - {preview}...\")\n",
    "\n",
    "if len(semantic_chunks) > 5:\n",
    "    print(f\"... ({len(semantic_chunks) - 5} more chunks)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8433343be506821",
   "metadata": {},
   "source": [
    "**Strategy 3 Analysis:**\n",
    "\n",
    "âœ… **Advantages:**\n",
    "- **Meaning-aware**: Detects topic shifts using semantic similarity\n",
    "- **Adaptive boundaries**: Chunk sizes vary based on content coherence\n",
    "- **Better retrieval**: Each chunk is semantically focused on a single topic\n",
    "- **No API costs**: Uses local embeddings (sentence-transformers)\n",
    "- **Intelligent**: Understands when topics change, even without structural markers\n",
    "\n",
    "âš ï¸ **Trade-offs:**\n",
    "- **Slower processing**: Must generate embeddings for all segments\n",
    "- **Variable sizes**: Harder to predict token usage and budget\n",
    "- **May ignore structure**: Doesn't respect document organization (headers, sections)\n",
    "- **Requires tuning**: Threshold and buffer size affect results\n",
    "- **Computational cost**: More expensive than simple text splitting\n",
    "\n",
    "ðŸŽ¯ **Best Use Cases:**\n",
    "- Dense academic text where topics shift gradually\n",
    "- Legal documents with complex semantic relationships\n",
    "- Narratives and stories where structure doesn't indicate topic changes\n",
    "- Content where semantic coherence is more important than structure\n",
    "\n",
    "**Context Engineering Principle:**\n",
    "> Semantic chunking optimizes for **topical coherence** - each chunk focuses on a single topic or concept, maximizing the relevance of retrieved content.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6270c434d935f7f5",
   "metadata": {},
   "source": [
    "### ðŸ“Š Comparing Chunking Strategies: Decision Framework\n",
    "\n",
    "Now let's compare all three strategies side-by-side:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88470264560bc11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "{'=' * 80}\n",
    "CHUNKING STRATEGY COMPARISON\n",
    "{'=' * 80}\n",
    "\n",
    "Document: Research Paper ({paper_tokens:,} tokens)\n",
    "\n",
    "Strategy              | Chunks | Avg Size | Complexity | Best For\n",
    "--------------------- | ------ | -------- | ---------- | --------\n",
    "Document-Based        | {len(structure_chunks):>6} | {sum(count_tokens(c) for c in structure_chunks) // len(structure_chunks):>8} | Low        | Structured docs\n",
    "Fixed-Size            | {len(fixed_chunks):>6} | {sum(count_tokens(c) for c in fixed_chunks) // len(fixed_chunks):>8} | Low        | Unstructured text\n",
    "Semantic              | {len(semantic_chunks):>6} | {sum(count_tokens(c) for c in semantic_chunks) // len(semantic_chunks):>8} | High       | Dense academic text\n",
    "\n",
    "{'=' * 80}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42ee88c4fc99386",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ YOUR Chunking Decision Framework\n",
    "\n",
    "Chunking strategy is a **design choice** that depends on your specific context. There's no universal \"correct\" chunk size or strategy.\n",
    "\n",
    "**Step 1: Start with Document Type**\n",
    "\n",
    "| Document Type | Default Approach | Reasoning |\n",
    "|---------------|------------------|----------|\n",
    "| **Structured records** (courses, products, FAQs) | Don't chunk | Natural boundaries already exist |\n",
    "| **Long-form text** (papers, books, docs) | Consider chunking | May need retrieval precision |\n",
    "| **PDFs with visual layout** | Page-level or structure-based | Preserves tables, figures |\n",
    "| **Code** | Function/class boundaries | Semantic structure matters |\n",
    "| **Unstructured text** | Fixed-size with overlap | No clear structure to follow |\n",
    "\n",
    "**Step 2: Evaluate These Factors**\n",
    "\n",
    "1. **Semantic completeness:** Is each item self-contained?\n",
    "   - âœ… Yes â†’ Don't chunk (preserve natural boundaries)\n",
    "   - âŒ No â†’ Consider chunking strategy\n",
    "\n",
    "2. **Query patterns:** What will users ask?\n",
    "   - Specific facts â†’ Smaller, focused chunks help\n",
    "   - Summaries/overviews â†’ Larger chunks or hierarchical\n",
    "   - Mixed â†’ Consider hierarchical approach\n",
    "\n",
    "3. **Topic density:** How many distinct topics per document?\n",
    "   - Single topic â†’ Whole-document embedding often works\n",
    "   - Multiple distinct topics â†’ Chunking may improve precision\n",
    "\n",
    "4. **Document structure:** Does it have clear organization?\n",
    "   - âœ… Yes â†’ Document-based chunking\n",
    "   - âŒ No â†’ Fixed-size or semantic chunking\n",
    "\n",
    "5. **Content type:** What's in the document?\n",
    "   - Text-only â†’ Any strategy works\n",
    "   - Tables/formulas/code â†’ Structure-aware chunking (keep context together)\n",
    "\n",
    "**Step 3: Choose Your Strategy**\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ Decision Tree                                                â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                              â”‚\n",
    "â”‚ Is data already structured records? (courses, products)     â”‚\n",
    "â”‚   â”œâ”€ YES â†’ Don't chunk, use hierarchical pattern            â”‚\n",
    "â”‚   â””â”€ NO â†’ Continue                                           â”‚\n",
    "â”‚                                                              â”‚\n",
    "â”‚ Does document have clear structure? (sections, headers)     â”‚\n",
    "â”‚   â”œâ”€ YES â†’ Document-based chunking                           â”‚\n",
    "â”‚   â””â”€ NO â†’ Continue                                           â”‚\n",
    "â”‚                                                              â”‚\n",
    "â”‚ Do you need consistent chunk sizes?                         â”‚\n",
    "â”‚   â”œâ”€ YES â†’ Fixed-size chunking                               â”‚\n",
    "â”‚   â””â”€ NO â†’ Semantic chunking                                  â”‚\n",
    "â”‚                                                              â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "**Example Decisions:**\n",
    "\n",
    "| Domain | Data Characteristics | Decision | Why |\n",
    "|--------|---------------------|----------|-----|\n",
    "| **Course Catalog** | Small, self-contained records | **Don't chunk** | Each course is a complete retrieval unit |\n",
    "| **Research Papers** | Multi-section, dense topics | **Document-based** | Sections are natural semantic units |\n",
    "| **Support Tickets** | Single issue per ticket | **Don't chunk** | Already at optimal granularity |\n",
    "| **Legal Contracts** | Nested structure, many clauses | **Hierarchical + Structure-based** | Need both overview and clause-level detail |\n",
    "| **Novels** | Continuous narrative, no structure | **Semantic** | Topic shifts don't align with structure |\n",
    "| **Technical Docs** | Clear sections and subsections | **Document-based** | Structure aligns with semantics |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c008e4a475adf3e6",
   "metadata": {},
   "source": [
    "### ðŸ”‘ Key Takeaway: Part 3\n",
    "\n",
    "> **Ask \"What is my natural retrieval unit?\" before deciding on a chunking strategy. For many structured data use cases, the answer is \"don't chunk.\"**\n",
    "\n",
    "**Context Engineering Principles:**\n",
    "\n",
    "1. **Structure-aware chunking** â†’ Optimizes for semantic completeness\n",
    "2. **Fixed-size chunking** â†’ Optimizes for predictability\n",
    "3. **Semantic chunking** â†’ Optimizes for topical coherence\n",
    "\n",
    "**Choose based on:**\n",
    "- Your data characteristics\n",
    "- Your query patterns\n",
    "- Your token budget\n",
    "- Your quality requirements\n",
    "\n",
    "---\n",
    "\n",
    "## Part 4: Advanced Topics\n",
    "\n",
    "### ðŸŽ¨ Handling Multimodal Content\n",
    "\n",
    "**The Challenge:** Research papers and technical documents aren't just text - they contain:\n",
    "- **Tables** with structured data\n",
    "- **Formulas** with variable definitions\n",
    "- **Figures** with visual patterns\n",
    "- **Code** with implementation details\n",
    "\n",
    "Standard text chunking can break these elements, separating content from context.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c048faa4e017920d",
   "metadata": {},
   "source": [
    "### ðŸŽ“ Theory: Multimodal Chunking Principles\n",
    "\n",
    "**Core Principle:** Context is king - never separate content from explanation\n",
    "\n",
    "**1. Tables:**\n",
    "- **Problem**: Splitting table from caption loses meaning\n",
    "- **Solution**: Keep table WITH caption and surrounding explanation\n",
    "- **Implementation**: Detect table boundaries, include Â±200 chars of context\n",
    "\n",
    "**2. Formulas:**\n",
    "- **Problem**: Formula without variable definitions is useless\n",
    "- **Solution**: Keep formula WITH variable definitions and explanation\n",
    "- **Implementation**: Include surrounding context (Â±200 chars)\n",
    "\n",
    "**3. Figures:**\n",
    "- **Problem**: Figure reference without description is incomplete\n",
    "- **Solution**: Describe visual patterns in text, keep WITH caption\n",
    "- **Implementation**: Extract caption and discussion together\n",
    "\n",
    "**4. Code:**\n",
    "- **Problem**: Code snippet without usage example is hard to understand\n",
    "- **Solution**: Keep code WITH usage examples and context\n",
    "- **Implementation**: Include function/class definitions with docstrings\n",
    "\n",
    "**Context Engineering Impact:**\n",
    "\n",
    "Without multimodal awareness:\n",
    "```\n",
    "Chunk 1: \"...as shown in Table 1.\"\n",
    "Chunk 2: [Table 1 data]\n",
    "Chunk 3: \"The results indicate...\"\n",
    "\n",
    "Problem: Table separated from context\n",
    "Result: LLM can't interpret table meaning\n",
    "```\n",
    "\n",
    "With multimodal awareness:\n",
    "```\n",
    "Chunk: \"...as shown in Table 1. [Table 1 data] The results indicate...\"\n",
    "\n",
    "Benefit: Table WITH context\n",
    "Result: LLM understands table meaning and implications\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d572af71ac753578",
   "metadata": {},
   "source": [
    "### ðŸ“Š Practical Example: Chunking Multimodal Content\n",
    "\n",
    "Let's see how to handle different content types from our research paper:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a882664e02864932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Example 1: Extract and chunk a table with context\n",
    "table_pattern = r'(Table \\d+:.*?)(?=\\n\\n[A-Z]|\\nFigure|\\n\\d+\\.|\\Z)'\n",
    "tables_found = re.findall(table_pattern, research_paper, re.DOTALL)\n",
    "\n",
    "if tables_found:\n",
    "    table_chunk = {\n",
    "        \"content_type\": \"table\",\n",
    "        \"text\": tables_found[0][:500],  # First 500 chars\n",
    "        \"metadata\": {\n",
    "            \"page\": \"6\",\n",
    "            \"section\": \"Evaluation\",\n",
    "            \"table_id\": \"Table 1\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    print(\"âœ… TABLE CHUNKING EXAMPLE:\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Content Type: {table_chunk['content_type']}\")\n",
    "    print(f\"Metadata: {table_chunk['metadata']}\")\n",
    "    print(f\"\\nChunk Text:\\n{table_chunk['text'][:300]}...\")\n",
    "    print(\"\\nâœ… Best Practice: Keep table WITH caption and surrounding context\")\n",
    "else:\n",
    "    print(\"Table extraction pattern needs adjustment for this PDF\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b812763fb907bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Extract and chunk formulas with context\n",
    "formula_pattern = r'(loss.*?=.*?(?:\\n|$))'\n",
    "formulas = re.findall(formula_pattern, research_paper, re.IGNORECASE)\n",
    "\n",
    "if formulas:\n",
    "    # Find context around the formula\n",
    "    formula_text = formulas[0]\n",
    "    formula_idx = research_paper.find(formula_text)\n",
    "    context_start = max(0, formula_idx - 200)\n",
    "    context_end = min(len(research_paper), formula_idx + len(formula_text) + 200)\n",
    "\n",
    "    formula_chunk = {\n",
    "        \"content_type\": \"formula\",\n",
    "        \"text\": research_paper[context_start:context_end],\n",
    "        \"metadata\": {\n",
    "            \"section\": \"Methodology\",\n",
    "            \"formula_type\": \"contrastive_loss\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    print(\"\\nâœ… FORMULA CHUNKING EXAMPLE:\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Content Type: {formula_chunk['content_type']}\")\n",
    "    print(f\"Metadata: {formula_chunk['metadata']}\")\n",
    "    print(f\"\\nChunk Text:\\n{formula_chunk['text'][:300]}...\")\n",
    "    print(\"\\nâœ… Best Practice: Keep formula WITH variable definitions and explanation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6702d3b8f05d8543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary: Multimodal chunking principles\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"MULTIMODAL CHUNKING PRINCIPLES:\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\"\"\n",
    "1. **Tables**: Keep WITH caption and explanation\n",
    "   - Preserve structure (markdown/HTML)\n",
    "   - Add metadata: table_id, section, content_type\n",
    "\n",
    "2. **Formulas**: Keep WITH variable definitions\n",
    "   - Include surrounding context (Â±200 chars)\n",
    "   - Preserve LaTeX if available\n",
    "\n",
    "3. **Figures**: Describe visual patterns in text\n",
    "   - Keep caption WITH discussion\n",
    "   - Add metadata: figure_id, visual_type\n",
    "\n",
    "4. **Code**: Keep WITH usage examples and context\n",
    "   - Preserve syntax and comments\n",
    "   - Include function/class definitions\n",
    "\n",
    "5. **General Rule**: Context is king - never separate content from explanation\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bba65384dbe10d",
   "metadata": {},
   "source": [
    "### ðŸ›ï¸ Advanced Topic: Complex Documents (Legal Contracts)\n",
    "\n",
    "**Note:** Some document types require approaches beyond chunking.\n",
    "\n",
    "**Why Legal Documents Are Different:**\n",
    "\n",
    "Legal contracts require sophisticated data engineering beyond simple chunking:\n",
    "\n",
    "**Key Challenges:**\n",
    "1. **Clause-level granularity** with hierarchical numbering (Section 3.2.1)\n",
    "2. **Cross-references** between clauses (\"as defined in Section 1.5...\")\n",
    "3. **Hierarchical dependencies** (amendments modify earlier provisions)\n",
    "4. **Legal precedence** (\"Notwithstanding Section 2.1...\" creates overrides)\n",
    "\n",
    "**What This Requires:**\n",
    "\n",
    "Simple chunking is insufficient. You need:\n",
    "- **Knowledge graphs** to capture clause relationships\n",
    "- **Recursive retrieval** to fetch referenced clauses\n",
    "- **Metadata enrichment** (clause type, parties, dates, jurisdiction)\n",
    "\n",
    "**Example Retrieval Flow:**\n",
    "```\n",
    "Query: \"What are the payment terms?\"\n",
    "\n",
    "1. Retrieve: Clause 3.2 (Payment Terms)\n",
    "2. Detect reference: \"as defined in Section 1.5\"\n",
    "3. Fetch: Clause 1.5 (Definitions: \"Net 30\")\n",
    "4. Detect modification: Clause 8.1 modifies 3.2\n",
    "5. Fetch: Clause 8.1 (Amendment: \"Net 45 for Q4\")\n",
    "6. Assemble: [3.2 + 1.5 + 8.1] with relationship metadata\n",
    "```\n",
    "\n",
    "**Recommendation:** This is a **research-level problem** requiring domain expertise. For production systems:\n",
    "- Start with clause-level chunking as baseline\n",
    "- Build knowledge graphs for relationships (Neo4j, etc.)\n",
    "- Implement recursive retrieval for dependencies\n",
    "- Consider specialized legal NLP tools (LexNLP, Blackstone)\n",
    "\n",
    "**Resources:**\n",
    "- [Multi-Graph Multi-Agent Systems](https://medium.com/enterprise-rag/legal-document-rag-multi-graph-multi-agent-recursive-retrieval-through-legal-clauses-c90e073e0052)\n",
    "- [GraphRAG for Contracts](https://neo4j.com/blog/developer/agentic-graphrag-for-commercial-contracts/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a551fb7424d9e81b",
   "metadata": {},
   "source": [
    "### ðŸ”§ Troubleshooting Common Chunking Failures\n",
    "\n",
    "**Common Failure Patterns and Solutions:**\n",
    "\n",
    "| Problem | Likely Cause | Solution |\n",
    "|---------|--------------|----------|\n",
    "| **Tables split across chunks** | Fixed-size chunking | Use structure-aware chunking |\n",
    "| **Formulas without context** | Naive chunking | Keep formulas with explanations |\n",
    "| **Missing cross-references** | Single-chunk retrieval | Implement recursive retrieval |\n",
    "| **Generic answers** | Chunks too large | Reduce chunk size or use semantic chunking |\n",
    "| **Incomplete answers** | Chunks too small | Increase chunk size or add overlap |\n",
    "| **Poor retrieval precision** | Wrong chunking strategy | Re-evaluate natural retrieval unit |\n",
    "| **High token costs** | No chunking on long docs | Implement appropriate chunking |\n",
    "| **Fragmented information** | Over-chunking structured data | Don't chunk, use hierarchical pattern |\n",
    "\n",
    "**Iterative Process:**\n",
    "1. Start simple (baseline strategy)\n",
    "2. Measure performance (retrieval quality, token usage)\n",
    "3. Identify failures (what queries fail? why?)\n",
    "4. Test improvements (try different strategies)\n",
    "5. Iterate (refine based on results)\n",
    "\n",
    "**Context Engineering Principle:**\n",
    "> Chunking is an iterative engineering process, not a one-time decision. Monitor, measure, and refine based on real-world performance.\n",
    "\n",
    "---\n",
    "\n",
    "## Part 5: Context Engineering Principles\n",
    "\n",
    "### ðŸŽ¯ How Data Engineering Affects Context Quality\n",
    "\n",
    "Every data engineering decision directly impacts what information reaches the LLM. Let's understand the connections:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6777c27f1b6199e9",
   "metadata": {},
   "source": [
    "### ðŸ“Š The Context Engineering Stack\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ Layer 5: LLM Response                                       â”‚\n",
    "â”‚ - Quality depends on context quality                        â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                            â†‘\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ Layer 4: Context Assembly                                   â”‚\n",
    "â”‚ - Combine retrieved chunks into coherent context            â”‚\n",
    "â”‚ - Order matters (Lost in the Middle)                        â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                            â†‘\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ Layer 3: Retrieval                                          â”‚\n",
    "â”‚ - Semantic search finds relevant chunks                     â”‚\n",
    "â”‚ - Quality depends on chunk granularity                      â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                            â†‘\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ Layer 2: Chunking Strategy â† YOU ARE HERE                  â”‚\n",
    "â”‚ - How you split documents affects retrieval precision       â”‚\n",
    "â”‚ - Chunk size affects token efficiency                       â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                            â†‘\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ Layer 1: Data Modeling                                      â”‚\n",
    "â”‚ - Natural retrieval units                                   â”‚\n",
    "â”‚ - Hierarchical patterns                                     â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "**Key Insight:** Data engineering decisions at Layer 1-2 cascade through the entire stack, affecting final response quality.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf845dfa5cbe405",
   "metadata": {},
   "source": [
    "### ðŸ”‘ Core Context Engineering Principles\n",
    "\n",
    "**Principle 1: Precision Over Completeness**\n",
    "\n",
    "```\n",
    "Bad: Retrieve entire 6,000-token document\n",
    "Good: Retrieve 500-token relevant section\n",
    "\n",
    "Why: Context Rot - irrelevant content actively hurts performance\n",
    "```\n",
    "\n",
    "**Principle 2: Semantic Boundaries Over Arbitrary Boundaries**\n",
    "\n",
    "```\n",
    "Bad: Split mid-table because chunk size limit reached\n",
    "Good: Keep table with caption, even if chunk is larger\n",
    "\n",
    "Why: Semantic completeness - content needs context to be useful\n",
    "```\n",
    "\n",
    "**Principle 3: Natural Units Over Forced Chunking**\n",
    "\n",
    "```\n",
    "Bad: Chunk course catalog into smaller pieces\n",
    "Good: Keep each course as a complete unit\n",
    "\n",
    "Why: Natural retrieval units - data already at optimal granularity\n",
    "```\n",
    "\n",
    "**Principle 4: Structure-Aware Over Structure-Blind**\n",
    "\n",
    "```\n",
    "Bad: Fixed-size chunking on research paper with clear sections\n",
    "Good: Document-based chunking that respects section boundaries\n",
    "\n",
    "Why: Author intent - structure often aligns with semantic boundaries\n",
    "```\n",
    "\n",
    "**Principle 5: Measure, Don't Assume**\n",
    "\n",
    "```\n",
    "Bad: \"512 tokens is the best chunk size\" (universal rule)\n",
    "Good: Test different strategies on YOUR data with YOUR queries\n",
    "\n",
    "Why: Context is domain-specific - what works for one use case may fail for another\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa23761f5c53b321",
   "metadata": {},
   "source": [
    "### ðŸ“ˆ Token Efficiency vs. Retrieval Precision\n",
    "\n",
    "Understanding the trade-off between token efficiency and retrieval precision:\n",
    "\n",
    "**Scenario 1: No Chunking (Long Documents)**\n",
    "\n",
    "```\n",
    "Document: 6,000 tokens\n",
    "Query: \"What is the methodology?\"\n",
    "Retrieved: Entire document (6,000 tokens)\n",
    "\n",
    "Token Efficiency: âŒ Low (5,500 irrelevant tokens)\n",
    "Retrieval Precision: âŒ Low (90% irrelevant content)\n",
    "Answer Quality: âŒ Poor (LLM must filter noise)\n",
    "```\n",
    "\n",
    "**Scenario 2: Over-Chunking (Structured Records)**\n",
    "\n",
    "```\n",
    "Course: 200 tokens\n",
    "Chunked into: 4 chunks of 50 tokens each\n",
    "Query: \"Tell me about CS101\"\n",
    "Retrieved: 2-3 chunks (100-150 tokens)\n",
    "\n",
    "Token Efficiency: âš ï¸ Medium (some fragmentation)\n",
    "Retrieval Precision: âŒ Low (missing related info)\n",
    "Answer Quality: âŒ Poor (incomplete information)\n",
    "```\n",
    "\n",
    "**Scenario 3: Optimal Chunking (Research Paper)**\n",
    "\n",
    "```\n",
    "Document: 6,000 tokens\n",
    "Chunked into: 12 sections (~500 tokens each)\n",
    "Query: \"What is the methodology?\"\n",
    "Retrieved: Methodology section (500 tokens)\n",
    "\n",
    "Token Efficiency: âœ… High (only relevant content)\n",
    "Retrieval Precision: âœ… High (exact section needed)\n",
    "Answer Quality: âœ… Excellent (focused, complete)\n",
    "```\n",
    "\n",
    "**Scenario 4: Hierarchical Pattern (Structured Records)**\n",
    "\n",
    "```\n",
    "Catalog: 100 courses Ã— 200 tokens = 20,000 tokens\n",
    "Hierarchical: 100 summaries (150 tokens) + 3 details (600 tokens)\n",
    "Query: \"Beginner programming courses\"\n",
    "Retrieved: 5 summaries + 3 details = 1,350 tokens\n",
    "\n",
    "Token Efficiency: âœ… High (93% reduction)\n",
    "Retrieval Precision: âœ… High (relevant courses)\n",
    "Answer Quality: âœ… Excellent (complete, focused)\n",
    "```\n",
    "\n",
    "**The Sweet Spot:**\n",
    "\n",
    "```\n",
    "Optimal Chunking = Maximum Retrieval Precision + Minimum Token Waste\n",
    "\n",
    "Achieved by:\n",
    "1. Understanding natural retrieval units\n",
    "2. Choosing appropriate chunking strategy\n",
    "3. Preserving semantic completeness\n",
    "4. Measuring and iterating\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc992e07a5b5909b",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ Production-Ready Decision Framework\n",
    "\n",
    "**Step-by-Step Process for Production Systems:**\n",
    "\n",
    "**1. Analyze Your Data**\n",
    "```python\n",
    "Questions to ask:\n",
    "- What is the natural retrieval unit?\n",
    "- How many distinct topics per document?\n",
    "- Does structure align with semantics?\n",
    "- What content types exist? (text, tables, code, formulas)\n",
    "```\n",
    "\n",
    "**2. Understand Your Query Patterns**\n",
    "```python\n",
    "Questions to ask:\n",
    "- What will users ask?\n",
    "- Do queries target specific sections or whole documents?\n",
    "- How precise do answers need to be?\n",
    "- What's the acceptable token budget?\n",
    "```\n",
    "\n",
    "**3. Choose Initial Strategy**\n",
    "```python\n",
    "Decision tree:\n",
    "if structured_records:\n",
    "    strategy = \"hierarchical_pattern\"  # Don't chunk\n",
    "elif has_clear_structure:\n",
    "    strategy = \"document_based\"  # Chunk by sections\n",
    "elif need_consistent_sizes:\n",
    "    strategy = \"fixed_size\"  # Chunk by tokens\n",
    "else:\n",
    "    strategy = \"semantic\"  # Chunk by meaning\n",
    "```\n",
    "\n",
    "**4. Implement and Measure**\n",
    "```python\n",
    "Metrics to track:\n",
    "- Retrieval precision (% relevant chunks retrieved)\n",
    "- Token efficiency (avg tokens per query)\n",
    "- Answer quality (human eval or LLM-as-judge)\n",
    "- Latency (time to retrieve and process)\n",
    "```\n",
    "\n",
    "**5. Iterate and Refine**\n",
    "```python\n",
    "Optimization loop:\n",
    "1. Identify failure cases\n",
    "2. Analyze root causes\n",
    "3. Test alternative strategies\n",
    "4. Measure improvements\n",
    "5. Deploy and monitor\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2687271c9ff754",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary and Key Takeaways\n",
    "\n",
    "### ðŸŽ¯ The Core Insight\n",
    "\n",
    "> **Chunking isn't about fitting in context windows - it's about data modeling for retrieval.**\n",
    "\n",
    "Just like database schema design, how you structure your knowledge base dramatically affects retrieval quality, token efficiency, and system performance.\n",
    "\n",
    "### ðŸ“š Key Concepts Covered\n",
    "\n",
    "**1. The Critical First Question**\n",
    "- What is my natural retrieval unit?\n",
    "- Many structured data types don't need chunking\n",
    "- Chunking is a design choice, not a default step\n",
    "\n",
    "**2. When NOT to Chunk**\n",
    "- Structured records (courses, products, FAQs)\n",
    "- Self-contained units with natural boundaries\n",
    "- Data already at optimal granularity\n",
    "- Use hierarchical patterns instead\n",
    "\n",
    "**3. When Chunking Helps**\n",
    "- Long-form documents with multiple topics\n",
    "- Research papers, technical docs, books\n",
    "- Improves retrieval precision (8-12x reduction in irrelevant context)\n",
    "- Reduces token costs and improves answer quality\n",
    "\n",
    "**4. Core Chunking Strategies**\n",
    "- **Document-Based**: Split by structure (sections, headers)\n",
    "  - Best for: Structured documents with clear organization\n",
    "  - Optimizes for: Semantic completeness\n",
    "- **Fixed-Size**: Split by token count with overlap\n",
    "  - Best for: Unstructured text, consistent sizes needed\n",
    "  - Optimizes for: Predictability\n",
    "- **Semantic**: Split by topic shifts using embeddings\n",
    "  - Best for: Dense academic text, adaptive boundaries\n",
    "  - Optimizes for: Topical coherence\n",
    "\n",
    "**5. Advanced Topics**\n",
    "- Multimodal content (tables, formulas, figures)\n",
    "- Complex documents (legal contracts, knowledge graphs)\n",
    "- Troubleshooting common failures\n",
    "\n",
    "**6. Context Engineering Principles**\n",
    "- Precision over completeness\n",
    "- Semantic boundaries over arbitrary boundaries\n",
    "- Natural units over forced chunking\n",
    "- Structure-aware over structure-blind\n",
    "- Measure, don't assume\n",
    "\n",
    "### ðŸŽ“ Decision Framework Summary\n",
    "\n",
    "| Question | Answer | Strategy |\n",
    "|----------|--------|----------|\n",
    "| **What is my natural retrieval unit?** | Single record (course, product, FAQ) | Don't chunk - use hierarchical patterns |\n",
    "| | Long-form document (paper, book) | Chunk by sections or semantically |\n",
    "| | Legal contract with cross-references | Advanced: knowledge graphs + recursive retrieval |\n",
    "| **How many topics per document?** | Single topic | Whole-document embedding |\n",
    "| | Multiple distinct topics | Chunking improves precision |\n",
    "| **What content types?** | Text-only | Standard chunking strategies |\n",
    "| | Multimodal (tables, figures) | Keep content WITH context |\n",
    "| **Does structure align with semantics?** | Yes | Document-based chunking |\n",
    "| | No | Fixed-size or semantic chunking |\n",
    "\n",
    "### ðŸ’¡ Remember\n",
    "\n",
    "**This is engineering, not magic:**\n",
    "- Start with understanding your data\n",
    "- Choose strategy based on characteristics\n",
    "- Implement and measure\n",
    "- Iterate based on results\n",
    "- There's no universal \"best\" approach\n",
    "\n",
    "**Context engineering is about:**\n",
    "- Controlling what information reaches the LLM\n",
    "- Maximizing retrieval precision\n",
    "- Minimizing irrelevant tokens\n",
    "- Preserving semantic completeness\n",
    "\n",
    "---\n",
    "\n",
    "## What's Next?\n",
    "\n",
    "### Module 4: Memory Systems for Context Engineering\n",
    "\n",
    "Now that you understand data modeling and chunking for knowledge bases, you'll learn to manage conversation context:\n",
    "- **Working Memory**: Track conversation history within a session\n",
    "- **Long-term Memory**: Remember user preferences across sessions\n",
    "- **Memory-Enhanced RAG**: Combine retrieved knowledge with conversation memory\n",
    "- **Redis Agent Memory Server**: Automatic memory extraction and retrieval\n",
    "\n",
    "```\n",
    "Module 1: Context Engineering Fundamentals\n",
    "    â†“\n",
    "Module 2: RAG Fundamentals\n",
    "    â†“\n",
    "Module 3: Chunking and Data Modeling â† You are here\n",
    "    â†“\n",
    "Module 4: Memory Systems â† Next\n",
    "    â†“\n",
    "Module 5: Building Agents (Complete System)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Practice Exercises\n",
    "\n",
    "### Exercise 1: Analyze Your Data\n",
    "Think about a dataset you work with. Answer these questions:\n",
    "1. What is the natural retrieval unit?\n",
    "2. Does it need chunking? Why or why not?\n",
    "3. If yes, which chunking strategy would you use?\n",
    "\n",
    "### Exercise 2: Design a Chunking Strategy\n",
    "For each document type, choose the best approach:\n",
    "1. Product catalog with 1,000 items\n",
    "2. 50-page technical manual with chapters\n",
    "3. Customer support tickets (avg 200 words each)\n",
    "4. Legal contracts (avg 20 pages, multiple clauses)\n",
    "\n",
    "### Exercise 3: Experiment with Chunking\n",
    "Take the research paper example and:\n",
    "1. Try all three chunking strategies\n",
    "2. Compare the number of chunks and average size\n",
    "3. Which strategy would work best for queries about \"semantic caching methodology\"?\n",
    "\n",
    "---\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "**Chunking Strategies:**\n",
    "- [LangChain Text Splitters](https://python.langchain.com/docs/modules/data_connection/document_transformers/)\n",
    "- [LlamaIndex Node Parsers](https://docs.llamaindex.ai/en/stable/module_guides/loading/node_parsers/)\n",
    "\n",
    "**Research Papers:**\n",
    "- [\"Lost in the Middle\" (arXiv:2307.03172)](https://arxiv.org/abs/2307.03172) - U-shaped attention patterns in LLMs\n",
    "- [\"Context Rot\" (Chroma Research, 2025)](https://research.trychroma.com/context-rot) - Performance degradation with input length\n",
    "- [Needle in the Haystack Benchmark](https://github.com/gkamradt/LLMTest_NeedleInAHaystack) - Retrieval in long contexts\n",
    "- [\"Contextual Retrieval\" (Anthropic, 2024)](https://www.anthropic.com/news/contextual-retrieval) - 49-67% reduction in retrieval failures\n",
    "- [\"Advancing Semantic Caching for LLMs\" (arXiv:2504.02268)](https://arxiv.org/abs/2504.02268) - Redis/Virginia Tech research\n",
    "\n",
    "**Advanced Topics:**\n",
    "- [Multi-Graph Multi-Agent Systems for Legal Documents](https://medium.com/enterprise-rag/legal-document-rag-multi-graph-multi-agent-recursive-retrieval-through-legal-clauses-c90e073e0052)\n",
    "- [GraphRAG for Commercial Contracts](https://neo4j.com/blog/developer/agentic-graphrag-for-commercial-contracts/)\n",
    "\n",
    "**Vector Databases:**\n",
    "- [Redis Vector Search Documentation](https://redis.io/docs/stack/search/reference/vectors/)\n",
    "- [RedisVL Python Library](https://github.com/RedisVentures/redisvl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df86351fbf2fe01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
