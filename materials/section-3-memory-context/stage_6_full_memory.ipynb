{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6eb681b1",
   "metadata": {},
   "source": [
    "# Stage 6: Full Memory - Long-Term Memory Tools for Cross-Session Personalization\n",
    "\n",
    "## Introduction\n",
    "\n",
    "At the end of Stage 5, we witnessed something interesting: RAMS was quietly extracting facts from every conversation turn and storing them in long-term memory. The compression ratios were impressive! 750 tokens of conversation distilled into 50 tokens of knowledge. But there was a catch. Our agent couldn't *use* any of it.\n",
    "\n",
    "All that accumulated knowledge of student preferences, past questions, and expressed interests sat in long-term memory. This creates a frustrating scenario:\n",
    "\n",
    "**Session 1:**  \n",
    "üë§ \"I prefer online courses and I'm interested in machine learning.\"  \n",
    "ü§ñ \"Great! Let me search for ML courses...\"  \n",
    "*(RAMS extracts and stores: \"Student prefers online courses\", \"Student interested in ML\")*\n",
    "\n",
    "**[User returns the next day and starts a new session]**\n",
    "\n",
    "**Session 2:**  \n",
    "üë§ \"What courses would you recommend for me?\"  \n",
    "ü§ñ \"I'm not sure what you're looking for. Could you tell me your preferences?\"  \n",
    "*(The knowledge exists in long-term memory... but the agent can't reach it)*\n",
    "\n",
    "The current version of our agent has amnesia despite having a full memory system. Stage 5 gave us the infrastructure, and now we need to give the agent the tools to actually use it.\n",
    "\n",
    "Once the agent has been completed with long-term memory tools, the architecture will look like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e613a4",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "graph TD\n",
    "    Q[Query] --> LM[Load Working Memory]\n",
    "    LM --> IC[Classify Intent]\n",
    "    IC -->|GREETING| HG[Handle Greeting]\n",
    "    IC -->|Other| RA[ReAct Agent]\n",
    "\n",
    "    subgraph ReAct Loop\n",
    "        RA --> T1[üí≠ Thought: Analyze + plan]\n",
    "        T1 --> A1[üîß Action: choose tool]\n",
    "        A1 --> O1[üëÅÔ∏è Observation: Results]\n",
    "        O1 --> T2[üí≠ Thought: Evaluate]\n",
    "        T2 --> |Need more| A1\n",
    "        T2 --> |Done| F[‚úÖ FINISH]\n",
    "    end\n",
    "\n",
    "    subgraph Available Tools\n",
    "        A1 -->|search| SC[search_courses]\n",
    "        A1 -->|store| SM[store_memory]\n",
    "        A1 -->|recall| RM[search_memories]\n",
    "    end\n",
    "\n",
    "    F --> SAV[Save Working Memory]\n",
    "    HG --> SAV\n",
    "    SAV --> END[Response + Reasoning Trace]\n",
    "\n",
    "    subgraph Memory Layer\n",
    "        LM -.->|Read| AMS[(Agent Memory Server)]\n",
    "        SAV -.->|Write| AMS\n",
    "        SM -.->|Write| LTM[(Long-term Memory)]\n",
    "        RM -.->|Read| LTM\n",
    "    end\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f08f7ce",
   "metadata": {},
   "source": [
    "Now, before diving into managing long-term memory, let's first explore the different types of long-term memory available via the Agent Memory Server. \n",
    "\n",
    "### Types of Long-Term Memory\n",
    "\n",
    "If you look back at the result of the long-term memory query in the previous stage, you'll notice a `memory_type` field indicating how that information was stored: \n",
    "\n",
    "```md\n",
    "CS001 is taught by Allison Hill.\n",
    "   Topics: education, instructor\n",
    "   **Type: MemoryTypeEnum.SEMANTIC**\n",
    "   Created: 2026-01-13 18:31:04.408673+00:00\n",
    "```\n",
    "\n",
    "`SEMANTIC` is one of three memory types available in the Agent Memory Server. The other two are episodic, and message. Let's review each of them to explore what their role is and when to use them:\n",
    "\n",
    "#### Semantic memory\n",
    "\n",
    "This type of memory (the default for AMS) stores timeless facts and preferences. Things like \"Student prefers online courses\" or \"CS401 requires CS201 as a prerequisite\" are examples of semantic memories. They can be user-scoped (personalizing for a specific student) or application-scoped (domain knowledge for everyone). These types of memories are compact and searchable, making them the default choice for most information.\n",
    "\n",
    "#### Episodic memory\n",
    "\n",
    "This type of memory captures time-bound events where sequence matters. Things like \"Student enrolled in CS101 on 2024-09-15\" or \"Completed CS101 with grade A\" are episodic memories. This type of memory is most useful when the timeline or temporal progression is meaningful.\n",
    "\n",
    "#### Message memory  \n",
    "\n",
    "This type of memory stores full conversation snippets where the complete context is crucial. This preserves detailed discussions, nuanced advice, or explanations that would be lost if summarized. However, message memories are token-expensive and should be used sparingly.\n",
    "\n",
    "<details >  \n",
    "  <summary> üí° Click the dropdown to see a few examples of correct memory type decisions </summary>\n",
    "\n",
    "### Scenario 1: Student States Preference\n",
    "\n",
    "**User says:** \"I prefer online courses because I work during the day.\"\n",
    "\n",
    "‚ùå **Wrong - Message memory (too verbose):**\n",
    "\n",
    "```python\n",
    "\n",
    "memory = \"Student said: 'I prefer online courses because I work during the day.'\"\n",
    "\n",
    "```\n",
    "\n",
    "‚úÖ **Right - Semantic memories (extracted facts):**\n",
    "\n",
    "```python\n",
    "\n",
    "memory1 = \"Student prefers online courses\"\n",
    "memory2 = \"Student works during the day\"\n",
    "\n",
    "```\n",
    "\n",
    "**Why:** Simple facts don't need verbatim storage.\n",
    "\n",
    "---\n",
    "\n",
    "### Scenario 2: Course Completion\n",
    "\n",
    "**User says:** \"I just finished CS101 last week!\"\n",
    "\n",
    "‚ùå **Wrong - Semantic (loses temporal context):**\n",
    "\n",
    "```python\n",
    "\n",
    "memory = \"Student completed CS101\"\n",
    "\n",
    "```\n",
    "\n",
    "‚úÖ **Right - Episodic (preserves timeline):**\n",
    "\n",
    "```python\n",
    "\n",
    "memory = \"Student completed CS101 on 2024-10-20\"\n",
    "\n",
    "```\n",
    "\n",
    "**Why:** Timeline matters for prerequisites and future planning.\n",
    "\n",
    "---\n",
    "\n",
    "### Scenario 3: Complex Career Advice\n",
    "\n",
    "**Context:** 20-message discussion about career path, including nuanced advice about research vs. industry, application timing, and specific companies to target.\n",
    "\n",
    "‚ùå **Wrong - Semantic (loses too much context):**\n",
    "\n",
    "```python\n",
    "\n",
    "memory = \"Student discussed career planning\"\n",
    "\n",
    "```\n",
    "\n",
    "‚úÖ **Right - Message memory (preserves full context):**\n",
    "```python\n",
    "memory = [Full conversation thread with all nuance]\n",
    "```\n",
    "\n",
    "**Why:** Details and context are critical; summary would be inadequate.\n",
    "\n",
    "</details>\n",
    "\n",
    "Now that you're familiar with the types of memory, let's begin by setting up our environment and examining the production code that supports this stage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f1e072",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Run the code block below to initialize the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894e5b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "project_root = Path(\"..\").resolve()\n",
    "\n",
    "stage6_path = project_root / \"progressive_agents\" / \"stage6_full_memory\"\n",
    "src_path = project_root / \"src\"\n",
    "\n",
    "load_dotenv(project_root / \".env\")\n",
    "\n",
    "sys.path.insert(0, str(src_path))\n",
    "sys.path.insert(0, str(stage6_path))\n",
    "\n",
    "from agent import setup_agent, create_workflow, WorkflowState, get_memory_client, MemoryMessage, WorkingMemory, run_agent_async\n",
    "\n",
    "print(\"Initializing Stage 6 Agent...\")\n",
    "course_manager, _ = await setup_agent(auto_load_courses=True)\n",
    "workflow = create_workflow(course_manager)\n",
    "print(\"‚úÖ Agent initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8526c8",
   "metadata": {},
   "source": [
    "### Implementation Overview\n",
    "\n",
    "As mentioned, this stage is all about giving our agent the ability to manage long-term memory via tools. In oder for this to happen, we'll build two tools: \n",
    "\n",
    "1. `search_memories` - This tool will search the long-term memory for relevant facts, preferences, and past interactions.\n",
    "2. `store_memory` - This tool will store important information to the student's long-term memory explicitly.\n",
    "\n",
    "Once the tools are implemented, we'll run a few tests for cross-session personalization by storing preferences in one session and retrieving them in another.\n",
    "\n",
    "Let's get started."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46cc5f9",
   "metadata": {},
   "source": [
    "## Part 1: Implementing Memory Tools\n",
    "\n",
    "In this first part, we'll build the two tools mentioned above. We'll start by implementing a way for the agent to search long-term memory, giving it the ability to decide when it's relevant to recall information from the past.\n",
    "\n",
    "### üìå Task 1: Searching Memories\n",
    "\n",
    "In order for the agent to be able to search long term memory, we'll need the `search_memories` tool implementation to do the following:\n",
    "\n",
    "1. Accept a natural language query and optional limit parameter\n",
    "2. Call the Agent Memory Server's long-term memory search endpoint\n",
    "3. Return a list of relevant memories formatted for the LLM\n",
    "\n",
    "In the starter code, we've provided the `SearchMemoriesInput` Pydantic model (similar to the tool input schemas you built in Stage 3) that defines the expected parameters. Your task is to implement the tool function that searches long-term memory and returns relevant results.\n",
    "\n",
    "<details>\n",
    "<summary>üõ†Ô∏è Show Implementation Details</summary>\n",
    "<br> \n",
    "    \n",
    "**Step 1: Add the Tool Decorator**\n",
    "\n",
    "Use the `@tool` decorator from LangChain with the `args_schema` parameter set to `SearchMemoriesInput`. This tells LangChain how to parse and validate the tool's inputs.\n",
    "\n",
    "**Step 2: Validate Student ID**\n",
    "\n",
    "Check if the `student_id` parameter is provided. If not, return an empty list‚Äîwe can't search memories without knowing whose memories to search.\n",
    "\n",
    "**Step 3: Search Memories**\n",
    "\n",
    "Call the async method `.search_long_term_memory()` on the memory client with these parameters:\n",
    "- `text`: the search query\n",
    "- `user_id`: a `UserId` filter with `eq=student_id` (import from `agent_memory_client.filters`)\n",
    "- `limit`: the maximum number of results\n",
    "\n",
    "This returns a response object with a `.memories` attribute containing the list of memory objects.\n",
    "\n",
    "**Step 4: Format Results**\n",
    "\n",
    "The memory objects returned from Agent Memory Server contain several fields, but we only need a few for the LLM. Convert each memory object to a dictionary with these fields:\n",
    "\n",
    "- `text`: The actual memory content (e.g., \"Student prefers online courses\")\n",
    "- `memory_type`: The type of memory (semantic, episodic, or message‚Äîas discussed earlier)\n",
    "- `topics`: A list of topic tags that were assigned when the memory was stored (e.g., `[\"preferences\", \"learning_style\"]`). These help categorize memories and can be useful for filtering.\n",
    "\n",
    "Return the formatted results as a list of these dictionaries.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2f5c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict, Any\n",
    "from agent_memory_client.filters import UserId\n",
    "\n",
    "\n",
    "class SearchMemoriesInput(BaseModel):\n",
    "    \"\"\"Input schema for searching memories.\"\"\"\n",
    "    query: str = Field(\n",
    "        description=\"Natural language query to search for in long-term memory. \"\n",
    "        \"Examples: 'user preferences', 'completed courses', 'learning goals'\"\n",
    "    )\n",
    "    limit: int = Field(\n",
    "        default=3,\n",
    "        description=\"Maximum number of memories to return (default: 3)\"\n",
    "    )\n",
    "\n",
    "# Get the memory client\n",
    "memory_client = get_memory_client()\n",
    "\n",
    "@tool(args_schema=SearchMemoriesInput)\n",
    "async def search_memories(query: str, limit: int = 5, student_id: str = None) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Search long-term memory for relevant facts and preferences.\n",
    "    \n",
    "    Use this tool to recall information from previous conversations,\n",
    "    such as user preferences, goals, completed courses, or interests.\n",
    "    \n",
    "    Args:\n",
    "        query: Natural language search query\n",
    "        limit: Maximum number of results to return\n",
    "        student_id: User identifier (passed via context)\n",
    "        \n",
    "    Returns:\n",
    "        List of relevant memories with text content\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validate student_id\n",
    "        if not student_id:\n",
    "            return []\n",
    "        \n",
    "        # Search long-term memories\n",
    "        results = await memory_client.search_long_term_memory(\n",
    "            text=query,\n",
    "            user_id=UserId(eq=student_id),\n",
    "            limit=limit\n",
    "        )\n",
    "        \n",
    "        # Format results for LLM\n",
    "        formatted_results = [\n",
    "            {\n",
    "                \"text\": memory.text,\n",
    "                \"memory_type\": memory.memory_type,\n",
    "                \"topics\": memory.topics if hasattr(memory, 'topics') else []\n",
    "            }\n",
    "            for memory in results.memories\n",
    "        ]\n",
    "        \n",
    "        return formatted_results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error searching memories: {e}\")\n",
    "        return []\n",
    "        \n",
    "print(\"‚úÖ search_memories tool defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13e51bc",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üóùÔ∏è Solution code</summary>\n",
    "<br>\n",
    "\n",
    "```python\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict, Any\n",
    "from agent_memory_client.filters import UserId\n",
    "\n",
    "\n",
    "class SearchMemoriesInput(BaseModel):\n",
    "    \"\"\"Input schema for searching memories.\"\"\"\n",
    "    query: str = Field(\n",
    "        description=\"Natural language query to search for in long-term memory. \"\n",
    "        \"Examples: 'user preferences', 'completed courses', 'learning goals'\"\n",
    "    )\n",
    "    limit: int = Field(\n",
    "        default=3,\n",
    "        description=\"Maximum number of memories to return (default: 3)\"\n",
    "    )\n",
    "\n",
    "# Get the memory client\n",
    "memory_client = get_memory_client()\n",
    "\n",
    "@tool(args_schema=SearchMemoriesInput)\n",
    "async def search_memories(query: str, limit: int = 5, student_id: str = None) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Search long-term memory for relevant facts and preferences.\n",
    "    \n",
    "    Use this tool to recall information from previous conversations,\n",
    "    such as user preferences, goals, completed courses, or interests.\n",
    "    \n",
    "    Args:\n",
    "        query: Natural language search query\n",
    "        limit: Maximum number of results to return\n",
    "        student_id: User identifier (passed via context)\n",
    "        \n",
    "    Returns:\n",
    "        List of relevant memories with text content\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validate student_id\n",
    "        if not student_id:\n",
    "            return []\n",
    "        \n",
    "        # Search long-term memories\n",
    "        results = await memory_client.search_long_term_memory(\n",
    "            text=query,\n",
    "            user_id=UserId(eq=student_id),\n",
    "            limit=limit\n",
    "        )\n",
    "        \n",
    "        # Format results for LLM\n",
    "        formatted_results = [\n",
    "            {\n",
    "                \"text\": memory.text,\n",
    "                \"memory_type\": memory.memory_type,\n",
    "                \"topics\": memory.topics if hasattr(memory, 'topics') else []\n",
    "            }\n",
    "            for memory in results.memories\n",
    "        ]\n",
    "        \n",
    "        return formatted_results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error searching memories: {e}\")\n",
    "        return []\n",
    "        \n",
    "print(\"‚úÖ search_memories tool defined\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bae569a",
   "metadata": {},
   "source": [
    "### Test the Implementation\n",
    "\n",
    "Before moving onto the next tool implementation, let's test the `search_memories` implementation above with the test utility:\n",
    "\n",
    "> **Note:** This test searches for memories stored under the `test_user` ID from Stage 5. If you haven't run the Stage 5 notebook recently (or if your Redis instance was reset), we recommend running the multi-turn tests in that notebook first to seed long-term memory with extracted facts. We also run a seed file to make sure a few more long term memories are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a0918d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the test utility from stage6_full_memory\n",
    "from test_search_memories_tool import test_search_memories_tool, seed_test_memories\n",
    "\n",
    "# Test your implementation\n",
    "# Note: We'll use a test student ID that has some memories stored\n",
    "await seed_test_memories()\n",
    "await test_search_memories_tool(search_memories, student_id=\"test_user\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7c441d",
   "metadata": {},
   "source": [
    "### üìå Task 2: Storing Memories\n",
    "\n",
    "You might wonder: if RAMS automatically extracts facts to long-term memory, why do we need a tool to store them explicitly? \n",
    "\n",
    "There's a few reasons. For one, we don't want to always be at the whim of automatic background extraction. When someone says \"Remember that I prefer evening classes,\" they expect the agent to *actively* save that, not hope background extraction catches it. Having full control also gives us the ability to customize the long-term memory to our liking. We can change the storage type, add custom metadata, and ensure the information is stored exactly as we want it.\n",
    "\n",
    "The `store_memory` tool needs to:\n",
    "\n",
    "1. Accept text content, memory type, and optional topics\n",
    "2. Validate the memory type (semantic, episodic, or message)\n",
    "3. Call the memory client's `create_long_term_memories()` method\n",
    "4. Return a success confirmation\n",
    "\n",
    "Like the previous task, in the starter code, we've provided a `StoreMemoryInput` Pydantic model that defines the expected parameters. Your task is to implement the tool function that stores information to long-term memory.\n",
    "\n",
    "<details>\n",
    "<summary>üõ†Ô∏è Show Implementation Details</summary>\n",
    "\n",
    "**Step 1: Add the Tool Decorator**\n",
    "\n",
    "Use the `@tool` decorator from LangChain with the `args_schema` parameter set to `StoreMemoryInput`. This tells LangChain how to parse and validate the tool's inputs.\n",
    "\n",
    "**Step 2: Validate Memory Type**\n",
    "\n",
    "Check that `memory_type` is one of the three valid types: \"semantic\", \"episodic\", or \"message\". If not, raise a `ValueError`. This prevents invalid data from being stored and gives clear feedback to the agent.\n",
    "\n",
    "**Step 3: Validate Student ID**\n",
    "\n",
    "Check if the `student_id` parameter is provided. If not, return an error message‚Äîwe can't store memories without knowing whose memories they are.\n",
    "\n",
    "**Step 4: Store Memory**\n",
    "\n",
    "Call `memory_client.create_long_term_memories()` with a list containing a single memory dictionary:\n",
    "\n",
    "```python\n",
    "await memory_client.create_long_term_memories([{\n",
    "    \"text\": text,\n",
    "    \"memory_type\": memory_type,\n",
    "    \"topics\": topics or [],\n",
    "    \"user_id\": student_id\n",
    "}])\n",
    "```\n",
    "\n",
    "The method takes a list of dictionaries, each with: `text`, `memory_type`, `topics`, and `user_id`.\n",
    "\n",
    "**Step 5: Return Success Message**\n",
    "\n",
    "Return a friendly confirmation message indicating the memory was stored successfully. Include a snippet of what was stored so the agent can confirm in its response to the user.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5507ac4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, List\n",
    "\n",
    "class StoreMemoryInput(BaseModel):\n",
    "    \"\"\"Input schema for storing memories.\"\"\"\n",
    "    text: str = Field(\n",
    "        description=\"The information to store in long-term memory. \"\n",
    "        \"Examples: 'Student prefers online courses', 'Interested in machine learning'\"\n",
    "    )\n",
    "    memory_type: str = Field(\n",
    "        default=\"semantic\",\n",
    "        description=\"Type of memory: 'semantic' (facts), 'episodic' (events), or 'message' (conversations). \"\n",
    "        \"Default is 'semantic'.\"\n",
    "    )\n",
    "    topics: Optional[List[str]] = Field(\n",
    "        default=None,\n",
    "        description=\"Optional list of topic tags for organization. \"\n",
    "        \"Examples: ['preferences', 'interests', 'goals']\"\n",
    "    )\n",
    "\n",
    "@tool(args_schema=StoreMemoryInput)\n",
    "async def store_memory(\n",
    "    text: str,\n",
    "    memory_type: str = \"semantic\",\n",
    "    topics: Optional[List[str]] = None,\n",
    "    student_id: str = None\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Store information in long-term memory.\n",
    "    \n",
    "    Use this tool when users share preferences, goals, constraints,\n",
    "    or other information that should be remembered for future conversations.\n",
    "    \n",
    "    Args:\n",
    "        text: The information to store\n",
    "        memory_type: Type of memory (semantic, episodic, message)\n",
    "        topics: Optional topic tags\n",
    "        student_id: User identifier (passed via context)\n",
    "        \n",
    "    Returns:\n",
    "        Success confirmation message\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validate memory_type\n",
    "        valid_types = [\"semantic\", \"episodic\", \"message\"]\n",
    "        if memory_type not in valid_types:\n",
    "            raise ValueError(f\"Invalid memory_type. Must be one of: {valid_types}\")\n",
    "        \n",
    "        # Validate student_id\n",
    "        if not student_id:\n",
    "            return \"Error: No student_id provided\"\n",
    "        \n",
    "        # Store memory\n",
    "        await memory_client.create_long_term_memories([{\n",
    "            \"text\": text,\n",
    "            \"memory_type\": memory_type,\n",
    "            \"topics\": topics or [],\n",
    "            \"user_id\": student_id\n",
    "        }])\n",
    "        \n",
    "        # Return success message\n",
    "        return f\"Successfully stored {memory_type} memory: {text[:50]}...\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error storing memory: {e}\"\n",
    "\n",
    "print(\"‚úÖ store_memory function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850b5171",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üóùÔ∏è Solution code</summary>\n",
    "<br>\n",
    "\n",
    "```python\n",
    "\n",
    "@tool(args_schema=StoreMemoryInput)\n",
    "async def store_memory(\n",
    "    text: str,\n",
    "    memory_type: str = \"semantic\",\n",
    "    topics: Optional[List[str]] = None,\n",
    "    student_id: str = None\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Store information in long-term memory.\n",
    "    \n",
    "    Use this tool when users share preferences, goals, constraints,\n",
    "    or other information that should be remembered for future conversations.\n",
    "    \n",
    "    Args:\n",
    "        text: The information to store\n",
    "        memory_type: Type of memory (semantic, episodic, message)\n",
    "        topics: Optional topic tags\n",
    "        student_id: User identifier (passed via context)\n",
    "        \n",
    "    Returns:\n",
    "        Success confirmation message\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validate memory_type\n",
    "        valid_types = [\"semantic\", \"episodic\", \"message\"]\n",
    "        if memory_type not in valid_types:\n",
    "            raise ValueError(f\"Invalid memory_type. Must be one of: {valid_types}\")\n",
    "        \n",
    "        # Validate student_id\n",
    "        if not student_id:\n",
    "            return \"Error: No student_id provided\"\n",
    "        \n",
    "        # Store memory\n",
    "        await memory_client.create_long_term_memories([{\n",
    "            \"text\": text,\n",
    "            \"memory_type\": memory_type,\n",
    "            \"topics\": topics or [],\n",
    "            \"user_id\": student_id\n",
    "        }])\n",
    "        \n",
    "        # Return success message\n",
    "        return f\"Successfully stored {memory_type} memory: {text[:50]}...\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error storing memory: {e}\"\n",
    "```\n",
    "\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1f5cb8",
   "metadata": {},
   "source": [
    "### Test Your Implementation\n",
    "\n",
    "Now let's test the `store_memory` implementation with the test utility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c444cf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the test utility\n",
    "from test_store_memory_tool import test_store_memory_tool\n",
    "\n",
    "# Test your implementation\n",
    "await test_store_memory_tool(store_memory, student_id=\"test_user\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab80f605",
   "metadata": {},
   "source": [
    "## Part 2: Testing Cross-Session Personalization\n",
    "\n",
    "With both memory tools implemented, we can now demonstrate the capability that was missing in Stage 5: true cross-session personalization. Remember the frustrating scenario from the introduction where the agent forgot user preferences between sessions? Let's prove that's no longer the case.\n",
    "\n",
    "We'll simulate a realistic user journey: Alice visits the course advisor, shares her preferences, leaves, and returns in a completely new session. In Stage 5, she would have had to repeat herself. Now, the agent should remember her from the previous conversation.\n",
    "\n",
    "The key thing to watch in these tests is the reasoning trace. You'll see the agent actively deciding *when* to use each tool‚Äîthis isn't hardcoded logic, it's the ReAct pattern in action. The agent reasons about what information it needs and selects the appropriate tool to get it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e214988",
   "metadata": {},
   "source": [
    "### Test 1: Store Preferences (Session 1)\n",
    "\n",
    "Alice is a new student visiting the course advisor for the first time. She shares her learning preferences and interests. Watch the reasoning trace to see how the agent recognizes this as information worth persisting and uses the `store_memory` tool to save it for future sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072511a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"TEST 1: Storing User Preferences (Session 1)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "result1 = await run_agent_async(\n",
    "    workflow,\n",
    "    query=\"I prefer online courses and I'm really interested in machine learning and AI.\",\n",
    "    session_id=\"session_001\",\n",
    "    student_id=\"alice\",\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Session 1 complete - preferences should be stored\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4558e8",
   "metadata": {},
   "source": [
    "In the reasoning trace above, you should see the agent identify Alice's preferences as valuable information and explicitly store them to long-term memory. The agent might store multiple memories (e.g., one for \"prefers online courses\" and another for \"interested in ML/AI\") to keep facts atomic and searchable.\n",
    "\n",
    "This is different from Stage 5's automatic extraction‚Äîhere the agent is *actively deciding* to remember this information because the user explicitly shared preferences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acea07d9",
   "metadata": {},
   "source": [
    "### Test 2: Retrieve Memories in New Session (Session 2)\n",
    "\n",
    "Now for the moment of truth. Alice returns the next day in a **completely new session** (`session_002`). She asks for course recommendations without repeating her preferences. \n",
    "\n",
    "In Stage 5, the agent would have no choice but to ask clarifying questions‚Äîthe working memory from yesterday's session is gone. But now, the agent has a tool to search long-term memory. Watch the reasoning trace to see if it thinks to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97824f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TEST 2: Retrieving Memories in New Session (Session 2)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "result2 = await run_agent_async(\n",
    "    workflow,\n",
    "    query=\"What courses would you recommend for me?\",\n",
    "    session_id=\"session_002\",  # DIFFERENT SESSION\n",
    "    student_id=\"alice\",        # SAME STUDENT\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Session 2 complete - agent should have used stored preferences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d715faa",
   "metadata": {},
   "source": [
    "This is cross-session personalization in action. Notice the multi-step reasoning:\n",
    "\n",
    "1. **Thought**: \"The user asked for recommendations but didn't specify criteria. Let me check if I have any stored information about their preferences.\"\n",
    "2. **Action**: `search_memories` with a query about preferences\n",
    "3. **Observation**: Finds Alice's stored preferences (online courses, ML/AI interest)\n",
    "4. **Thought**: \"Now I can search for courses that match these preferences.\"\n",
    "5. **Action**: `search_courses` with personalized criteria\n",
    "\n",
    "The agent remembered Alice without her having to repeat herself. This is the seamless experience we were aiming for."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be8224b",
   "metadata": {},
   "source": [
    "### Test 3: Multi-Tool Orchestration\n",
    "\n",
    "Let's push the agent further with a query that requires chaining multiple tools together. This tests not just memory retrieval, but the agent's ability to plan a multi-step approach: recall preferences, search courses, and filter by prerequisites‚Äîall in one turn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facba0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TEST 3: Multi-Tool Orchestration\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "result3 = await run_agent_async(\n",
    "    workflow,\n",
    "    query=\"Show me courses that match my interests and tell me which ones have prerequisites.\",\n",
    "    session_id=\"session_003\",\n",
    "    student_id=\"alice\",\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Multi-tool test complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33103ce",
   "metadata": {},
   "source": [
    "The reasoning trace here reveals sophisticated planning. The agent doesn't just blindly execute tools‚Äîit forms a strategy:\n",
    "\n",
    "- First, understand what \"my interests\" means by searching memories\n",
    "- Then, find courses matching those interests\n",
    "- Finally, analyze prerequisite information from the results\n",
    "\n",
    "This multi-step orchestration is the ReAct pattern at its best: the agent reasons, acts, observes the result, and decides what to do next. Each iteration brings it closer to a complete answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae22c08",
   "metadata": {},
   "source": [
    "## Part 3: Understanding Tool Orchestration Patterns\n",
    "\n",
    "Now that you've seen the agent in action, let's step back and examine the patterns that emerge. Different types of queries lead to different tool orchestration flows. Understanding these patterns helps you predict agent behavior and design better tools.\n",
    "\n",
    "**Pattern 1: Store First, Then Search**  \n",
    "When users share new information *and* ask a question in the same turn, the agent typically stores first, then searches. This ensures the new preference is persisted before moving on.  \n",
    "*Example:* \"I like Python programming. Show me related courses.\"  \n",
    "*Flow:* `store_memory` ‚Üí `search_courses` ‚Üí FINISH\n",
    "\n",
    "**Pattern 2: Search Memories First**  \n",
    "When users ask personalized questions in a new session (without providing new context), the agent searches memories to recall who they are and what they prefer.  \n",
    "*Example:* \"What courses fit my preferences?\"  \n",
    "*Flow:* `search_memories` ‚Üí `search_courses` ‚Üí FINISH\n",
    "\n",
    "**Pattern 3: Search Courses Only**  \n",
    "For factual, non-personalized queries, the agent goes straight to course search. No memory tools needed‚Äîthe question is self-contained.  \n",
    "*Example:* \"What is CS401?\"  \n",
    "*Flow:* `search_courses` ‚Üí FINISH\n",
    "\n",
    "**Pattern 4: Complex Multi-Tool**  \n",
    "Some queries require all three tools: store a new preference, recall existing context, and search for matching content.  \n",
    "*Example:* \"I want to learn databases. Remember that and find relevant courses.\"  \n",
    "*Flow:* `store_memory` ‚Üí `search_memories` ‚Üí `search_courses` ‚Üí FINISH\n",
    "\n",
    "Let's run through a few patterns with a new student (Charlie) to see these flows in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b3f0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"PATTERN TESTING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "patterns = [\n",
    "    (\"Pattern 1\", \"I like Python programming. Show me related courses.\", \"charlie\", \"charlie_001\"),\n",
    "    (\"Pattern 2\", \"What courses fit my preferences?\", \"charlie\", \"charlie_002\"),\n",
    "    (\"Pattern 3\", \"What is CS401?\", \"charlie\", \"charlie_003\"),\n",
    "]\n",
    "\n",
    "for pattern_name, query, student_id, session_id in patterns:\n",
    "    print(f\"\\n--- {pattern_name} ---\")\n",
    "    print(f\"Query: {query}\")\n",
    "    await run_agent_async(\n",
    "        workflow,\n",
    "        query=query,\n",
    "        session_id=session_id,\n",
    "        student_id=student_id,\n",
    "    )\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe7c228",
   "metadata": {},
   "source": [
    "## Wrap Up üèÅ\n",
    "\n",
    "You've completed Stage 6 and built a production-ready agent with full memory capabilities. Let's reflect on what you accomplished:\n",
    "\n",
    "**The Problem We Solved**\n",
    "\n",
    "At the start of this notebook, we identified a frustrating limitation: our Stage 5 agent had amnesia between sessions. RAMS was automatically extracting facts to long-term memory, but the agent had no way to access them. Users had to repeat their preferences every time they started a new conversation.\n",
    "\n",
    "**The Solution We Built**\n",
    "\n",
    "You implemented two tools that unlock long-term memory for the agent:\n",
    "\n",
    "- **`search_memories`**: Enables the agent to query stored facts, preferences, and history from previous sessions. When a user asks \"What courses fit my preferences?\" in a new session, the agent can now recall who they are.\n",
    "\n",
    "- **`store_memory`**: Gives the agent explicit control over what gets remembered. When a user says \"Remember that I prefer evening classes,\" the agent actively stores that fact rather than relying on automatic extraction.\n",
    "\n",
    "**The Patterns We Discovered**\n",
    "\n",
    "Through testing, you observed how the agent orchestrates these tools dynamically:\n",
    "- Storing information when users share preferences\n",
    "- Searching memories before personalized recommendations  \n",
    "- Chaining multiple tools for complex queries\n",
    "- Skipping memory tools entirely for factual questions\n",
    "\n",
    "This isn't hardcoded logic‚Äîit's the ReAct pattern enabling the agent to reason about what information it needs and select the right tool to get it.\n",
    "\n",
    "---\n",
    "\n",
    "### The Complete Journey\n",
    "\n",
    "You've now completed the entire progressive agents learning path. Here's the full architecture you've built from the ground up:\n",
    "\n",
    "| Section | Stage | What You Built |\n",
    "|---------|-------|----------------|\n",
    "| **Context Engineering Foundations** | Stage 1 | Baseline RAG with retrieved context + generation |\n",
    "| | Stage 2 | Data-engineered RAG with structured data and optimized chunking |\n",
    "| **From RAG to Agent** | Stage 3 | Hierarchical retrieval with intent classification and progressive disclosure |\n",
    "| | Stage 4 | Hybrid search + ReAct with visible reasoning and tool orchestration |\n",
    "| **Memory & Context** | Stage 5 | Working memory for multi-turn conversation continuity |\n",
    "| | Stage 6 | Full memory with explicit long-term memory control |\n",
    "\n",
    "Each stage built on the previous one, and together they form a complete context engineering system:\n",
    "\n",
    "- **Context engineering** taught you how to structure, chunk, and assemble information for optimal LLM consumption\n",
    "- **Intelligent retrieval** gave you multiple strategies (semantic, exact match, hybrid) to find the right information\n",
    "- **Agentic reasoning** enabled visible decision-making through the ReAct pattern\n",
    "- **Memory management** provided both automatic extraction and explicit control over what the agent remembers\n",
    "\n",
    "---\n",
    "\n",
    "### Congratulations! üéâ\n",
    "\n",
    "You've mastered the basics of context engineering for AI agents. The concepts and patterns you've learned‚Äîhierarchical context assembly, hybrid search strategies, ReAct reasoning, and two-tier memory management‚Äîare the building blocks of sophisticated, context-aware AI systems.\n",
    "\n",
    "Now go build something amazing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
