{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 0: Crafting Effective System Prompts\n",
    "\n",
    "Before we dive into building complex retrieval systems with our agent, we need to define who our agent is. To do so, we'll focus on the foundation of all context: system context.\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "1.  Define system context: Explore how to set an agent's role, capabilities, and constraints through system instructions.\n",
    "2.  Evaluate system prompt effectiveness: You'll experiment with different system instructions and observe how they change agent behavior.\n",
    "\n",
    "> ‚ö†Ô∏è **Note**: This notebook makes repeated calls to an LLM. The responses shown are examples captured when the notebook was authored, and your outputs may vary. We recommend running each query multiple times to assess both the system‚Äôs response consistency and the variety of replies.\n",
    "\n",
    "Before diving in, let's recap what system context is and explore some industry-shared best practices before diving into crafting it with the Redis University agent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Art of System Context\n",
    "\n",
    "To recap what we saw in the introduction to this course, system context (also known as a system prompt or system instructions) is the persistent context that defines your agent's identity and behavior. System context is typically included in every conversation turn you'll have with an LLM and tells it the following:\n",
    "\n",
    "1.  Who it is (Role and identity)\n",
    "2.  What it can do (Capabilities and tools)\n",
    "3.  How it should behave (Personality and constraints)\n",
    "4.  What it knows (Domain knowledge and context)\n",
    "\n",
    "As you'll get to experience in this notebook and in your journey of building AI applications, setting system context can sometimes feel more of an art than a science. \n",
    "\n",
    "Anthropic shared some of their advice in what they find to be effective system prompts. In their guide on [Effective Context Engineering](https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents), Anthropic emphasizes that system prompts should be \"extremely clear and use simple, direct language that presents ideas at the right altitude for the agent.\"\n",
    "\n",
    "They describe this \"right altitude\" as a *Goldilocks Zone*:\n",
    "\n",
    "> \"At one extreme, we see engineers hardcoding complex, brittle logic in their prompts... At the other extreme, engineers sometimes provide vague, high-level guidance... The optimal altitude strikes a balance: specific enough to guide behavior effectively, yet flexible enough to provide the model with strong heuristics to guide behavior.\"\n",
    "\n",
    "<img src=\"https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F0442fe138158e84ffce92bed1624dd09f37ac46f-2292x1288.png&w=3840&q=75\" alt=\"Calibrating the system prompt\" width=\"800\"/>\n",
    "\n",
    "*Image Source: Anthropic*\n",
    "\n",
    "To achieve this balance, Anthropic recommends organizing prompts into distinct sections (like `<background_information>`, `<instructions>`, `## Tool guidance`, etc.) using XML tags or Markdown headers. \n",
    "\n",
    "In this notebook, we will apply a structured approach, and you'll see the difference a carefully crafted system prompt can make. Let's get started! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's set up our environment. For this notebook, we're going to be using the Stage 1 baseline RAG agent as our foundation (located in the `/progressive_agents` directory). Don't worry about the internals yet ‚Äî it's a basic retrieval pipeline that searches for courses and generates responses. We'll dive deep into how it works in the next notebook (stage 1).\n",
    "\n",
    "The key thing to note is that we will be using a special function called `set_system_instructions`. This hook will allow us to dynamically override the agent's system prompt without modifying the source code ‚Äî perfect for experimenting!\n",
    "\n",
    "To begin, run the code blocks below to initialize the agent and load sample course data (50 courses) into Redis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code sets up the notebook to be able to access the provided OpenAI API Key and access to the agent code\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "if \"OPENAI_API_BASE\" in os.environ:\n",
    "    os.environ[\"OPENAI_BASE_URL\"] = os.environ[\"OPENAI_API_BASE\"]\n",
    "\n",
    "project_root = Path(\"..\").resolve()\n",
    "\n",
    "stage1_path = project_root / \"progressive_agents\" / \"stage1_baseline_rag\"\n",
    "src_path = project_root / \"src\"\n",
    "\n",
    "sys.path.insert(0, str(src_path))\n",
    "sys.path.insert(0, str(stage1_path))\n",
    "\n",
    "print('OpenAI API key and agent access setup!')\n",
    "\n",
    "from agent import setup_agent\n",
    "from agent.nodes import set_system_instructions\n",
    "\n",
    "print(\"Initializing Stage 1 Baseline Agent...\")\n",
    "# We use the Stage 1 baseline agent, but we will override its system prompt\n",
    "workflow, course_manager = setup_agent(auto_load_courses=True, verbose=False)\n",
    "print(\"Agent is ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crafting System Instructions\n",
    "\n",
    "Let's build system instructions for our Redis University advisor agent step by step. We will override the agent's default system prompt and see how it changes the response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Minimal System Instructions\n",
    "\n",
    "Let's start with the bare minimum and see what happens. We're going to tell the system to be a \"helpful assistant\" but otherwise are not providing any meaningful guidance about its purpose and role. We'll test two queries: one about its identity and the other about what courses it would recommend.\n",
    "\n",
    "Run the code block below to see the system's response. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal system prompt\n",
    "minimal_prompt = \"You are a helpful assistant.\"\n",
    "\n",
    "# Override the agent's system instructions\n",
    "set_system_instructions(minimal_prompt)\n",
    "\n",
    "# Test the system's identity\n",
    "print(\"Running agent query on identity...\")\n",
    "result_identity = await workflow.ainvoke({\"query\": \"Who are you and what can you do?\"})\n",
    "\n",
    "print(\"Response on identity:\")\n",
    "print(result_identity['final_answer'])\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Test the courses it will recommend\n",
    "print(\"Running agent query on course recommendations...\")\n",
    "result_courses = await workflow.ainvoke({\"query\": \"Give me a recommendation on a course I should take next semester\"})\n",
    "\n",
    "print(\"Response on course recommendations:\")\n",
    "print(result_courses['final_answer'])\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this application is an RAG, the LLM model is smart enough to recognize that we are working with course data (stored in our Redis database); however, in our testing (which may differ slightly from your own), we consistently received responses referencing that it was designed to help with business-specific courses: \n",
    "\n",
    "> \"I am an AI assistant designed to help you with information about various courses offered in the Computer Science department\"\n",
    "\n",
    "And when asked for a specific course recommendation, it seemingly chooses a few courses at random related to math: \n",
    "\n",
    "> \"If you are interested in machine learning and want to strengthen your mathematical foundation, **MATH022: Linear Algebra for Machine Learning** would be an excellent choice. If you are leaning towards computer science, **MATH029: Discrete Mathematics** is highly relevant. For a deeper dive into advanced mathematics, consider **MATH030: Abstract Algebra**, provided you meet the prerequisite. If you need to solidify your foundational skills, **MATH023: Pre-Calculus** is a great option.\"\n",
    "\n",
    "With this in mind, we can identify two key improvements we want to make via the system prompt: \n",
    "\n",
    "1. We want it to identify itself properly and know exactly its purpose. This should steer it in the right direction, acting as a more general course advisor rather than one designed specifically for computer science. \n",
    "\n",
    "2. Secondly, we'll want it to have some level of consultative intelligence. We'll want the system to understand the nuance of a request, ask clarifying questions when necessary, and provide recommendations that actually make sense for the user's context.\n",
    "\n",
    "Let's give it a try!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Adding Role and Purpose\n",
    "\n",
    "Below, our system prompt has been upgraded. We explicitly define its identity and role. We will run it against the same set of queries from earlier, but in addition, we will also include a third query that poses an off-topic question. We will ask it to suggest a pizza recipe for a cooking class that the imaginary student is attending, and see how it responds. \n",
    "\n",
    "Run the code block below and observe the responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add role and purpose\n",
    "role_prompt = \"\"\"You are the Redis University Class Agent.\n",
    "\n",
    "Your role is to help students:\n",
    "- Find courses that match their interests and requirements\n",
    "- Plan their academic schedule\n",
    "- Check prerequisites and eligibility\n",
    "- Get personalized course recommendations\n",
    "\"\"\"\n",
    "\n",
    "# Override agent instructions\n",
    "set_system_instructions(role_prompt)\n",
    "\n",
    "queries = [\n",
    "    {\n",
    "        \"label\": \"identity\",\n",
    "        \"description\": \"Test the system's identity\",\n",
    "        \"query\": \"Who are you and what can you do?\"\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"course recommendations\",\n",
    "        \"description\": \"Test the courses it will recommend\",\n",
    "        \"query\": \"Give me a recommendation on a course I should take next semester\"\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"off-topic query\",\n",
    "        \"description\": \"Test an off-topic query\",\n",
    "        \"query\": \"Suggest me a pizza recipe for my class\"\n",
    "    },\n",
    "]\n",
    "\n",
    "for q in queries:\n",
    "    print(f\"{q['description']}...\")\n",
    "    print(f\"Running agent query on {q['label']}...\")\n",
    "\n",
    "    result = await workflow.ainvoke({\"query\": q[\"query\"]})\n",
    "\n",
    "    print(f\"Response on {q['label']}:\")\n",
    "    print(result[\"final_answer\"])\n",
    "    print(\"\\n\" + \"=\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That response is much better! The system now understands its role and responds with a set of capabilities we have defined. In our testing for the first query, it consistently responded with its identity: \n",
    "\n",
    "> \"I am the Redis University Class Agent, here to assist you with your academic journey. I can help you with the following: ...\"\n",
    "\n",
    "However, when asked for course recommendations, it seemingly chose a random set of courses related to math to recommend: \n",
    "\n",
    "> \"Based on your request for a course recommendation for the next semester, I suggest considering the following options:\n",
    "\n",
    "### 1. **Linear Algebra for Machine Learning (MATH022)** ...\"\n",
    "\n",
    "While we have resolved its identity issue, we still want the system to suggest courses thoughtfully, rather than randomly. This approach may resemble a more turn-based method, where the learner is consulted to learn about their preferences before a final suggestion is made. We'll implement a more complex version of the agent later in this course to handle multi-turn scenarios. \n",
    "\n",
    "Lastly, the system was presented with an off-topic question about making a pizza dough recipe. In our first attempt and several attempts after, we were able to get the system to return a recipe:\n",
    "\n",
    "> \"It seems like you're looking for a pizza recipe, but I specialize in helping with course information and academic planning. If you're interested in courses related to cooking or culinary arts, I can assist you in finding relevant classes. However, if you're looking for a pizza recipe, here's a simple one you can try: ...\"\n",
    "\n",
    "However, in good news, on several other attempts, it refused to return a recipe: \n",
    "\n",
    "> \"It seems like you're looking for a pizza recipe, but I specialize in helping with course information and academic planning. If you're interested in courses related to cooking or culinary arts, I can assist you in finding relevant classes.\"\n",
    "\n",
    "These types of inconsistencies can occur due to the nature of a model, but it's best practice to steer our system by providing specific guidelines on how to behave. For our third example around an off-topic query, let's add some behavioral guidance to improve the course suggestions and (hopefully) avoid returning an answer to an off-topic query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: Adding Behavioral Guidelines\n",
    "\n",
    "In this next example, let's see how the system responds when presented with specific behavioral guidelines. \n",
    "\n",
    "Below, we extend the previous system prompt and will re-run the same queries as before. Our guidelines are designed to address the two core issues we observed in the earlier example: \n",
    "\n",
    "1. Providing more thorough assistance to the student\n",
    "2. Ensuring the system does not respond to queries outside its domain.\n",
    "\n",
    "To further test the preferences guideline, we have also added a fourth query requesting specific guidance on a topic the student mentioned. With a more specific query (e.g., ‚ÄúLearn about databases‚Äù), we would expect the system to recognize this as a preference and then search for courses related to databases.\n",
    "\n",
    "Examine the code block below and then run it to see the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add behavioral guidelines\n",
    "guideline_prompt = \"\"\"You are the Redis University Class Agent.\n",
    "\n",
    "Your role is to help students:\n",
    "- Find courses that match their interests and requirements\n",
    "- Plan their academic schedule\n",
    "- Check prerequisites and eligibility\n",
    "- Get personalized course recommendations\n",
    "\n",
    "Guidelines:\n",
    "- Do not recommend any courses unless you know about the student's preferences\n",
    "- If asked about topics outside your domain and responsibilities, always politely redirect to course planning\n",
    "\"\"\"\n",
    "\n",
    "# Override agent instructions\n",
    "set_system_instructions(guideline_prompt)\n",
    "\n",
    "queries = [\n",
    "    {\n",
    "        \"label\": \"identity\",\n",
    "        \"description\": \"Test the system's identity\",\n",
    "        \"query\": \"Who are you and what can you do?\"\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"course recommendations\",\n",
    "        \"description\": \"Test the courses it will recommend\",\n",
    "        \"query\": \"Give me a recommendation on a course I should take next semester\"\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"off-topic query\",\n",
    "        \"description\": \"Test an off-topic query\",\n",
    "        \"query\": \"Suggest me a pizza recipe for my class\"\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"specific query\",\n",
    "        \"description\": \"Test a specific query\",\n",
    "        \"query\": \"I want to learn about databases and am not sure where to start\"\n",
    "    },\n",
    "]\n",
    "\n",
    "for q in queries:\n",
    "    print(f\"{q['description']}...\")\n",
    "    print(f\"Running agent query on {q['label']}...\")\n",
    "\n",
    "    result = await workflow.ainvoke({\"query\": q[\"query\"]})\n",
    "\n",
    "    print(f\"Response on {q['label']}:\")\n",
    "    print(result[\"final_answer\"])\n",
    "    print(\"\\n\" + \"=\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our various tests at the time of authoring this notebook, the new guidelines provided to the system prompt sufficiently improved the system's response. \n",
    "\n",
    "When asked about course recommendations without knowing specific preferences, the system successfully utilized our guideline (\"Do not recommend any courses unless you know about the student's preferences\") to facilitate a more fluid conversation. It typically responded with the following: \n",
    "\n",
    "> \"To provide you with a personalized course recommendation, I need to know more about your interests and academic goals. Here are a few questions to help narrow down the options: ...\"\n",
    "\n",
    "We were also unable to reproduce the issue with the system providing a pizza recipe, and it consistently tried to redirect based on the second guideline (\"If asked about topics outside your domain and responsibilities, always politely redirect to course planning\"). It typically responded with the following: \n",
    "\n",
    "> \"I'm here to assist you with course planning and academic scheduling, but I can't provide recipes or cooking advice...\"\n",
    "\n",
    "Lastly, we confirmed that the guideline regarding learner preferences would also function properly when the query provided specifics (e.g., database courses). Our system typically returned a few recommendations related to the topic: \n",
    "\n",
    "> \"If you're interested in learning about databases, I recommend considering the following course: Course: Database Systems (CS005) ...\"\n",
    "\n",
    "Overall, it was a solid upgrade to our system context and has laid the foundation for our university agent moving forward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap Up\n",
    "\n",
    "Great job! You‚Äôve now seen how powerful well-crafted system instructions can be and how much subtle changes can reshape your agent‚Äôs behavior. Just as importantly, you‚Äôve also seen that system prompts are more art than science: they evolve as you test the system, discover edge cases, and expand its capabilities.\n",
    "\n",
    "More specifically, in this notebook, we:\n",
    "\n",
    "- Defined the agent‚Äôs identity and role so it knows who it is and what domain it operates in.\n",
    "- Clarified its capabilities by specifying what it can access and what it can help with.\n",
    "- Added behavioral guidelines to shape tone, interaction style, and how it handles ambiguous or out-of-scope queries.\n",
    "- Introduced constraints so the agent explicitly knows what it should *not* do.\n",
    "\n",
    "Remember, this is just a starting point. System instructions can grow to include many more elements, such as:\n",
    "\n",
    "- Example interactions (‚Äúwhen the user says X, respond like Y‚Äù)  \n",
    "- Tool descriptions and usage rules (‚Äúyou have access to tools A, B, C, and should use them when‚Ä¶‚Äù)  \n",
    "- Fallback strategies and escalation paths for when the agent is unsure or underpowered  \n",
    "\n",
    "As you iterate, treat your system prompt as a living document: refine it, extend it, and let your experiments guide its evolution.\n",
    "\n",
    "Before moving on to the next section, use the code block below as your playground. You'll find some sample experiments to try in the dropdown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>üî∂ Click the dropdown to see sample experiments to run.</summary>\n",
    "  <br>\n",
    "\n",
    "Experiment 1: Switch the advisor‚Äôs persona and tone\n",
    "\n",
    "Goal: See how changing the identity and tone instructions affects the style of answers, while keeping the content mostly the same.\n",
    "\n",
    "System prompt change:\n",
    "- In the identity section, first set the agent to be a ‚Äúformal academic advisor at Redis University who is precise and concise.‚Äù\n",
    "- After testing, change it to ‚Äúfriendly peer mentor at Redis University who is encouraging, conversational, and uses simple language.‚Äù\n",
    "\n",
    "Example queries:\n",
    "1. Who are you, and how can you help me with course selection?  \n",
    "2. Please explain how you will assist me in planning my learning for the next semester.\n",
    "\n",
    "Compare how the answers differ between the two versions of the system prompt.\n",
    "\n",
    "---\n",
    "\n",
    "Experiment 2: Personalized plan for a sample student (Olivia)\n",
    "\n",
    "Goal: Test how well the agent uses a detailed profile when the system prompt explicitly tells it to ground recommendations in that profile.\n",
    "\n",
    "System prompt change:\n",
    "- Add a section such as:\n",
    "  - ‚ÄúWhen given a student profile, restate the key parts (background, interests, preferences, goals) and then map each course recommendation back to those details.‚Äù\n",
    "  - ‚ÄúPrefer courses that align with the student‚Äôs long-term goals, even if they are slightly more challenging, but explain any trade-offs.‚Äù\n",
    "\n",
    "Example query:\n",
    "\n",
    "\"Below is a student profile. Based on this information, please recommend 2‚Äì4 courses, in order, and briefly justify each recommendation in terms of the profile's background, interests, preferences, and goal.\"\n",
    "   \n",
    "> - Name: Olivia Jansen  \n",
    "> - Major: Computer Science  \n",
    "> - Year: Sophomore  \n",
    "> - Completed: Intro to Programming (CS101), Data Structures (CS201), Calculus I  \n",
    "> - Interests: Machine learning, Data science  \n",
    "> - Preferences: Prefers online courses, learns best with hands-on projects  \n",
    "> - Goal: Build a career in AI\n",
    "\n",
    "Try removing or weakening that ‚Äúprofile‚Äù section in the system prompt and see how the recommendations and explanations change.\n",
    "\n",
    "---\n",
    "\n",
    "Experiment 3: Handling conflicting requirements and trade-offs\n",
    "\n",
    "Goal: Make the agent explicitly reason about trade-offs when the student‚Äôs constraints cannot all be satisfied.\n",
    "\n",
    "System prompt change:\n",
    "- In the behavioral guidelines, add:\n",
    "  - ‚ÄúIf the student‚Äôs requirements conflict (for example, wanting something very advanced, very short, and beginner-friendly), explain the trade-offs clearly.‚Äù\n",
    "  - ‚ÄúOffer the closest available option and be transparent about what compromises are being made.‚Äù\n",
    "\n",
    "Example queries:\n",
    "1. I want a course that is extremely advanced and requires no prior programming experience. Recommend the best fit and clearly explain which of my requirements you can and cannot satisfy.\n",
    "2. I want an intermediate-level Redis course that is not too long and does not assume deep math knowledge. What would you recommend?\n",
    "\n",
    "Verify whether the agent follows the new instructions to discuss trade-offs.\n",
    "\n",
    "---\n",
    "\n",
    "Experiment 4: Tool and capability honesty\n",
    "\n",
    "Goal: Ensure the agent clearly communicates what it can and cannot do (for example, no direct enrollment, no real-time catalog access).\n",
    "\n",
    "System prompt change:\n",
    "- Add a capabilities and constraints block, such as:\n",
    "  - ‚ÄúYou do not have direct access to enrollment systems, student accounts, or live scheduling data.‚Äù\n",
    "  - ‚ÄúWhen the user asks you to perform actions you cannot do, explain your limitations and suggest what they can do instead (for example, visiting a specific site or contacting support).‚Äù\n",
    "\n",
    "Example queries:\n",
    "\n",
    "1. Tell me which courses are open for enrollment next month, and sign me up for the best one for me.\n",
    "2. Can you update my account so that it tracks my progress automatically?\n",
    "\n",
    "Observe whether the agent now reliably explains its limits instead of pretending to have capabilities it does not have.\n",
    "\n",
    "\n",
    "</details>\n",
    " <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with the system prompt below\n",
    "\n",
    "custom_prompt = \"\"\"You are the Redis University Class Agent, powered by Redis and the Agent Memory Server.\n",
    "\n",
    "Your role is to help students:\n",
    "- Find courses that match their interests and requirements\n",
    "- Plan their academic schedule for the upcoming semesters\n",
    "- Check prerequisites and course eligibility\n",
    "- Get personalized course recommendations based on their goals\n",
    "\n",
    "You have access to:\n",
    "- A complete course catalog with descriptions, prerequisites, and schedules\n",
    "- Student preferences and goals (stored in long-term memory)\n",
    "- Conversation history (stored in working memory)\n",
    "- Tools to search courses and check prerequisites\n",
    "\n",
    "Guidelines:\n",
    "- Be helpful, friendly, and encouraging\n",
    "- Ask clarifying questions when you need more information\n",
    "- Provide specific course recommendations with course codes and details\n",
    "- Explain prerequisites and requirements clearly\n",
    "- Remember student preferences and reference them in future conversations\n",
    "- Stay focused on course planning and scheduling\n",
    "- If asked about topics outside your domain, politely redirect to course planning\n",
    "\n",
    "Example interactions:\n",
    "- Student: \"I'm interested in machine learning\"\n",
    "  You: \"Great! I can help you find ML courses. What's your current year and have you taken any programming courses?\"\n",
    "\n",
    "- Student: \"What are the prerequisites for CS401?\"\n",
    "  You: \"Let me check that for you.\" [Use check_prerequisites tool]\n",
    "\"\"\"\n",
    "\n",
    "# Override agent instructions\n",
    "set_system_instructions(custom_prompt)\n",
    "\n",
    "queries = [\n",
    "    {\n",
    "        \"label\": \"identity\",\n",
    "        \"description\": \"Test the system's identity\",\n",
    "        \"query\": \"Who are you and what can you do?\"\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"course recommendations\",\n",
    "        \"description\": \"Test the courses it will recommend\",\n",
    "        \"query\": \"Give me a recommendation on a course I should take next semester\"\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"off-topic query\",\n",
    "        \"description\": \"Test an off-topic query\",\n",
    "        \"query\": \"Suggest me a pizza recipe for my class\"\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"specific query\",\n",
    "        \"description\": \"Test a specific query\",\n",
    "        \"query\": \"I want to learn about databases and am not sure where to start\"\n",
    "    },\n",
    "]\n",
    "\n",
    "for q in queries:\n",
    "    print(f\"{q['description']}...\")\n",
    "    print(f\"Running agent query on {q['label']}...\")\n",
    "\n",
    "    result = await workflow.ainvoke({\"query\": q[\"query\"]})\n",
    "\n",
    "    print(f\"Response on {q['label']}:\")\n",
    "    print(result[\"final_answer\"])\n",
    "    print(\"\\n\" + \"=\" * 80 + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
