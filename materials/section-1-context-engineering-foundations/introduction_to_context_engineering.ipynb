{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "![Redis](https://redis.io/wp-content/uploads/2024/04/Logotype.svg?auto=webp&quality=85,75&width=120)\n",
    "\n",
    "# Introduction\n",
    "\n",
    "Over the past few years, AI applications have undergone rapid evolution. Early on, engineers built a polite clerk behind a glass window: users would slide a note - \"draft this email,\" \"explain this code\" â€” and the clerk would read it, scribble an answer, and slide it back. Their answers were generally good, but not always what we wanted. \n",
    "\n",
    "Both engineers and users of these AI systems quickly realized that if they *precisely* engineer what the note says, they can, in turn, achieve better results from the clerk. So, they used more precise instructions â€” \"act as my editor,\" \"use this tone,\" \"return a table\" â€” and the outputs became sharper. This, in turn, became the practice of prompt engineering. \n",
    "\n",
    "Prompt engineering took these applications further, but eventually showed its limits â€” especially with our clerk behind the glass. Many times, we would hope the wording we provided would stick, but the longer notes got slow and contradictory. Sometimes, when we modified small parts of the prompt, the system's behavior changed in ways that were difficult to predict or control, and no amount of wordsmithing seemed to fully rectify the issue.\n",
    "\n",
    "For a while, if you were an engineer building with these systems, the playbook for solving these issues was simple: upgrade the model. Swap in the latest version, and your clerk would provide sharper responses, have a better grasp of nuance, and possess the capability to undertake specialized tasks like research or creative exploration.\n",
    "\n",
    "Typically, upgrading the model did indeed help! The clerk began to catch more nuances in the notes that were passed. It could juggle longer instructions, synthesize more information, and make fewer obvious mistakes. For many engineers, it felt like the main knob to turn was simply: use a bigger, smarter model.\n",
    "\n",
    "But under the hood, no matter how powerful a model became, the old cracks were still there. The AI system's clerk was still working mostly from whatever happened to be on the note in front of them. They still forgot everything between one visit and the next. When they didnâ€™t know something, they would still guess instead of checking. In other words, weâ€™d upgraded the clerk, but not the glass, not the office, and not the way work flowed around them.\n",
    "\n",
    "Then...came agents.\n",
    "\n",
    "Instead of a clerk answering one note at a time, we started asking that same clerk to run tasks, such as breaking down a goal, fetching information from the internet, and reading and updating complex code. Our polite assistant became a sort of project manager.\n",
    "\n",
    "In our metaphor, it was as if we took the clerk from behind the glass and said: \"Feel free to walk the halls. Use the phone, dig through the filing cabinets, talk to other departments, and come back with a finished result.\"\n",
    "\n",
    "This unlocked striking capabilities â€” but it also made the old problems impossible to ignore. Small ambiguities in instructions ballooned over ten or twenty steps. Missing background information meant the clerk confidently walked in the wrong direction for minutes at a time. Every task and its associated subtasks came with their own little note â€” their own tiny prompt â€” and suddenly the clerk wasn't wrestling with one interaction, but with a swarm of them, all slightly inconsistent.\n",
    "\n",
    "So, what do these issues look like if we were to crack open one of these agentic applications? Where do \"missing background,\" \"forgotten preferences,\" and that \"swarm of tiny prompts\" actually live?\n",
    "\n",
    "In practice, they all appear as distinct components of context surrounding a model call: the state and history you carry forward, the prompts and policies you apply, the memories you load, the documents you retrieve, and the structured outputs you expect to receive back. Visually, it looks something like this:\n",
    "\n",
    "![Context engineering overview](../public/ce-overview.png)\n",
    "\n",
    "Things like user input, operational databases, web APIs, and data warehouses all feed into the applicationâ€™s context layer. Everything inside that dashed red circle is what we, as engineers, design and control before a single token ever reaches the LLM. Instead of only asking, \"Whatâ€™s the right prompt?\" or \"Whatâ€™s the right model?\", we are now shifting to ask, â€œWhat information should be present at every step of this process, and how do we control it?â€\n",
    "\n",
    "That shift, from crafting individual notes to deliberately shaping the information surrounding the application, is what has become known as context engineering.\n",
    "\n",
    "Let's now ground this idea in an example application for a Redis University course agent (the same agent we built in this course) and watch how context engineering makes a difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context Engineering in Action\n",
    "\n",
    "We can imagine that at most universities today, one of the biggest pain points for learners is the time-suck of researching and selecting their academic classes for the year. In most cases, this involves a tedious process of waiting for their registration time slot to open (as often more senior students have priority), scrolling through various pages of courses/descriptions, and verifying if they meet the prerequisites, among other tasks. There are even dedicated roles designed to help students determine which classes are the right fit and assist them with their planning. \n",
    "\n",
    "As an engineer on an imaginary Redis University Innovation Team, our goal is to solve this issue by creating a seamless interface that helps expedite the research and selection process for a student's courses. \n",
    "\n",
    "Let's now imagine we did indeed build this agent and are running a pilot of the results with a subset of students. Let's examine a common scenario we want the agent to handle: a student seeking advice on which classes to take to help build a career in AI. \n",
    "\n",
    "To ground us, we'll use a sample student profile as our base: \n",
    "\n",
    "- Name: Olivia Jansen\n",
    "- Major: Computer Science\n",
    "- Year: Sophomore\n",
    "- Completed: Intro to Programming (CS101), Data Structures (CS201), Calculus I\n",
    "- Interests: Machine learning, Data science\n",
    "- Preferences: Prefers online courses, learns best with hands-on projects\n",
    "- Goal: Build a career in AI\n",
    "\n",
    "Olivia goes ahead and interacts with the agent and has the following results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>ğŸ”¶ Click the dropdown to review the conversation with the agent</summary>\n",
    "  <br>\n",
    "    \n",
    "**Turn 1:**\n",
    "\n",
    "*Student:* \"I'm interested in machine learning courses\"\n",
    "\n",
    "*Agent:* \"Here are all machine learning courses available:\n",
    "- CS301: Introduction to Machine Learning\n",
    "- CS401: Advanced Machine Learning\n",
    "- CS402: Deep Learning\n",
    "- CS403: Natural Language Processing\n",
    "- CS404: Computer Vision\n",
    "\n",
    "All courses meet twice per week on campus.\"\n",
    "\n",
    "---\n",
    "\n",
    "**Turn 2:**\n",
    "\n",
    "*Student:* \"I prefer online courses.\"\n",
    "\n",
    "*Agent:* \"Here are all machine learning courses available:\n",
    "- CS301: Introduction to Machine Learning\n",
    "- CS401: Advanced Machine Learning\n",
    "...\"\n",
    "\n",
    "Notice that the result is the same list, ignoring Olivia's preferences.\n",
    "\n",
    "---\n",
    "\n",
    "**Turn 3:**\n",
    "\n",
    "*Student:* \"Can I take CS401?\"\n",
    "\n",
    "*Agent:* \"CS401 requires CS301 as a prerequisite. Do you meet this requirement?\"\n",
    "\n",
    "The agent does not respond adequately as it doesn't know what courses the student has completed\n",
    "\n",
    "---\n",
    "\n",
    "**Turn 4:**\n",
    "\n",
    "*Student:* \"What about that intro course you mentioned earlier?\"\n",
    "\n",
    "*Agent:* \"I'm not sure which course you're referring to. Could you provide more details?\"\n",
    "\n",
    "The agent does not remember its old replies and has no context on what intro course was mentioned. \n",
    "\n",
    "---\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This advisor is intentionally simple, but its failure modes mirror those of real systems: it has no memory (canâ€™t recall prior turns), no personalization (ignores her preferences and background), and no awareness (doesnâ€™t know her history, canâ€™t check prerequisites, and cannot connect relevant information). The result is a frustrating experience that wastes time and delivers little value to the student.\n",
    "\n",
    "We don't want to leave our students feeling disappointed, so we spend some time applying some common context engineering techniques to our agent to improve the results. Now, let's examine the same agent, but with proper context management: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>ğŸ”¶ Click the dropdown to review the conversation with the agent with proper context management </summary>\n",
    "    <br>\n",
    "\n",
    "**Turn 1:**\n",
    "\n",
    "*Student:* \"I'm interested in machine learning courses.\"\n",
    "\n",
    "*Agent:* \"Great! Based on your Computer Science major and the courses you've completed (CS101 and CS201), you're ready for CS301: Introduction to Machine Learning.\n",
    "\n",
    "Since you prefer online courses and hands-on learning, I should mention that CS301 has:\n",
    "- A fully online section is available\n",
    "- Weekly programming assignments with real datasets\n",
    "- A final project where you build your own ML system\n",
    "\n",
    "This course aligns perfectly with your goal of building an AI career and serves as the foundation for more advanced ML courses.\"\n",
    "\n",
    "---\n",
    "\n",
    "**Turn 2:**\n",
    "\n",
    "*Student:* \"That sounds perfect! What comes after that?\"\n",
    "\n",
    "*Agent:* \"After completing CS301, you'll have several great options:\n",
    "\n",
    "**Immediately Available:**\n",
    "- CS402: Deep Learning (Online, project-based)\n",
    "  Focus: Neural networks, CNNs, RNNs\n",
    "  \n",
    "- CS403: Natural Language Processing (Online, project-based)\n",
    "  Focus: Text analysis, transformers, LLMs\n",
    "\n",
    "**Recommended Path for AI Career:**\n",
    "1. CS301 (Introduction) â† Start here\n",
    "2. CS402 (Deep Learning) â† Most relevant to modern AI\n",
    "3. CS403 (NLP) or CS404 (Computer Vision) â† Specialize\n",
    "\n",
    "Given your interest in data science, I'd especially recommend the NLP path - it combines well with your data structures background.\"\n",
    "\n",
    "---\n",
    "\n",
    "**Turn 3:**\n",
    "\n",
    "*Student:* \"How long will that path take?\"\n",
    "\n",
    "*Agent:* \"Let me break it down for you:\n",
    "\n",
    "**CS301:** 14 weeks (3 credits)\n",
    "**CS402:** 14 weeks (3 credits)  \n",
    "**CS403:** 14 weeks (3 credits)\n",
    "\n",
    "If you take one course per semester:\n",
    "- Fall 2024: CS301\n",
    "- Spring 2025: CS402\n",
    "- Fall 2025: CS403\n",
    "\n",
    "Since you're currently a Sophomore, this timeline would have you completing this sequence before graduation, with one semester remaining for an internship or capstone project.\n",
    "\n",
    "Alternatively, since these are online courses, you could potentially take CS301 this fall and CS402 in a winter intersession to accelerate your path.\"\n",
    "\n",
    "---\n",
    "\n",
    "**Turn 4:**\n",
    "\n",
    "*Student:* \"I like that accelerated option. Can I register now?\"\n",
    "\n",
    "*Agent:* \"Yes! Since you've met the prerequisites for CS301, I can guide you through registration. The online section (CS301-W01) has 15 seats remaining.\n",
    "\n",
    "Would you like me to:\n",
    "1. Reserve a seat for you in CS301-W01 for Fall 2024?\n",
    "2. Add you to the notification list for the Winter CS402 section (registration opens in October)?\n",
    "3. Send you the course syllabus and professor information?\"\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference in this interaction is stark compared to the previous. With proper context engineering, the advisor carries the context instead of the student: it remembers who Olivia is (major, completions, preferences), filters to relevant options (online, project-based ML), checks prerequisites automatically, turns choices into a sequenced plan and timeline, and can even propose recommended actions (register, notify, send syllabi). The result is a fast, personalized, high-confidence experience that actually delivers value.\n",
    "\n",
    "So, while in our example, we waved a magic wand and the agent was suddenly more effective, what actually goes into making this improvement happen? To grasp the techniques used, we must first explore the types of context that an AI system manages. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a complete context: the four pillars\n",
    "\n",
    "We can break down the most common context that goes into an AI application into four distinct types: \n",
    "\n",
    "1. System context\n",
    "2. User context\n",
    "3. Conversation context\n",
    "4. Retrieved context \n",
    "\n",
    "Each of these types plays a crucial role in making sure that an AI system has what it needs to properly respond. In this section, we'll explore each context type in more detail and setup a sample context to call a LLM (OpenAI). As you go through, make sure to run each code block that is provided as we build up the context and send it to a LLM at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. System Context: \"What Am I?\"\n",
    "\n",
    "System context (the type that is likely most familiar if you have prompted a AI system before) defines the AI's identity, capabilities, and knowledge. It is static, universal, and always present.\n",
    "\n",
    "It typically contains things like: \n",
    "- A role definition (\"You are a course advisor\")\n",
    "- Available tools and actions (`search_courses(query)`)\n",
    "- Domain knowledge and business rules (\"CS401 requires CS301\")\n",
    "- Behavioral guidelines (\"Ask one clarifying question at a time\")\n",
    "\n",
    "Below is an example of system context (also commonly called the system prompt) for our Redis University agent. Run the code block to create the context. We'll use it shortly when we assemble the full context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_context = \"\"\"You are a Redis University course advisor.\n",
    "\n",
    "Guidelines:\n",
    "1. Always provide specific course recommendations with clear reasoning\n",
    "2. Consider the student's background, completed courses, and interests\n",
    "3. Ensure prerequisites are met before recommending advanced courses\n",
    "4. Be encouraging and supportive in your guidance\n",
    "\"\"\"\n",
    "\n",
    "print(\"âœ… System context created successfully!\")\n",
    "print(system_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### 2. User Context: \"Who Are You?\"\n",
    "\n",
    "Next is the user context. This type of context contains personal information about the specific user. It is typically dynamic, personalized, and retrieved from storage. \n",
    "\n",
    "It typically contains: \n",
    "- Profile information (major, year, background)\n",
    "- Preferences and learning style (\"prefers online/asynchronous\")\n",
    "- History and achievements (\"completed CS101/CS201/Calc I\")\n",
    "- Goals and constraints (\"Evening and weekends\")\n",
    "\n",
    "We have already seen an example of user context when we defined Olivia's user profile and preferences earlier. Run the code block below to create the sample profile in the notebook environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olivia_profile = {\n",
    "    \"name\": \"Olivia Jansen\",\n",
    "    \"background\": \"Sophomore student in a computer science major\",\n",
    "    \"completed_courses\": [\"CS001, CS201, MATH024\"],\n",
    "    \"interests\": [\"machine learning\", \"data science\"],\n",
    "    \"time_availability\": \"evenings and weekends\",\n",
    "    \"goal\": \"Build a career in AI\",\n",
    "}\n",
    "\n",
    "print(\"âœ… User context for Olivia created successfully!\")\n",
    "print(olivia_profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: In production, the above context would likely be retrieved from a database, but we have hardcoded it for demonstration purposes above. \n",
    "\n",
    "Since we will be using this profile to call an LLM (OpenAI), we do need to perform one more step to prepare it for later. The OpenAI API requires message content to be a string, so we need to convert our dictionary from above to text. We have two options to accomplish this goal:\n",
    "\n",
    "1. Send it as a JSON string: `json.dumps(olivia_profile)`\n",
    "2. Format it as natural language: Use a formatting function for better readability and control\n",
    "\n",
    "We'll use option 2 because it's more readable and gives us precise control over how the information is presented to the LLM. This type of data transformation â€” converting structured data into LLM-friendly formats â€” is actually a core context engineering technique that we'll explore in further detail throughout this course.\n",
    "\n",
    "Now, run the code block below to create the function and format Olivia's profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_user_context(profile):\n",
    "    \"\"\"Convert user profile dictionary to formatted context string\"\"\"\n",
    "    return f\"\"\"Student Profile:\n",
    "- Name: {profile['name']}\n",
    "- Background: {profile['background']}\n",
    "- Completed Courses: {', '.join(profile['completed_courses'])}\n",
    "- Interests: {', '.join(profile['interests'])}\n",
    "- Availability: {profile['time_availability']}\n",
    "- Goal: {profile['goal']}\n",
    "\"\"\"\n",
    "\n",
    "user_context = format_user_context(olivia_profile)\n",
    "print(\"Formatted Context:\", user_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Conversation Context: \"What Have We Discussed?\"\n",
    "\n",
    "Conversation context is one of the most important types of context since it represents the history of the current conversation. Typically, this is implemented in the form of memory (short-term and long-term). It is dynamic, session-specific, and will grow over time. \n",
    "\n",
    "It typically contains: \n",
    "- Previous user messages\n",
    "- Previous AI responses\n",
    "- Decisions and commitments made\n",
    "- Topics explored\n",
    "\n",
    "Like user context, we also saw an example of conversational context earlier:\n",
    "\n",
    "```\n",
    "Turn 1:\n",
    "User: \"I'm interested in machine learning courses.\"\n",
    "AI: \"I recommend CS301: Introduction to Machine Learning...\"\n",
    "\n",
    "Turn 2:\n",
    "User: \"What comes after that course?\"\n",
    "[Current query - needs context from Turn 1 to understand \"that course\"]\n",
    "AI: \"After CS301, you can take CS402 or CS403...\"\n",
    "\n",
    "Turn 3:\n",
    "User: \"How long will that path take?\"\n",
    "[Current query - needs context from Turn 2 to understand \"that path\"]\n",
    "```\n",
    "\n",
    "In this notebook, since we don't have an explicit chat interface to interact with, we will simulate a conversation history by manually creating a list of message dictionaries. In a real application, this list would be dynamically built as users interact with the system, but here we'll pre-populate it to demonstrate how conversation context works.\n",
    "\n",
    "Examine and then run the code block below. Note that it will execute silently, as we will observe in just a moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Start with an empty conversation history\n",
    "conversation_history = []\n",
    "\n",
    "# Step 2: Add the first user message\n",
    "conversation_history.append(\n",
    "    {\"role\": \"user\", \"content\": \"What Redis course should I take next?\"}\n",
    ")\n",
    "\n",
    "# Step 3: Add the AI's response (simulated)\n",
    "conversation_history.append(\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"\"\"Based on your Python background and completion of RU101, \n",
    "I recommend RU201: Redis for Python Developers. This course will teach you \n",
    "how to build Redis applications using redis-py, which aligns perfectly with \n",
    "your goal of building a RAG system.\"\"\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Step 4: Add a follow-up question that references previous context\n",
    "conversation_history.append(\n",
    "    {\"role\": \"user\", \"content\": \"How long will that take me to complete?\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice above that the user said \"that\" instead of \"RU201\" in the query. \n",
    "\n",
    "The AI needs the conversation history to understand what \"that\" refers to. Let's view the complete conversation history. Run the code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, msg in enumerate(conversation_history, 1):\n",
    "    print(f\"Turn {i} ({msg['role']}):\")\n",
    "    print(f\"{msg['content']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Retrieved Context: \"What Information Is Relevant?\"\n",
    "\n",
    "Lastly, there is retrieved context. This is information fetched on demand based on the current query. This involves the system retrieving specific and relevant context across other systems.\n",
    "\n",
    "It typically contains: \n",
    "- Database records (course details, schedules)\n",
    "- Search results (relevant documents, FAQs)\n",
    "- API responses (real-time data, availability)\n",
    "- Computed information (eligibility checks, recommendations)\n",
    "\n",
    "For example, if a student asked the Redis University agent about \"CS301\", the system would need to find any relevant context to respond to the query. For instance, it would call a course catalog database, find the CS301 course, and retrieve information like course details (description, prerequisites, format), current availability (X seats in online section), and professor ratings and reviews.\n",
    "\n",
    "Let's simulate what retrieved context will look like by hard-coding course content. \n",
    "\n",
    "Run the code block below (it will execute silently)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_database = {\n",
    "    \"RU101\": {\n",
    "        \"title\": \"Introduction to Redis Data Structures\",\n",
    "        \"level\": \"Beginner\",\n",
    "        \"description\": \"Master Redis fundamentals: strings, hashes, lists, sets, and sorted sets\",\n",
    "        \"duration\": \"4-6 hours\",\n",
    "        \"prerequisites\": [],\n",
    "        \"topics\": [\"Data structures\", \"Basic commands\", \"Use cases\"],\n",
    "    },\n",
    "    \"RU201\": {\n",
    "        \"title\": \"Redis for Python Developers\",\n",
    "        \"level\": \"Intermediate\",\n",
    "        \"description\": \"Build production Redis applications with Python and redis-py\",\n",
    "        \"duration\": \"6-8 hours\",\n",
    "        \"prerequisites\": [\"RU101\", \"Python experience\"],\n",
    "        \"topics\": [\"redis-py library\", \"Connection pooling\", \"Pipelining\", \"Pub/Sub\"],\n",
    "    },\n",
    "    \"RU202\": {\n",
    "        \"title\": \"Redis for Java Developers\",\n",
    "        \"level\": \"Intermediate\",\n",
    "        \"description\": \"Build production Redis applications with Java and Jedis\",\n",
    "        \"duration\": \"6-8 hours\",\n",
    "        \"prerequisites\": [\"RU101\", \"Java experience\"],\n",
    "        \"topics\": [\n",
    "            \"Jedis library\",\n",
    "            \"Connection pooling\",\n",
    "            \"Transactions\",\n",
    "            \"Redis Streams\",\n",
    "        ],\n",
    "    },\n",
    "    \"RU301\": {\n",
    "        \"title\": \"Vector Similarity Search with Redis\",\n",
    "        \"level\": \"Advanced\",\n",
    "        \"description\": \"Implement semantic search and RAG systems with Redis vector capabilities\",\n",
    "        \"duration\": \"8-10 hours\",\n",
    "        \"prerequisites\": [\"RU201 or RU202\", \"ML/AI interest\"],\n",
    "        \"topics\": [\n",
    "            \"Vector embeddings\",\n",
    "            \"Semantic search\",\n",
    "            \"RAG architecture\",\n",
    "            \"Hybrid search\",\n",
    "        ],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's simulate retrieving course information based on a query. Just like before, we'll need to transform the data. Run the code block below to create the function and simulate the retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create a retrieval function\n",
    "\n",
    "def retrieve_course_info(course_code):\n",
    "    \"\"\"Retrieve detailed information about a specific course\"\"\"\n",
    "    course = course_database.get(course_code)\n",
    "    if not course:\n",
    "        return None\n",
    "\n",
    "    return f\"\"\"Course Details:\n",
    "        Code: {course_code}\n",
    "        Title: {course['title']}\n",
    "        Level: {course['level']}\n",
    "        Description: {course['description']}\n",
    "        Duration: {course['duration']}\n",
    "        Prerequisites: {', '.join(course['prerequisites']) if course['prerequisites'] else 'None'}\n",
    "        Topics Covered: {', '.join(course['topics'])}\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "# Retrieve information about RU201\n",
    "retrieved_context = retrieve_course_info(\"RU201\")\n",
    "print(retrieved_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bringing It All Together: Complete Context Integration\n",
    "\n",
    "Now that we have explored each context type individually, let's see how they work together to create an intelligent and personalized response.\n",
    "\n",
    "Here's how all four context types will combine in a single LLM call:\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚           COMPLETE LLM REQUEST              â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚ 1. SYSTEM CONTEXT (Static)                  â”‚\n",
    "â”‚    - Role: \"You are a course advisor\"       â”‚\n",
    "â”‚    - Domain: Available courses              â”‚\n",
    "â”‚    - Rules: Guidelines and constraints      â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚ 2. USER CONTEXT (Dynamic - User Specific)   â”‚\n",
    "â”‚    - Profile: Sarah Chen, Python dev        â”‚\n",
    "â”‚    - History: Completed RU101               â”‚\n",
    "â”‚    - Goal: Build RAG system                 â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚ 3. CONVERSATION CONTEXT (Dynamic - Session) â”‚\n",
    "â”‚    - User: \"What course should I take?\"     â”‚\n",
    "â”‚    - AI: \"I recommend RU201...\"             â”‚\n",
    "â”‚    - User: \"How long will that take?\"       â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚ 4. RETRIEVED CONTEXT (Dynamic - Query)      â”‚\n",
    "â”‚    - RU201 course details                   â”‚\n",
    "â”‚    - Duration, prerequisites, topics        â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚ RESULT: Personalized, context-aware answer  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "Let's add them together into a messages list. Run the following code block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Start with system context\n",
    "messages = [{\"role\": \"system\", \"content\": system_context}]\n",
    "\n",
    "# Step 2: Add user context\n",
    "messages.append({\"role\": \"system\", \"content\": user_context})\n",
    "\n",
    "# Step 3: Add conversation history\n",
    "messages.extend(conversation_history)\n",
    "\n",
    "# Step 4: Add retrieved context\n",
    "messages.append({\"role\": \"system\", \"content\": retrieved_context})\n",
    "\n",
    "# Check the final messages structure\n",
    "for i, msg in enumerate(messages, 1):\n",
    "    print(f\"Message {i} ({msg['role']}):\")\n",
    "    print(f\"{msg['content']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can use the context to call the LLM. Run the code block below to initaite the call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI, AsyncOpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"],          \n",
    "    base_url=os.environ[\"OPENAI_API_BASE\"],         \n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "To recap what just happened, we sent an assembled context to the LLM. It received all four context types and used them to generate a personalized response:\n",
    "\n",
    "1. **System Context** told it to act as a course advisor and provided course information\n",
    "2. **User Context** gave it Sarah's background, interests, and goals\n",
    "3. **Conversation Context** showed that \"that\" refers to RU201\n",
    "4. **Retrieved Context** provided detailed information about RU201's duration and topics\n",
    "\n",
    "The result is a response that:\n",
    "- Understands what course \"that\" refers to\n",
    "- Considers Olivia's available time (evenings and weekends)\n",
    "- Relates the duration to her specific situation\n",
    "- Stays aligned with her goal of building a RAG system\n",
    "\n",
    "While this was a simple example, it demonstrated all four layers of context that we will be managing throughout this course. \n",
    "\n",
    "As the agent we'll build becomes increasingly complex, these same principles will apply â€” but the techniques for managing, optimizing, and orchestrating these contexts will become increasingly sophisticated.\n",
    "\n",
    "And yet...even the most perfectly engineered has one problem to be aware of: the finite size of the model's context window. \n",
    "\n",
    "In the next section, we'll explore this constraint and learn about one of the most important parts of managing context in AI systems. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Fundamental Challenge: Context Windows\n",
    "\n",
    "These days, even the most powerful AI models have a big limitation: they can only process a fixed amount of text in a single request.\n",
    "\n",
    "This fixed amount is called the **context window**, and is essentially the size of our metaphorical clerk's desk. \n",
    "\n",
    "For example, here are the context window sizes of some of the most popular models available today:\n",
    "\n",
    "| Model | Context Window |\n",
    "|-------|----------------|\n",
    "| GPT-4o | 128,000 tokens (~96,000 words) |\n",
    "| GPT-4o-mini | 128,000 tokens (~96,000 words) |\n",
    "| Claude 3.5 Sonnet | 200,000 tokens (~150,000 words) |\n",
    "\n",
    "The limits above might look generous, but when we break it down, we have a ton of different context competing for space this space. Here is an example context budget breakdown for a single turn using a modeL:\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚   CONTEXT WINDOW - 128K tokens      â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚ System Context    â”‚ 2,000 tokens    â”‚  â† AI's role and rules\n",
    "â”‚ User Context      â”‚ 1,000 tokens    â”‚  â† Your profile\n",
    "â”‚ Conversation      â”‚ 4,000 tokens    â”‚  â† What we've discussed\n",
    "â”‚ Retrieved Info    â”‚ 5,000 tokens    â”‚  â† Relevant data\n",
    "â”‚ Your Query        â”‚ 100 tokens      â”‚  â† Current question\n",
    "â”‚ Response Space    â”‚ 4,000 tokens    â”‚  â† AI's answer\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚ TOTAL TOKENS      â”‚ 16,100 tokens   â”‚\n",
    "â”‚ REMAINING TOKENS  â”‚ 111,900 tokens  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "That remaining space (111,900) might look comforting but remember this is just one turn. Our inputs will likely only grow longer (think a long conversation history), and as they do, models have a harder time producing effective results for tasks. \n",
    "\n",
    "In fact, [Chroma](https://www.trychroma.com/) (a leading AI research company) revealed a critical challenge related to working with LLMs and their context window: [context rot](https://research.trychroma.com/context-rot) - the phenomenon where LLM performance degrades non-uniformly as input context length increases, even with simple tasks.\n",
    "\n",
    "If we summarized the research findings around the size of context, it would break out into the following: \n",
    "\n",
    "1. Longer context â‰  better context: Reliability drops and accelerates as inputs grow. This means we should treat the window like working memory; budget tokens when possible and keep the slice small.\n",
    "\n",
    "2. Relevance rules: High semantic match drives accuracy; loosely related text hurts. We should prioritize optimizing retrieval precision (rerank, tighten filters, rewrite queries).\n",
    "\n",
    "3. Distractors are toxic: Similar but wrong snippets do disproportionate damage as length increases. To reduce distractors, we should aggressively filter/threshold, dedupe, and avoid \"just in case\" context.\n",
    "\n",
    "4. Placement & structure matter: Models attend unevenly across the window; key facts can be missed when buried. We should surface essentials early, chunk clearly, and summarize instead of pasting raw dumps. \n",
    "\n",
    "Remember, every token spent on one thing is a token NOT available for another. This means when we build these systems, we must constantly decide:\n",
    "\n",
    "- Which context is most relevant?\n",
    "- What can be omitted without hurting quality?\n",
    "- When to retrieve more vs. use what you have?\n",
    "- How to compress long conversations?\n",
    "\n",
    "This makes context engineering a practice of optimization within constraints. As conversations grow longer, systems accumulate more data, and applications become more sophisticated, context management becomes increasingly critical.\n",
    "\n",
    "While managing the size of your context window is critical, simply fitting everything in isn't the only hurdle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Challenges of Managing Context\n",
    "\n",
    "D. Breunig highlights in [How Contexts Fail (and How to Fix Them)](https://www.dbreunig.com/2025/06/22/how-contexts-fail-and-how-to-fix-them.html) that there are several other ways context can degrade the performance of your agent, even when you are well within the token limits.\n",
    "\n",
    "He mentions four key failure modes to watch out for:\n",
    "\n",
    "1.  **Context Poisoning**: This occurs when an error or hallucination makes its way into your context (e.g., conversation history) and is then treated as fact in subsequent turns. The model \"learns\" the wrong information from its own previous output, leading to a loop of compounding errors.\n",
    "\n",
    "2.  **Context Distraction**: Sometimes, having *too much* history can be detrimental. If an agent has a massive log of past actions, it may start to over-focus on repeating those past behaviors rather than reasoning about the current, novel situation. It relies on its \"contextual habit\" instead of its training.\n",
    "\n",
    "3.  **Context Confusion**: This happens when the context is cluttered with superfluous informationâ€”such as too many available tools or irrelevant document snippets. Even if the model *could* ignore them, the mere presence of these \"distractors\" increases the probability of the model getting confused or trying to use a tool that isn't needed.\n",
    "\n",
    "4.  **Context Clash**: This is when different parts of your context contradict each other. For example, your system prompt might say one thing, but a retrieved document or an early turn in the conversation history contradicts it. When the model faces this internal conflict, its reasoning capabilities often degrade significantly.\n",
    "\n",
    "Understanding these failure modes reinforces why context engineering is not just about *compression*â€”it's about *curation*. We must actively manage, clean, and sometimes even \"forget\" context to keep our agents sharp.\n",
    "\n",
    "It's essential to note that in this course, we will not necessarily solve every one of these failure modes. Some, like context poisoning, remain as complex open research problems in AI. However, we will systematically dismantle the most common ones by building a series of \"progressive agents,\" each designed to overcome specific context limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap Up\n",
    "\n",
    "In this introduction, we started to explore how real AI applications depend on carefully constructed context. More specifically, we covered the following:\n",
    "\n",
    "1. Context engineering is the practice of deliberately shaping the information surrounding an application, rather than just crafting individual prompts.\n",
    "2. There are four types of context we will focus on: system context, user context, conversation context, and retrieved context.\n",
    "3. All LLMs have fixed context windows, creating a fundamental constraint where every token used for one purpose is unavailable for another.\n",
    "4. Context rot is a phenomenon where LLM performance degrades as input context length increases, even on simple tasks.\n",
    "5. Context failures such as distraction, confusion, and clash occur when irrelevant or contradictory information is present in the context window.\n",
    "\n",
    "You're now ready to start building. In the next notebook (`project_overview`), we will outline the specific project we will be working on: a Redis University course advisor agent. We will examine the available data, the tools we will develop, and the \"progressive agent\" architecture we will follow to transform our agent from a basic RAG to a context-aware Q&A agent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
