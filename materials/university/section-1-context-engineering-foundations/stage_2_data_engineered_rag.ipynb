{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba3d772d",
   "metadata": {},
   "source": [
    "# Stage 2: Data-Engineered RAG\n",
    "\n",
    "In Stage 1, our baseline RAG agent played it safe and sent everything: full-course objects, verbose fields, and lengthy descriptions. That worked, but it came at a cost ‚Äî simple questions like *\"What computer science courses are available?\"* could trigger 5,000+ extra tokens of context.\n",
    "\n",
    "Before we move on to a richer agent architecture (like a ReAct agent), we‚Äôre going to pause and ask a simpler question:\n",
    "\n",
    "> ‚ÄúWhat if we just got smarter about the data we send?‚Äù\n",
    "\n",
    "In this stage, we‚Äôll keep the same basic RAG pattern, but engineer the context itself. Since context is just data, we can apply lightweight data engineering techniques to make it more efficient and cleaner for the LLM to consume.\n",
    "\n",
    "More specifically, we‚Äôll:\n",
    "\n",
    "1. Trim the data: We'll remove noise fields and unnecessary detail so the model only sees what it needs. In most cases, this will be the core course content, including descriptions, learning objectives, and other relevant details.   \n",
    "2. Transform the format into LLM-friendly text: We'll take the raw JSON/course objects and convert them into natural, human-readable text that LLMs handle more easily.\n",
    "3. Context depth control: We'll use compact course summaries when we need an overview, and keep full details for when they‚Äôre truly needed.\n",
    "4. Experiment:  We'll see how the token count changes compared to our original baseline RAG call.\n",
    "\n",
    "That last point will serve as a gentle introduction to a powerful concept known as progressive disclosure: Start with a brief summary view and reveal full details only upon demand. \n",
    "\n",
    "In this stage, you‚Äôll see progressive disclosure in action through ‚Äúsummary vs. full‚Äù course representations, and in the next stage, we‚Äôll push this further inside a full agent loop.\n",
    "\n",
    "With just these small changes, you‚Äôll see how we can reduce the context size (tokens) by around 50% while maintaining answer quality essentially unchanged.\n",
    "\n",
    "Let‚Äôs dive in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1816a20",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Let's set up our environment and import the stage 2 agent. Run the code blocks below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffa9c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code sets up the notebook to be able to access the provided OpenAI API Key and access to the agent code\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "if \"OPENAI_API_BASE\" in os.environ:\n",
    "    os.environ[\"OPENAI_BASE_URL\"] = os.environ[\"OPENAI_API_BASE\"]\n",
    "\n",
    "project_root = Path(\"..\").resolve()\n",
    "\n",
    "stage1_path = project_root / \"progressive_agents\" / \"stage2_data_engineered\"\n",
    "src_path = project_root / \"src\"\n",
    "\n",
    "sys.path.insert(0, str(src_path))\n",
    "sys.path.insert(0, str(stage1_path))\n",
    "\n",
    "print('OpenAI API key and agent access setup!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37ed621",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from agent import setup_agent\n",
    "\n",
    "print(\"Initializing Stage 2 Agent...\")\n",
    "# This reuses the same Redis data from Stage 1 (or generates it if missing)\n",
    "workflow, course_manager = setup_agent(auto_load_courses=True, verbose=True)\n",
    "print(\"Agent is ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1969ff54-91ae-4a35-bb60-8b51a0e66cac",
   "metadata": {},
   "source": [
    "## Optimization: Human-Readable, LLM-Friendly Course Text\n",
    "Our course data currently resides in a structured `Course` object that mirrors how it's stored in the Redis database: numerous fields, some student-facing and some purely system-facing. In Stage 1, we essentially dumped that structure into the prompt, which meant the LLM had to parse a lot of syntax and noise it did not really need.\n",
    "\n",
    "There are two things to note about this approach:\n",
    "1. JSON-style representations are full of extra characters: quotes, braces, commas, and field names.\n",
    "2. The shape is designed for machines and storage, not for a model trying to answer a question in natural language.\n",
    "\n",
    "For example, think about the difference between these two versions of the same idea:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"course_code\": \"CS101\",\n",
    "  \"title\": \"Introduction to Computer Science\",\n",
    "  \"department\": \"Computer Science\"\n",
    "}\n",
    "```\n",
    "versus\n",
    "```txt\n",
    "CS101: Introduction to Computer Science\n",
    "Department: Computer Science\n",
    "```\n",
    "\n",
    "The first version spends tokens on punctuation and keys; the second goes straight to the meaning. Across dozens or hundreds of courses, that extra syntax turns into a lot of wasted tokens.\n",
    "\n",
    "In this section, you will build `transform_course_to_text`, a function that reshapes a `Course` object into a compact, human-readable description. More specifically, we will accomplish the following:\n",
    "\n",
    "1. Get rid of  system-oriented fields like IDs and timestamps\n",
    "2. Remove null and empty fields (e.g., when a course has no prerequesites)\n",
    "3. Organize the important fields (title, level, format, instructor, prerequisites, learning objectives) into a simple text block that an LLM can scan easily\n",
    "\n",
    "The result will be a prompt-ready course description that is both easier for the model to work with and significantly cheaper in tokens than sending the raw object or its JSON representation.\n",
    "\n",
    "Start by running the cell below to inspect a sample `Course` instance in its original form.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3be2c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from redis_context_course.models import Course, DifficultyLevel, CourseFormat\n",
    "\n",
    "# A dummy course for testing purposes\n",
    "sample_course = Course(\n",
    "    id=\"course_cs009\",\n",
    "    course_code=\"CS009\",\n",
    "    title=\"Computer Vision\",\n",
    "    department=\"Computer Science\",\n",
    "    major=\"Computer Science\",\n",
    "    credits=4,\n",
    "    difficulty_level=DifficultyLevel.ADVANCED,\n",
    "    format=CourseFormat.HYBRID,\n",
    "    semester=\"fall\",\n",
    "    year=2025,\n",
    "    max_enrollment=100,\n",
    "    current_enrollment=0,\n",
    "    instructor=\"Kayla Perez\",\n",
    "    description=(\n",
    "        \"This course teaches students how to build systems that can see and understand visual data.\"\n",
    "    ),\n",
    "    prerequisites=[\n",
    "        {\n",
    "            \"course_code\": \"CS002\",\n",
    "            \"course_title\": \"Prerequisite Course 2\",\n",
    "            \"minimum_grade\": \"C\",\n",
    "            \"can_be_concurrent\": False,\n",
    "        }\n",
    "    ],\n",
    "    learning_objectives=[\n",
    "        \"Understand core concepts in computer vision\",\n",
    "        \"Implement computer vision algorithms and techniques\",\n",
    "        \"Apply computer vision to real-world problems\",\n",
    "        \"Analyze and evaluate computer vision solutions\",\n",
    "        \"Design and build complete computer science systems\",\n",
    "    ],\n",
    "    created_at=\"2023-01-01T00:00:00Z\",\n",
    "    updated_at=\"2023-06-01T00:00:00Z\",\n",
    ")\n",
    "\n",
    "print(\"--- Raw Course Data (JSON) ---\")\n",
    "print(sample_course.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8293a224-31ef-4158-ba7e-97e2bef6f0c5",
   "metadata": {},
   "source": [
    "Now that we have the baseline, it's time to define the function that will transform the data.\n",
    "\n",
    "### üìå Task 1: Transform the course data\n",
    "\n",
    "Your goal is to convert a `Course` object from its structured form into clean, human-readable text that's optimized for LLM consumption. This transformation removes database artifacts (IDs, timestamps), eliminates empty fields, and formats the essential information using natural language instead of JSON syntax.\n",
    "\n",
    "Your function should produce clean, formatted text like this:\n",
    "\n",
    "```\n",
    "CS009: Computer Vision\n",
    "Department: Computer Science\n",
    "Credits: 4\n",
    "Level: advanced\n",
    "Format: hybrid\n",
    "Instructor: Kayla Perez\n",
    "Prerequisites: CS002\n",
    "Description: This course teaches students how to build systems that can see and understand visual data.\n",
    "Learning Objectives:\n",
    "  - Understand core concepts in computer vision\n",
    "  - Implement computer vision algorithms and techniques\n",
    "  - Apply computer vision to real-world problems\n",
    "  - Analyze and evaluate computer vision solutions\n",
    "  - Design and build complete computer science systems\n",
    "```\n",
    "\n",
    "<details>\n",
    "<summary>üõ†Ô∏è Show Implementation Details</summary>\n",
    "<br>\n",
    "\n",
    "Requirements:\n",
    "\n",
    "1. Input: A `Course` object\n",
    "2. Output: A formatted string\n",
    "3. Fields: Code, Title, Department, Credits, Level, Format, Instructor, Description\n",
    "4. Conditional fields: Include prerequisites and learning objectives only if they exist\n",
    "5. Excluded Fields: ID, timestamps, enrollment numbers\n",
    "6. Format: Use clean `Key: Value` format with proper line breaks\n",
    "\n",
    "**Implementation Steps:**\n",
    "\n",
    "**Step 1: Build prerequisites text**\n",
    "\n",
    "Check if `course.prerequisites` exists. If it does:\n",
    "- Extract just the `course_code` from each prerequisite object\n",
    "- Join them with commas: `\", \".join([p.course_code for p in course.prerequisites])`\n",
    "- Store as `prereq_text`\n",
    "\n",
    "**Step 2: Build learning objectives text**\n",
    "\n",
    "Check if `course.learning_objectives` exists. If it does:\n",
    "- Format each objective as a bulleted item with `\"  - \"` prefix\n",
    "- Join them with newlines\n",
    "- Add a leading newline before the list\n",
    "- Store as `objectives_text`\n",
    "\n",
    "**Step 3: Build the formatted course text**\n",
    "\n",
    "Create an f-string that includes:\n",
    "- Course code and title on the first line\n",
    "- Department, Credits, Level, Format, Instructor on separate lines\n",
    "- Prerequisites line (using the prereq_text you built)\n",
    "- Description\n",
    "- Learning Objectives header followed by objectives_text\n",
    "\n",
    "Use `course.difficulty_level.value` and `course.format.value` to access enum values.\n",
    "\n",
    "</details>\n",
    "\n",
    "Feel free to reference the solution code to compare your own code or if you feel stuck. The code can also be run at any point to test the output based on the sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038cd261-23d4-4224-8e89-6e324abe220f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def transform_course_to_text(course: Course) -> str:\n",
    "    \"\"\"\n",
    "    Transform course object to LLM-optimized text format.\n",
    "    \n",
    "    Args:\n",
    "        course: Course object to transform\n",
    "    \n",
    "    Returns:\n",
    "        LLM-friendly text representation\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: Build prerequisites text\n",
    "    prereq_text = \"\"\n",
    "    \n",
    "    # TODO: Build learning objectives text  \n",
    "    objectives_text = \"\"\n",
    "    \n",
    "    # TODO: Build and return the formatted course text\n",
    "    course_text = \"\"\n",
    "    \n",
    "    return course_text\n",
    "\n",
    "print(\"‚úÖ Transform function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3366287-b636-4fd7-8f5f-a2f05c678580",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üóùÔ∏è Solution code</summary>\n",
    "<br>\n",
    "    \n",
    "```python\n",
    "\n",
    "def transform_course_to_text(course: Course) -> str:\n",
    "    \"\"\"\n",
    "    Transform course object to LLM-optimized text format.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Build prerequisites text (no leading newline)\n",
    "    prereq_text = \"\"\n",
    "    if course.prerequisites:\n",
    "        prereq_codes = [p.course_code for p in course.prerequisites]\n",
    "        prereq_text = f\"{', '.join(prereq_codes)}\"\n",
    "\n",
    "    # Build learning objectives text (no leading newline)\n",
    "    objectives_text = \"\"\n",
    "    if course.learning_objectives:\n",
    "        objectives_text = \"\\n\" + \"\\n\".join(\n",
    "            f\"  - {obj}\" for obj in course.learning_objectives\n",
    "        )\n",
    "\n",
    "    # Build course text\n",
    "    course_text = f\"\"\"{course.course_code}: {course.title}\n",
    "Department: {course.department}\n",
    "Credits: {course.credits}\n",
    "Level: {course.difficulty_level.value}\n",
    "Format: {course.format.value}\n",
    "Instructor: {course.instructor}\n",
    "Prerequisites: {prereq_text}\n",
    "Description: {course.description}\n",
    "Learning Objectives:{objectives_text}\n",
    "\"\"\"\n",
    "\n",
    "    return course_text\n",
    "\n",
    "print(\"‚úÖ Transform function defined!\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41696340",
   "metadata": {},
   "source": [
    "Lastly, we'll need to attach the function to our agent for later. Run the code block below to accomplish this goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a8217f-cd6e-4959-a1d3-6bec79fc32ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import agent.data_engineering\n",
    "\n",
    "# Inject our function into the agent's module\n",
    "agent.data_engineering.transform_course_to_text = transform_course_to_text\n",
    "\n",
    "print(\"‚úÖ Successfully injected the custom function into the agent!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1a32e3-2634-40b3-a252-744b9afcd559",
   "metadata": {},
   "source": [
    "## Optimization: Ultra-Compact Course Summaries\n",
    "\n",
    "We've successfully reshaped a Course object into a clean, human-readable description. That format is much better for the LLM than raw JSON and is significantly cheaper in terms of tokens, but it is still fairly detailed, including a full description, learning objectives, prerequisites, and more.\n",
    "\n",
    "Before we start testing that format in our RAG agent, we will build one more representation: an ultra-compact version that retains only the bare essentials. This gives us a third option to compare. So we'll have:\n",
    "\n",
    "1. A raw JSON / full object (what we started with in Stage 1)\n",
    "2. A human-readable full-text description (`transform_course_to_text`)\n",
    "3. An ultra-compact one-line summary (`compact_course_text`)\n",
    "\n",
    "Why do we need something this small? Well, in realistic systems, there are many situations where you don't want full details for every item. For example, when you are listing dozens of courses as a quick menu, or scanning over search results, you mostly need a short sketch: course code, title, a hint of what it is about, and maybe whether it has prerequisites.\n",
    "\n",
    "This is where the idea of progressive disclosure starts to become practical. You can imagine a flow where the ultra-compact text is used for broad overviews or lists, and the full text representation is used only for the few items the user seems to care about."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55ac64b-7a1a-4fb3-b64c-48655e3b1ae3",
   "metadata": {},
   "source": [
    "### üìå Task 2: Create a compact course text representation\n",
    "\n",
    "Your goal is to create an ultra-compact, single-line course representation that preserves only the bare essentials. This format is ideal for scenarios where you need to display multiple courses simultaneously (such as search result lists) or when you want to minimize token usage while still providing enough information for users to identify relevant courses.\n",
    "\n",
    "Your function should produce a single-line format like this:\n",
    "\n",
    "```\n",
    "CS009: Computer Vision - This course teaches students how to build systems that can see and understand visual data.... (Prereq: CS002)\n",
    "```\n",
    "\n",
    "<details>\n",
    "<summary>üõ†Ô∏è Show Implementation Details</summary>\n",
    "<br>\n",
    "\n",
    "**Requirements:**\n",
    "\n",
    "1. Input: A `Course` object\n",
    "2. Output: A single-line string\n",
    "3. Format: `Code: Title - Description (truncated)... (Prereq: codes)`\n",
    "4. Truncate: Description to 100 characters\n",
    "5. Conditional Fields: Include prerequisites only if they exist\n",
    "\n",
    "**Implementation Steps:**\n",
    "\n",
    "**Step 1: Build prerequisites text**\n",
    "\n",
    "Check if `course.prerequisites` exists. If it does:\n",
    "- Extract just the `course_code` from each prerequisite object\n",
    "- Join them with commas\n",
    "- Format as: `\" (Prereq: CODE1, CODE2)\"`\n",
    "- If no prerequisites exist, use an empty string\n",
    "\n",
    "Store this as `prereqs`.\n",
    "\n",
    "**Step 2: Build the compact format**\n",
    "\n",
    "Create a single-line string with:\n",
    "- Course code and title: `f\"{course.course_code}: {course.title}\"`\n",
    "- Truncated description: Use string slicing `course.description[:100]` followed by `\"...\"`\n",
    "- Prerequisites: Append the `prereqs` string you built\n",
    "\n",
    "Use an f-string to combine all parts: `f\"{code}: {title} - {truncated_description}...{prereqs}\"`\n",
    "\n",
    "</details>\n",
    "\n",
    "Feel free to reference the solution code to compare your own code or if you feel stuck. The code can also be run at any point to test the output based on the sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9e9bea-ccec-40c5-88a9-0b31749ab9d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def compact_course_text(course: Course) -> str:\n",
    "    \"\"\"\n",
    "    Create an ultra-compact course description.\n",
    "\n",
    "    Reduces token count while preserving essential information.\n",
    "\n",
    "    Use this when you need maximum token efficiency (e.g., many courses).\n",
    "    Use transform_course_to_text() when you need full details.\n",
    "\n",
    "    Args:\n",
    "        course: Course object to optimize\n",
    "\n",
    "    Returns:\n",
    "        Compact text representation\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: Build prerequisites text\n",
    "    prereqs = \"\"\n",
    "    \n",
    "    # TODO: Build and return the compact format\n",
    "    \n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76547fa5-1639-482a-a754-2459d896f426",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üóùÔ∏è Solution code</summary>\n",
    "<br>\n",
    "    \n",
    "```python\n",
    "\n",
    "def compact_course_text(course: Course) -> str:\n",
    "    \"\"\"\n",
    "    Create an ultra-compact course description.\n",
    "\n",
    "    Reduces token count while preserving essential information.\n",
    "\n",
    "    Use this when you need maximum token efficiency (e.g., many courses).\n",
    "    Use transform_course_to_text() when you need full details.\n",
    "\n",
    "    Args:\n",
    "        course: Course object to optimize\n",
    "\n",
    "    Returns:\n",
    "        Compact text representation\n",
    "    \"\"\"\n",
    "    prereqs = (\n",
    "        f\" (Prereq: {', '.join([p.course_code for p in course.prerequisites])})\"\n",
    "        if course.prerequisites\n",
    "        else \"\"\n",
    "    )\n",
    "    return (\n",
    "        f\"{course.course_code}: {course.title} - {course.description[:100]}...{prereqs}\"\n",
    "    )\n",
    "\n",
    "print(\"‚úÖ Compact summary function defined!\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed52d3c9-ee77-45c6-95b6-38e677777b0d",
   "metadata": {},
   "source": [
    "As before, we'll need to attach the function to our agent for later. Run the code block below to accomplish this goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365d6ed2-5281-44d0-a77e-036f9f9179a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import agent.data_engineering\n",
    "\n",
    "# Inject our function into the agent's module\n",
    "agent.data_engineering.compact_course_text = compact_course_text\n",
    "\n",
    "print(\"Successfully injected the custom function into the agent!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b377df22",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Let's now compare the results. In Stage 1, this query cost us ~10,000 tokens. We'll run the exact same query as in Stage 1 to make a direct comparison.\n",
    "\n",
    "Run the code block below to initiate the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd35a055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the user's query\n",
    "query = \"What computer science courses are available?\"\n",
    "\n",
    "print(f\"User asks: '{query}'\")\n",
    "print(\"Running workflow...\")\n",
    "\n",
    "# Run the graph\n",
    "result = await workflow.ainvoke({\"query\": query})\n",
    "\n",
    "# Display the Answer\n",
    "print(\"=\"*60)\n",
    "print(f\"Agent Answer:\\n\\n{result['final_answer']}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Display the Metrics\n",
    "courses_found = result.get('courses_found', 0)\n",
    "total_tokens = result.get('total_tokens', 0)\n",
    "\n",
    "print(f\"\\nStatistics:\")\n",
    "print(f\"   Courses Retrieved: {courses_found}\")\n",
    "print(f\"   Total Tokens Used: {total_tokens:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc773e5",
   "metadata": {},
   "source": [
    "### The Comparison\n",
    "\n",
    "| Metric | Stage 1 (Baseline) | Stage 2 (Engineered) | Improvement |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **Total Tokens** | 6000+ | **~576** | **~91% Reduction** |\n",
    "| **Format** | Raw JSON | Clean Text | Better Readability |\n",
    "| **Noise** | High (Syllabi, IDs) | Low (Relevant info only) | Focused Context |\n",
    "\n",
    "We achieved a ~91% reduction in token usage by simply cleaning and formatting our data.\n",
    "\n",
    "### Inspecting the Engineered Context\n",
    "Let's see what the LLM actually saw this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d3c704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the engineered context\n",
    "engineered_context = result.get('engineered_context', '')\n",
    "\n",
    "print(f\"Total Context Size: {len(engineered_context):,} characters\")\n",
    "print(\"-\" * 40)\n",
    "print(\"PREVIEW OF ENGINEERED CONTEXT\")\n",
    "print(\"-\" * 40)\n",
    "print(engineered_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db7feaf",
   "metadata": {},
   "source": [
    "## Wrap Up üèÅ\n",
    "\n",
    "You've completed Stage 2 and transformed your RAG agent from a token-wasting baseline into an efficient, data-engineered system.\n",
    "\n",
    "In this stage, you:\n",
    "\n",
    "- Cleaned course data by removing database artifacts, noise fields, and unnecessary details\n",
    "- Transformed structured data from JSON into LLM-friendly natural text format\n",
    "- Optimized context with ultra-compact summaries for maximum token efficiency\n",
    "- Compared different representation strategies (raw JSON vs. clean text vs. compact summaries)\n",
    "\n",
    "The key transformation is understanding that context is just data, and data can be engineered. By applying lightweight data engineering techniques‚Äîcleaning, transforming, and optimizing‚Äîyou achieved a 91% reduction in token usage while maintaining answer quality. This demonstrates that more context isn't always better; curated, well-formatted context is.\n",
    "\n",
    "In Stage 3, you'll take the next leap: hierarchical retrieval with progressive disclosure. Instead of deciding upfront whether to send summaries or full details, you'll build an intelligent agent that retrieves summaries first, evaluates relevance, and fetches full syllabi only for the most relevant courses. This adaptive approach gives you both low token usage and high detail exactly when needed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
