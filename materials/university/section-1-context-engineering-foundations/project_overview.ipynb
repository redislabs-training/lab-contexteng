{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00d31327",
   "metadata": {},
   "source": [
    "# Project Overview\n",
    "\n",
    "Now that you've gotten a introduction to the basics of what context engineering is and the basics of how it works, we'll dive into the project you'll be building in the course.\n",
    "\n",
    "Throughout this course, you'll progressively build a course advisor agent - an AI assistant that helps students discover and explore courses from a catalog. Starting with a simple retrieval system, you'll incrementally build up to a full agent while exploring how to construct context and apply common context engineering techniques.\n",
    "\n",
    "Each implementation in this course tackles a different challenge: making your agent token-efficient so it doesn't waste context, handling multi-turn conversations where users ask follow-up questions, combining semantic search with exact matching for precision, remembering user preferences across sessions, and improving the agent's reasoning process transparent for debugging.\n",
    "\n",
    "By the end, you'll have built 7 progressively advanced implementations, each solving specific context engineering challenges you'll encounter in real-world AI systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916a7027",
   "metadata": {},
   "source": [
    "## Course Structure\n",
    "\n",
    "There are a total of 7 stages in this course to reach the final agent implementation: \n",
    "\n",
    "### Section 1: Context Engineering Foundations\n",
    "\n",
    "---\n",
    "\n",
    "#### Stage 0: Crafting Effective System Prompts\n",
    "\n",
    "Before we build onto the agent's capabilities, we'll work with system context. It's the easiest context to manage because if you've written prompts before, it will be the most familiar! In this preliminary stage, you'll learn how to craft effective system instructions that define your agent's role, capabilities, and behavioral constraints. You'll see how a well-crafted system prompt acts as the foundation for all other context.\n",
    "\n",
    "#### Stage 1: Baseline RAG\n",
    "\n",
    "Whether you're building a chatbot, documentation assistant, or complex agentic system, you'll likely need to retrieve relevant information from a knowledge base, assemble context for the language model, and generate responses grounded in that context. Most applications implement this in a form of a retrieval-augmented generation (RAG) pipeline. \n",
    "\n",
    "We will start with observing a basic RAG application because context engineering fundamentals apply to *all* AI systems - from simple one-shot applications to complex multi-agent workflows. You'll learn to engineer context effectively in basic systems before tackling the additional complexity of agents, memory, and reasoning loops.\n",
    "\n",
    "The agent presented in stage 1 will show off how basic retrieval works but is inefficient. You'll observe what happens when you DON'T engineer context.\n",
    "\n",
    "#### Stage 2: Data Engineered RAG\n",
    "\n",
    "Once you observe the limits of a basic non-context-engineered RAG system, we'll apply context engineering techniques to dramatically improve efficiency. You'll see why context engineering isn't about retrieving more - it's about assembling LESS context more intelligently.\n",
    "\n",
    "You'll implement context cleaning, transformation, and optimization to reduce token usage by over ~80% while maintaining quality. This stage demonstrates the power of proper data engineering for context. \n",
    "\n",
    "\n",
    "### Section 2: From Pipeline to Agent\n",
    "\n",
    "---\n",
    "\n",
    "#### Stage 3: Hierarchical Retrieval & Intent Classification (Full Agent Architecture)\n",
    "\n",
    "This stage is when we really kick it into gear. In stages 1 and 2, what we called an \"agent\" was essentially just a RAG pipeline. This stage transforms the system into a true LangGraph-based agent with structured workflows, defined tools, and intelligent routing.\n",
    "\n",
    "You'll implement:\n",
    "- Intent classification to route different query types\n",
    "- Quality evaluation with iterative improvement loops\n",
    "- Hierarchical retrieval using progressive disclosure\n",
    "\n",
    "This is where RAG becomes an agent with observable, stateful workflows.\n",
    "\n",
    "#### Stage 4: Hybrid Search with ReAct\n",
    "\n",
    "This stage builds on the agent created in stage 3 and tackles two major improvements:\n",
    "\n",
    "- Hybrid Search with NER: You'll add Named Entity Recognition (NER) to extract course codes and combine exact matching with semantic search for better retrieval accuracy.\n",
    "\n",
    "- The ReAct Architecture: We'll upgrade from a RAG pipeline to a ReAct (Reasoning + Acting) agent architecture where the agent's reasoning becomes visible. Instead of opaque tool-calling, you'll see explicit Thought → Action → Observation traces, making the agent's decision-making transparent and debuggable.\n",
    "\n",
    "\n",
    "### Section 3: Memory Context\n",
    "\n",
    "---\n",
    "\n",
    "#### Stage 5: Working Memory\n",
    "\n",
    "In stage's 5 and 6 we add the dimension of time and explore managing conversational context. For stage 5 , we'll integrate Redis [Agent Memory Server](https://github.com/redis/agent-memory-server) to implement working memory for session-based conversation history.\n",
    "\n",
    "The agent will be able to:\n",
    "- Store and retrieve conversation history within a session\n",
    "- Resolve pronouns like \"Tell me more about *it*\"\n",
    "- Maintain context across multiple turns in a conversation\n",
    "\n",
    "#### Stage 6: Full Memory (Working + Long-term)\n",
    "\n",
    "In our final stage, we complete the memory architecture by introducing how to manage long-term memory via tools that allow the agent to explicitly store and recall user preferences across different sessions.\n",
    "\n",
    "This stage combines everything:\n",
    "- Working Memory: Session-based conversation history (from Stage 5)\n",
    "- Long-term Memory Tools: Application-based cross-session persistence\n",
    "- ReAct: Transparent reasoning traces (from Stage 4)\n",
    "- Hierarchical Retrieval: Progressive disclosure (from Stage 3)\n",
    "- Hybrid Search: Exact + semantic matching (from Stage 4)\n",
    "\n",
    "By the end, you'll have a fully functional production-ready ReAct agent with properly managed context across tools, memory types, and retrieved knowledge.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
