{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e39fd892",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Stage 4: Hybrid Search & The ReAct Loop\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In Stage 3, we made significant progress in context management around retrieved context. We built an intent-driven architecture that dynamically selected between hierarchical data views (summaries vs. full details), assembled context using progressive disclosure, and implemented a quality validation loop that automatically retried with different strategies when context was insufficient. We even introduced tool calling where the LLM could decide *when* to search for courses.\n",
    "\n",
    "This was effective for managing context when queries fit our predefined categories. But we were still pre-programming every path through the system. We decided which intents existed, which search strategies to use for each intent, and what fallback rules to follow when context was insufficient.\n",
    "\n",
    "Real production agents work differently. Think about how ChatGPT or Claude handle queries. They reason about what context they need and how to retrieve it. They don't necessarily follow pre-programmed paths; they make dynamic decisions based on the specific query in front of them. In these types of systems the job shifts from programming all the paths to providing the tools and guidance agents need to make smart context decisions themselves.\n",
    "\n",
    "This shift becomes critical when we add conversation memory in the next stage (Stage 5). Memory introduces fundamental ambiguity our stage 3 agent simply cannot handle. Consider the following query: \n",
    "\n",
    "*\"What are the prerequisites for that course?\"* \n",
    "\n",
    "There are core challenges with a query like this for our current system. Which course? The one from three messages ago? The last course code mentioned? A course implied by context? \n",
    "\n",
    "Pre-programmed logic would need to account for every possible reference pattern. A reasoning agent can analyze the conversation history and determine what \"that course\" means in context.\n",
    "\n",
    "To build agents that reason about their context needs, we need a new cognitive architecture: the ReAct pattern (Reasoning + Acting). This allows the agent to:\n",
    "1. Analyze the user's request\n",
    "2. Decide what context is missing\n",
    "3. Retrieve that specific context using tools\n",
    "4. Evaluate if the context is sufficient, and if not, loop back to get more\n",
    "\n",
    "To implement this, we need two components working together:\n",
    "\n",
    "**1. The ReAct agent architecture**\n",
    "\n",
    "The reasoning engine that replaces our Stage 3 pipeline. The agent will think through what context it needs, retrieve it, evaluate if it's sufficient, and loop until it has everything required to answer confidently. Its structure will look like this:\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    Q[Query] --> RA[ReAct Agent]\n",
    "\n",
    "    subgraph ReAct Loop\n",
    "        RA --> T1[üí≠ Thought: What context do I need?]\n",
    "        T1 --> A1[üîß Action: Retrieve Context]\n",
    "        A1 --> O1[üëÅÔ∏è Observation: Review Data]\n",
    "        O1 --> T2[üí≠ Thought: Is this enough?]\n",
    "        T2 --> |No| A1\n",
    "        T2 --> |Yes| F[‚úÖ FINISH]\n",
    "    end\n",
    "\n",
    "    F --> R[Response]\n",
    "```\n",
    "\n",
    "**2. A hybrid search tool**\n",
    "\n",
    "In addition to the new architecture, we're also going to provide one more improvement to the way we search for the right context. \n",
    "\n",
    "In stage 3's hierarchical context assembly (summaries vs. full details, progressive disclosure), we solved the problem of *how much* information to return and *how to structure it*. That was context engineering for presentation.\n",
    "\n",
    "In this stage we're going to implement the ability to perform hybrid search.\n",
    "\n",
    "Hybrid search adds the ability to combine semantic search with exact filtering:\n",
    "- Semantic search alone: \"Find courses similar to 'CS101'\" (might return CS101, but also other intro courses)\n",
    "- Exact filtering: \"Find the course with course_code='CS101'\" (guaranteed to return only CS101)\n",
    "- Hybrid: \"Find advanced courses about machine learning\" (semantic search for 'machine learning' + filter for difficulty_level='advanced')\n",
    "\n",
    "The key difference between these approaches is intentional precision vs. semantic luck. Our hybrid search tool exposes both capabilities, allowing a reasoning agent to choose the right retrieval strategy based on the query's needs.\n",
    "\n",
    "This will become critical when:\n",
    "- The user asks for something specific (\"Tell me about CS101\" - why search 5 similar courses when you can filter for exactly CS101?)\n",
    "- The user needs combined criteria (\"Most advanced CS course\" - semantic search + exact difficulty filter)\n",
    "- Multi-step reasoning requires exact references (\"What are the prerequisites for that course?\" - need to filter for the exact course code from context)\n",
    "\n",
    "Together, these components create an agent that can reason about both *what* context it needs and *how* to retrieve it.\n",
    "\n",
    "Let's start building.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c31cf4",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, like before, let's set up our environment and import the stage 3 agent. Run the code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c24f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code sets up the notebook to be able to access the provided OpenAI API Key and access to the agent code\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "project_root = Path(\"..\").resolve()\n",
    "\n",
    "stage4_path = project_root / \"progressive_agents\" / \"stage4_hybrid_search_react\"\n",
    "src_path = project_root / \"src\"\n",
    "\n",
    "load_dotenv(project_root / \".env\")\n",
    "\n",
    "sys.path.insert(0, str(src_path))\n",
    "sys.path.insert(0, str(stage4_path))\n",
    "\n",
    "from agent import setup_agent, create_workflow\n",
    "\n",
    "print(\"Initializing Stage 4 Agent...\")\n",
    "course_manager, _ = await setup_agent(auto_load_courses=True)\n",
    "workflow = create_workflow(course_manager)\n",
    "\n",
    "print(\"‚úÖ Agent is ready!\")\n",
    "print(\"‚úÖ Course manager initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef1a1d0",
   "metadata": {},
   "source": [
    "## Part 1: Building the Hybrid Search Tool\n",
    "\n",
    "In this part, we're going to build out the hybrid search capability.\n",
    "\n",
    "In Stage 3, you built a `search_courses_tool` that used a pre-built helper function (`search_courses_sync`) to handle retrieval. Under the hood, that helper used RedisVL's [`VectorQuery`](https://docs.redisvl.com/en/latest/api/query.html#vectorquery) class to perform semantic/vector search.\n",
    "\n",
    "Now we're upgrading to hybrid search by working directly with a underlying `course_manager.search_courses()` method and leveraging more of RedisVL. In addition to `VectorQuery` for KNN search, RedisVL also provides the [`FilterQuery`](https://docs.redisvl.com/en/latest/api/query.html#filterquery) class for field-level filters. \n",
    "\n",
    "Our hybrid implementation combines both: we use vector search to retrieve semantically similar candidates, then apply filtering to guarantee exact matches when needed. This gives us the speed of vector search with the precision of exact matching. (Note: RedisVL also offers a [`HybridQuery`](https://docs.redisvl.com/en/latest/api/query.html#hybridquery) class for combining vector + full-text search, but our use case is simpler since we only need \"vector search OR exact field matching\" rather than \"vector + text ranking\".)\n",
    "\n",
    "We'll create a `search_courses_hybrid` function with an optional `course_code` parameter. When provided, the function switches to exact mode‚Äîsearching a larger set and filtering for matches. When `None`, it uses semantic search (the Stage 3 behavior). In Part 2, the ReAct agent will reason about which mode to use based on the query.\n",
    "\n",
    "Let's implement it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cefeee6",
   "metadata": {},
   "source": [
    "### üìå Task 1: Implement Hybrid Search\n",
    "\n",
    "Your task is to complete the `search_courses_hybrid` function below to support both semantic and exact search modes.\n",
    "\n",
    "The function should check whether a `course_code` parameter is provided. If it is, perform exact matching by searching a larger set of courses and filtering to only those matching the code. If not, perform a semantic search and return the top results directly.\n",
    "\n",
    "Both modes should return results as JSON strings, and any errors should be caught and returned as error messages.\n",
    "\n",
    "<details>\n",
    "<summary>üõ†Ô∏è Show Implementation Details</summary>\n",
    "<br>\n",
    "\n",
    "Step 1: **Search with higher limit (exact match mode)**\n",
    "\n",
    "Use the async method `.search_courses(query, limit=10)` on `course_manager` to fetch more results. This increases the chance of finding the target course code among the semantic results.\n",
    "\n",
    "Step 2: **Convert Pydantic models to dicts (exact match mode)**\n",
    "\n",
    "Use a list comprehension: `[r.model_dump(mode='json') for r in results]`. This converts the Pydantic Course objects into JSON-serializable dictionaries.\n",
    "\n",
    "Step 3: **Filter for course_code match**\n",
    "\n",
    "Filter the results to find courses where the `course_code` field matches your target. Use case-insensitive comparison: `[r for r in results_data if course_code.lower() in r['course_code'].lower()]`\n",
    "\n",
    "Step 4: **Search with smaller limit (semantic mode)**\n",
    "\n",
    "Use the async method `.search_courses(query, limit=3)`. For semantic search, you only need the top few matches.\n",
    "\n",
    "Step 5: **Convert and return as JSON (semantic mode)**\n",
    "\n",
    "Same conversion pattern: `[r.model_dump(mode='json') for r in results]`. The `json.dumps()` return statement is already provided.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f371b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "async def search_courses_hybrid(query: str, course_code: str = None) -> str:\n",
    "    \"\"\"\n",
    "    Search for courses using hybrid search (semantic + exact filter).\n",
    "    \n",
    "    Args:\n",
    "        query: The search text (e.g., \"machine learning\")\n",
    "        course_code: Optional exact course code to filter by (e.g., \"CS002\")\n",
    "    \n",
    "    Returns:\n",
    "        JSON string of matching courses\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if course_code:\n",
    "            # EXACT MATCH MODE\n",
    "            print(f\"üîç Tool: Executing EXACT match for code='{course_code}'\")\n",
    "            \n",
    "            # TODO - Step 1: Search with higher limit to ensure we find the match\n",
    "            results = None\n",
    "            \n",
    "            # TODO - Step 2: Convert Pydantic models to dicts using .model_dump(mode='json')\n",
    "            results_data = None\n",
    "            \n",
    "            # TODO - Step 3: Filter results where course_code matches (case-insensitive)\n",
    "            filtered = None\n",
    "            \n",
    "            if filtered:\n",
    "                return json.dumps(filtered, indent=2)\n",
    "            else:\n",
    "                return f\"No courses found with code {course_code}\"\n",
    "        \n",
    "        else:\n",
    "            # SEMANTIC SEARCH MODE\n",
    "            print(f\"üîç Tool: Executing SEMANTIC search for query='{query}'\")\n",
    "            \n",
    "            # TODO - Step 4: Search with smaller limit for top semantic matches\n",
    "            results = None\n",
    "            \n",
    "            # TODO - Step 5: Convert Pydantic models to dicts and return as JSON\n",
    "            results_data = None\n",
    "            return json.dumps(results_data, indent=2)\n",
    "            \n",
    "    except Exception as e:\n",
    "        return f\"Error searching courses: {str(e)}\"\n",
    "\n",
    "print(\"‚úÖ Hybrid search tool defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b78c945",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üóùÔ∏è Solution code</summary>\n",
    "<br>\n",
    "    \n",
    "```python\n",
    "\n",
    "import json\n",
    "\n",
    "async def search_courses_hybrid(query: str, course_code: str = None) -> str:\n",
    "    \"\"\"\n",
    "    Search for courses using hybrid search (semantic + exact filter).\n",
    "    \n",
    "    Args:\n",
    "        query: The search text (e.g., \"machine learning\")\n",
    "        course_code: Optional exact course code to filter by (e.g., \"CS002\")\n",
    "    \n",
    "    Returns:\n",
    "        JSON string of matching courses\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # If we have a specific course code, use exact matching mode\n",
    "        if course_code:\n",
    "            print(f\"üîç Tool: Executing EXACT match for code='{course_code}'\")\n",
    "            \n",
    "            # Fetch more results to ensure we find the match\n",
    "            results = await course_manager.search_courses(query, limit=10)\n",
    "            \n",
    "            # Convert Pydantic models to dicts\n",
    "            results_data = [r.model_dump(mode='json') for r in results]\n",
    "            \n",
    "            # Filter for the specific course code\n",
    "            filtered = [r for r in results_data if course_code.lower() in r['course_code'].lower()]\n",
    "            \n",
    "            if filtered:\n",
    "                return json.dumps(filtered, indent=2)\n",
    "            else:\n",
    "                return f\"No courses found with code {course_code}\"\n",
    "        \n",
    "        # Otherwise, use semantic search mode\n",
    "        else:\n",
    "            print(f\"üîç Tool: Executing SEMANTIC search for query='{query}'\")\n",
    "            results = await course_manager.search_courses(query, limit=3)\n",
    "            \n",
    "            # Convert Pydantic models to dicts\n",
    "            results_data = [r.model_dump(mode='json') for r in results]\n",
    "            return json.dumps(results_data, indent=2)\n",
    "            \n",
    "    except Exception as e:\n",
    "        return f\"Error searching courses: {str(e)}\"\n",
    "\n",
    "print(\"‚úÖ Hybrid search tool defined\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46620cf",
   "metadata": {},
   "source": [
    "### Test the implementation\n",
    "\n",
    "Run the test utility below to verify your hybrid search tool works correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb689afa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import the test utility\n",
    "from test_hybrid_search import test_hybrid_search_tool\n",
    "\n",
    "# Test your implementation\n",
    "await test_hybrid_search_tool(search_courses_hybrid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56cb1b7",
   "metadata": {},
   "source": [
    "### Connect the tool to the agent\n",
    "\n",
    "Before we build the ReAct loop, let's register our hybrid search function in a `tools_map` dictionary. The ReAct agent will use this mapping to look up and execute tools by name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cedb056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping of tool names to functions\n",
    "tools_map = {\n",
    "    \"search_courses_hybrid\": search_courses_hybrid\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Tool registered! The ReAct agent can now access search_courses_hybrid.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b543da6d",
   "metadata": {},
   "source": [
    "## Part 2: The ReAct Agent Architecture\n",
    "\n",
    "Now that we have a hybrid search tool that can retrieve context with precision, we can build an agent that reasons about how to use it.\n",
    "\n",
    "This reasoning happens in a loop structure. The agent alternates between three phases:\n",
    "\n",
    "1. **Thought**: The agent reasons about what it needs to do next. \"I don't have enough information yet. I should search for courses about machine learning.\"\n",
    "\n",
    "2. **Action**: The agent decides to either call a tool or provide a final answer. \"I'll use search_courses with query='machine learning' and no course_code (semantic search).\"\n",
    "\n",
    "3. **Observation**: The agent sees the result of its action. \"I received 3 courses about machine learning. Now I have enough context to answer the user's question.\"\n",
    "\n",
    "The loop continues until the agent decides it has sufficient information to answer. Within a single query, each iteration builds on the previous and the agent sees its own thoughts and observations in the message history, allowing it to build up context progressively.\n",
    "\n",
    "In order to implement the architecture, we'll need the following components:\n",
    "\n",
    "1. **A System Prompt**: Similar to how we designed a system prompt before, we'll need instructions that tell the LLM how to format its thoughts and actions. This defines the ReAct protocol the agent will follow.\n",
    "\n",
    "2. **The Parser**: A function that extracts structured decisions from the LLM's free-text output. It identifies what action the agent wants to take and what inputs to provide.\n",
    "\n",
    "3. **The Loop**: A `react_agent_node` function that orchestrates the cycle. It calls the LLM, parses the response, executes tools, and feeds observations back into the conversation.\n",
    "\n",
    "We'll provide the prompt and parser for you. Your job is to implement the loop logic that brings them together.\n",
    "\n",
    "Let's start by examining the system prompt and parser, then you'll build the loop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316fe306",
   "metadata": {},
   "source": [
    "### The ReAct System Prompt and Parser\n",
    "\n",
    "Before implementing the ReAct loop, you need to understand the two components that make it work:\n",
    "\n",
    "1. **REACT_SYSTEM_PROMPT**: Tells the LLM how to think and format its output\n",
    "2. **parse_react_output()**: Extracts the Action and Action Input from LLM responses\n",
    "\n",
    "We've provided these implementations for you in the dropdown sections below. Review them carefully\n",
    "\n",
    "<details>\n",
    "<summary>üîç Open to explore the ReAct System Prompt</summary>\n",
    "<br>\n",
    "    \n",
    "The abreviated prompt below defines the ReAct protocol and includes:\n",
    "- Multiple search strategies (exact_match, hybrid, semantic_only)\n",
    "- Intent classification (GENERAL, PREREQUISITES, SYLLABUS_OBJECTIVES, ASSIGNMENTS)\n",
    "- Detailed examples for different query types\n",
    "- Guidance on handling empty results vs. errors\n",
    "- Instructions to avoid unnecessary re-searching\n",
    "\n",
    "You can also view the complete implementation in the agent directory for [react_prompts.py](../progressive_agents/stage4_hybrid_search_react/agent/react_prompts.py)\n",
    "\n",
    "```python\n",
    "\n",
    "REACT_SYSTEM_PROMPT = \"\"\"You are a helpful Redis University course advisor assistant.\n",
    "\n",
    "You have access to ONE tool:\n",
    "\n",
    "**search_courses_hybrid** - Search the Redis University course catalog with hybrid search\n",
    "   Parameters:\n",
    "   - query (str): Search query\n",
    "   - intent (str): GENERAL, PREREQUISITES, SYLLABUS_OBJECTIVES, or ASSIGNMENTS\n",
    "   - search_strategy (str): \"exact_match\", \"hybrid\", or \"semantic_only\"\n",
    "   - course_codes (list): Specific course codes to search for (use for exact matches)\n",
    "   - information_type (list): What info to retrieve (e.g., [\"prerequisites\", \"syllabus\"])\n",
    "   - departments (list): Filter by department\n",
    "\n",
    "You must use the following format:\n",
    "\n",
    "Thought: [Your reasoning about what to do next]\n",
    "Action: [One of: search_courses or FINISH]\n",
    "Action Input: [Valid JSON with the required parameters]\n",
    "\n",
    "You will receive:\n",
    "Observation: [Result of the action]\n",
    "\n",
    "Then you continue with another Thought/Action/Observation cycle.\n",
    "\n",
    "When you have enough information to answer the user's question, use:\n",
    "Thought: I have enough information to provide a complete answer\n",
    "Action: FINISH\n",
    "Action Input: [Your final answer to the user]\n",
    "\n",
    "IMPORTANT GUIDELINES:\n",
    "- Always start with a Thought explaining your reasoning\n",
    "- Only use ONE Action per turn\n",
    "- Action Input must be valid JSON matching the tool's parameters\n",
    "- Use \"exact_match\" strategy when the user mentions specific course codes\n",
    "- Use \"hybrid\" strategy for topic-based searches\n",
    "- Use FINISH when you're ready to provide the final answer\n",
    "\n",
    "INTERPRETING SEARCH RESULTS:\n",
    "- If a search returns course data with an empty field (e.g., \"prerequisites\": []), \n",
    "  that means the field has NO VALUE - not that the search failed\n",
    "- Empty prerequisites [] means \"no prerequisites required\" - this IS a valid answer\n",
    "- Only retry a search if you get an actual error or no courses are found\n",
    "- Do NOT keep searching with different strategies when you already have the course data\n",
    "\n",
    "[... additional examples and guidance ...]\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>üîç Open to explore the ReAct Parser</summary>\n",
    "<br>\n",
    "    \n",
    "The core parser function extracts structured data from the LLM's free-text ReAct output. It returns a dictionary with three keys:\n",
    "- `thought`: The agent's reasoning\n",
    "- `action`: The action to take (e.g., \"search_courses\" or \"FINISH\")\n",
    "- `action_input`: The JSON parameters for the action\n",
    "\n",
    "The full implementation also includes three helper methods to be aware of:\n",
    "- `validate_action_input()`: Parses and validates JSON with fallback logic for malformed input\n",
    "- `format_observation()`: Formats tool results with configurable truncation to prevent context overflow\n",
    "- `extract_final_answer()`: Extracts the final answer text from FINISH actions\n",
    "\n",
    "You can view the complete implementation with all helper methods in [react_parser.py](../progressive_agents/stage4_hybrid_search_react/agent/react_parser.py). Below, you will find the core parser function.\n",
    "\n",
    "```python\n",
    "\n",
    "def parse_react_output(text: str) -> Dict[str, Optional[str]]:\n",
    "    \"\"\"\n",
    "    Parse ReAct format output from LLM.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with 'thought', 'action', and 'action_input' keys\n",
    "    \"\"\"\n",
    "    # Extract Thought (everything between \"Thought:\" and \"Action:\")\n",
    "    thought_match = re.search(\n",
    "        r\"Thought:\\s*(.+?)(?=\\nAction:|\\Z)\", text, re.DOTALL | re.IGNORECASE\n",
    "    )\n",
    "    \n",
    "    # Extract Action (word after \"Action:\")\n",
    "    action_match = re.search(r\"Action:\\s*(\\w+)\", text, re.IGNORECASE)\n",
    "    \n",
    "    # Extract Action Input\n",
    "    action_input_match = re.search(\n",
    "        r\"Action Input:\\s*(.+?)(?=\\nThought:|\\nObservation:|\\nAction:|\\Z)\",\n",
    "        text,\n",
    "        re.DOTALL | re.IGNORECASE,\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"thought\": thought_match.group(1).strip() if thought_match else None,\n",
    "        \"action\": action_match.group(1).strip() if action_match else None,\n",
    "        \"action_input\": (\n",
    "            action_input_match.group(1).strip() if action_input_match else None\n",
    "        ),\n",
    "    }\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf9fc64",
   "metadata": {},
   "source": [
    "### üìå Task: Implement the ReAct Loop\n",
    "\n",
    "In this task, you will implement the core ReAct loop logic. Your implementation will match the production version used in [react_agent.py](../progressive_agents/stage4_hybrid_search_react/agent/react_agent.py), except we'll skip the logging code to focus on the essential logic.\n",
    "\n",
    "Before you start coding, here's what's already provided for you:\n",
    "\n",
    "1. `AgentState` - A TypedDict that defines the structure of our state:\n",
    "   - `input`: The user's query string\n",
    "   - `history`: List of previous conversation turns\n",
    "   - `final_response`: The final answer to return\n",
    "     \n",
    "2. `messages` - A list of `AIMessage` and `HumanMessage` objects that stores the conversation history. Each iteration appends new messages so the LLM can see what happened previously.\n",
    "\n",
    "3. `get_react_llm()` - A helper function imported from the production code that returns a configured LLM instance with the right parameters (model, temperature, max_tokens, etc.).\n",
    "\n",
    "4. `execute_react_tool()` - A helper function imported from the production code that handles tool lookup and execution. You just call it with the tool name and arguments.\n",
    "\n",
    "5. `tools_map` - A dictionary mapping tool names (like \"search_courses\") to their actual function implementations.\n",
    "\n",
    "6. `REACT_SYSTEM_PROMPT` - The system prompt that instructs the LLM to use ReAct format (Thought/Action/Action Input).\n",
    "\n",
    "7. `parse_react_output()` - A function that parses the LLM's text response and extracts the thought, action, and action_input fields.\n",
    "\n",
    "Now, implement the ReAct loop logic. At a high level the  loop needs to:\n",
    "1. Parse the LLM response to extract the action\n",
    "2. Check if it's a FINISH action (completion)\n",
    "3. Execute tool actions with proper error handling\n",
    "4. Append observations to message history for the next iteration\n",
    "\n",
    "> **Note**: By appending observations to the message list, the LLM sees the full conversation history on the next iteration. It can reason about what it learned and decide what to do next.\n",
    "\n",
    "<details>\n",
    "<summary>üõ†Ô∏è Show Implementation Details</summary>\n",
    "<br> \n",
    "    \n",
    "Step 1: **Parse the LLM output**\n",
    "\n",
    "The `parse_react_output()` function returns a dictionary. You need to:\n",
    "- Call `parse_react_output(response_text)` and store the result in a variable called `parsed`\n",
    "- Extract the `\"action\"` key from the dictionary stored in `parsed` and store it in a variable called `action`\n",
    "\n",
    "This gives you access to what action the LLM wants to take.\n",
    "\n",
    "Step 2: **Check for FINISH action**\n",
    "\n",
    "The production implementation uses \"FINISH\" to signal completion. You need to:\n",
    "- Check if `action` exists and if it equals \"FINISH\" (case-insensitive using `.upper()`)\n",
    "- If it is finished, get the final answer from `parsed[\"action_input\"]`\n",
    "- Return a dictionary with key `\"final_response\"` containing that answer\n",
    "- Use `or \"\"` to handle None values\n",
    "\n",
    "Step 3: **Execute tool actions**\n",
    "\n",
    "For tool actions like \"search_courses\", you need to:\n",
    "- Check if the `action` is a key in the `tools_map` dictionary\n",
    "- Get the action input string from `parsed[\"action_input\"]`\n",
    "- Parse that string as JSON using `json.loads()` to get a dictionary of arguments\n",
    "- Call the helper function `execute_react_tool(action, tool_args)` with await\n",
    "- Wrap the tool execution in a try/except block to catch any errors (JSON parsing or tool execution)\n",
    "- If there's an error, set the observation to an error message string\n",
    "- Print the observation (truncate to 200 characters for readability)\n",
    "\n",
    "The `execute_react_tool()` helper function handles looking up the tool in the map and calling it for you.\n",
    "\n",
    "Step 4: **Append observation to messages**\n",
    "\n",
    "After executing a tool successfully, you need to update the message history so the LLM sees what happened:\n",
    "\n",
    "- Append the LLM's response as an `AIMessage` with content=response_textThis helps the LLM self-correct on the next iteration.\n",
    "\n",
    "- Append the observation as a `HumanMessage` with content=f\"Observation: {observation}\"\n",
    "\n",
    "This uses LangChain's message types (AIMessage/HumanMessage) instead of tuples, matching the production code.\n",
    "\n",
    "Step 5: **Handle invalid actions**\n",
    "\n",
    "If the action isn't recognized (not in tools_map and not FINISH), you need to give the LLM feedback:\n",
    "- Append the LLM's response as an `AIMessage`\n",
    "- Append an error message as a `HumanMessage`: \"Error: Unknown action...\"\n",
    "- Include the action name and list valid options\n",
    "\n",
    "This helps the LLM self-correct on the next iteration.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5523459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import TypedDict, List, Optional\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from agent.react_agent import get_react_llm, execute_react_tool\n",
    "from agent.react_prompts import REACT_SYSTEM_PROMPT\n",
    "from agent.react_parser import parse_react_output\n",
    "\n",
    "# Define the State\n",
    "class AgentState(TypedDict):\n",
    "    input: str\n",
    "    history: List[str]\n",
    "    final_response: str\n",
    "\n",
    "async def react_agent_node(state: AgentState, llm: Optional[ChatOpenAI] = None):\n",
    "    \"\"\"\n",
    "    The ReAct agent that implements Thought ‚Üí Action ‚Üí Observation loop.\n",
    "    \n",
    "    This function maintains a conversation with the LLM where:\n",
    "    - The LLM sees the system prompt, user query, and all previous observations\n",
    "    - Each iteration adds new observations to the message history\n",
    "    - The loop continues until the LLM returns \"FINISH\" or max iterations reached\n",
    "    \n",
    "    Args:\n",
    "        state: AgentState with input, history, and final_response\n",
    "        llm: Optional LLM instance (uses get_react_llm() if not provided)\n",
    "    \"\"\"\n",
    "    query = state['input']\n",
    "    history = state.get('history', [])\n",
    "    \n",
    "    # Get LLM instance (use provided or default)\n",
    "    if llm is None:\n",
    "        llm = get_react_llm()\n",
    "    \n",
    "    # Build initial messages (using LangChain message types)\n",
    "    messages = [\n",
    "        HumanMessage(content=REACT_SYSTEM_PROMPT),\n",
    "        HumanMessage(content=f\"\\nUser: {query}\\n\\nHistory: {history}\")\n",
    "    ]\n",
    "    \n",
    "    # Limit the loop to prevent infinite spins\n",
    "    max_iterations = 5\n",
    "    iteration = 0\n",
    "    \n",
    "    while iteration < max_iterations:\n",
    "        iteration += 1\n",
    "        \n",
    "        # Call the LLM\n",
    "        response = await llm.ainvoke(messages)\n",
    "        response_text = response.content\n",
    "        print(f\"\\nü§ñ Step {iteration} Response:\\n{response_text}\")\n",
    "        \n",
    "        # TODO Step 1: Parse the output to get action dictionary\n",
    "        # Use parse_react_output() and extract the 'action' field\n",
    "        parsed = None  # Replace with: parse_react_output(response_text)\n",
    "        action = None  # Replace with: parsed[\"action\"]\n",
    "        \n",
    "        # TODO Step 2: Check if action is \"FINISH\"\n",
    "        # If action is FINISH (case-insensitive), extract final answer and return\n",
    "        \n",
    "        \n",
    "        # TODO Step 3: Execute tool if action is in tools_map\n",
    "        # - Get action input from parsed[\"action_input\"]\n",
    "        # - Parse action input as JSON using json.loads()\n",
    "        # - Call execute_react_tool(action, tool_args) with try/except\n",
    "        # - Print observation (truncate to 200 chars)\n",
    "        \n",
    "        \n",
    "        # TODO Step 4: Append messages for next iteration\n",
    "        # After executing a tool, append both the LLM response and observation:\n",
    "        # - AIMessage with the response_text\n",
    "        # - HumanMessage with the observation\n",
    "        \n",
    "        \n",
    "        # TODO Step 5: Handle invalid actions\n",
    "        # If action not recognized, append error feedback\n",
    "        \n",
    "    \n",
    "    return {\"final_response\": \"I could not find the answer within the iteration limit.\"}\n",
    "\n",
    "print(\"‚úÖ ReAct agent node defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8013d8d",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üóùÔ∏è Solution code</summary>\n",
    "\n",
    "```python\n",
    "\n",
    "import json\n",
    "from typing import TypedDict, List\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "from agent.react_agent import get_react_llm, execute_react_tool\n",
    "from agent.react_prompts import REACT_SYSTEM_PROMPT\n",
    "from agent.react_parser import parse_react_output\n",
    "\n",
    "# Define the State\n",
    "class AgentState(TypedDict):\n",
    "    input: str\n",
    "    history: List[str]\n",
    "    final_response: str\n",
    "\n",
    "async def react_agent_node(state: AgentState):\n",
    "    \"\"\"\n",
    "    The ReAct agent that implements Thought ‚Üí Action ‚Üí Observation loop.\n",
    "    \n",
    "    This function maintains a conversation with the LLM where:\n",
    "    - The LLM sees the system prompt, user query, and all previous observations\n",
    "    - Each iteration adds new observations to the message history\n",
    "    - The loop continues until the LLM returns \"FINISH\" or max iterations reached\n",
    "    \"\"\"\n",
    "    query = state['input']\n",
    "    history = state.get('history', [])\n",
    "    \n",
    "    # Get LLM instance\n",
    "    llm = get_react_llm()\n",
    "    \n",
    "    # Build initial messages (using LangChain message types)\n",
    "    messages = [\n",
    "        HumanMessage(content=REACT_SYSTEM_PROMPT),\n",
    "        HumanMessage(content=f\"\\nUser: {query}\\n\\nHistory: {history}\")\n",
    "    ]\n",
    "    \n",
    "    # Limit the loop to prevent infinite spins\n",
    "    max_iterations = 5\n",
    "    iteration = 0\n",
    "    \n",
    "    while iteration < max_iterations:\n",
    "        iteration += 1\n",
    "        \n",
    "        # Call the LLM\n",
    "        response = await llm.ainvoke(messages)\n",
    "        response_text = response.content\n",
    "        print(f\"\\nü§ñ Step {iteration} Response:\\n{response_text}\")\n",
    "        \n",
    "        # Step 1: Parse the output\n",
    "        parsed = parse_react_output(response_text)\n",
    "        action = parsed[\"action\"]\n",
    "        \n",
    "        # Step 2: Check for FINISH action\n",
    "        if action and action.upper() == \"FINISH\":\n",
    "            final_answer = parsed[\"action_input\"] or \"\"\n",
    "            return {\"final_response\": final_answer}\n",
    "        \n",
    "        # Step 3: Execute tool actions\n",
    "        elif action in tools_map:\n",
    "            action_input_str = parsed[\"action_input\"]\n",
    "            \n",
    "            try:\n",
    "                tool_args = json.loads(action_input_str)\n",
    "                observation = await execute_react_tool(action, tool_args)\n",
    "            except Exception as e:\n",
    "                observation = f\"Error: {str(e)}\"\n",
    "            \n",
    "            print(f\"\\nüëÅÔ∏è Observation: {observation[:200]}...\")\n",
    "            \n",
    "            # Step 4: Append to message history\n",
    "            messages.append(AIMessage(content=response_text))\n",
    "            messages.append(HumanMessage(content=f\"Observation: {observation}\"))\n",
    "        \n",
    "        # Step 5: Handle invalid actions\n",
    "        else:\n",
    "            messages.append(AIMessage(content=response_text))\n",
    "            messages.append(HumanMessage(content=f\"Error: Unknown action '{action}'. Use 'search_courses_hybrid' or 'FINISH'.\"))\n",
    "    \n",
    "    return {\"final_response\": \"I could not find the answer within the iteration limit.\"}\n",
    "    \n",
    "print(\"‚úÖ ReAct agent node defined\")\n",
    "```\n",
    "\n",
    "This core implementation matches the logic in [react_agent.py](../progressive_agents/stage4_hybrid_search/agent/react_agent.py). The production version adds:\n",
    "- Detailed logging for debugging and monitoring\n",
    "- LLM call tracking and metrics\n",
    "- Reasoning trace for observability\n",
    "- More sophisticated error handling\n",
    "- State management for workflow integration\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d7426f",
   "metadata": {},
   "source": [
    "### Test Your Implementation\n",
    "\n",
    "Now let's test your ReAct loop! \n",
    "\n",
    "We'll use the production implementation from [react_agent.py](../progressive_agents/stage4_hybrid_search_react/agent/react_agent.py) which includes the same core logic you just built, plus additional features like detailed logging, metrics tracking, and error handling.\n",
    "\n",
    "The test utility below will verify that your understanding of the ReAct pattern is correct by comparing your implementation's behavior against expected outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a5698f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_react_agent import test_react_agent\n",
    "\n",
    "# Test your implementation\n",
    "await test_react_agent(react_agent_node, tools_map, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f208d0",
   "metadata": {},
   "source": [
    "## Part 3: Building the Graph Architecture\n",
    "\n",
    "Now that we have our ReAct agent node, we need to wrap it in a LangGraph StateGraph to create the execution flow.\n",
    "\n",
    "Since our `react_agent_node` handles the looping internally (the while loop), our graph structure is simple and linear: `Start ‚Üí Agent ‚Üí End`.\n",
    "\n",
    "This is different from Stage 3, which had multiple nodes (classify_intent_node, agent_node, etc.) with conditional edges. Here, the ReAct pattern consolidates all reasoning into a single node that loops internally.\n",
    "\n",
    "### üìå Task: Build and Compile the Graph\n",
    "\n",
    "Your task is to build a simple LangGraph workflow that wraps the ReAct agent node.\n",
    "\n",
    "The graph building process involves initializing a [`StateGraph`](https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.StateGraph) with your state schema, registering your agent function as a node, defining the execution flow with edges, and compiling everything into an executable application.\n",
    "\n",
    "This is a simplified mock implementation to help you understand the core concepts. The full production implementation with additional features can be found in [workflow.py](../progressive_agents/stage4_hybrid_search/agent/workflow.py).\n",
    "\n",
    "<details>\n",
    "<summary>üõ†Ô∏è Show Implementation Details</summary>\n",
    "<br> \n",
    "    \n",
    "Step 1: **Initialize the StateGraph**\n",
    "\n",
    "Create a [`StateGraph`](https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.StateGraph) instance by passing your `AgentState` TypedDict as the type parameter. This tells LangGraph what shape the state will have.\n",
    "\n",
    "Step 2: **Add the agent node**\n",
    "\n",
    "Create a StateGraph instance by passing your `AgentState` TypedDict as the type parameter. This tells LangGraph what shape the state will have.\n",
    "\n",
    "Use the [`.add_node()`](https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.StateGraph.add_node) method to add a node:\n",
    "- First parameter: node name as a string (use \"agent\")\n",
    "- Second parameter: the function to execute (your `react_agent_node`)\n",
    "\n",
    "Step 3: **Set the entry point**\n",
    "\n",
    "Use the [`.set_entry_point()`](https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.StateGraph.set_entry_point) method to specify which node executes first. Pass the node name as a string.\n",
    "\n",
    "Step 4: **Add edge to END**\n",
    "\n",
    "Use the [`.add_edge()`](https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.StateGraph.add_edge) method to connect the agent to termination:\n",
    "- First parameter: source node name (\"agent\")\n",
    "- Second parameter: destination (the `END` constant)\n",
    "\n",
    "Step 5: **Compile the graph**\n",
    "\n",
    "Call [`.compile()`](https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.StateGraph.compile) on the workflow to create the executable application. Store this in a variable called `app`.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbb624b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# TODO: Step 1 - Initialize the StateGraph with AgentState\n",
    "\n",
    "# TODO: Step 2 - Add the agent node\n",
    "\n",
    "# TODO: Step 3 - Set the entry point\n",
    "\n",
    "# TODO: Step 4 - Add edge to END\n",
    "\n",
    "# TODO: Step 5 - Compile\n",
    "\n",
    "print(\"‚úÖ Graph compiled!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8740bb2f",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üóùÔ∏è Solution code</summary>\n",
    "<br>\n",
    "    \n",
    "```python\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# Initialize the StateGraph with AgentState\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add the agent node\n",
    "workflow.add_node(\"agent\", react_agent_node)\n",
    "\n",
    "# Set the entry point\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "# Add edge to END\n",
    "workflow.add_edge(\"agent\", END)\n",
    "\n",
    "# Compile\n",
    "app = workflow.compile()\n",
    "\n",
    "print(\"‚úÖ Graph compiled!\")\n",
    "```\n",
    "\n",
    "This creates a simple linear graph:\n",
    "- `START` ‚Üí `agent` ‚Üí `END`\n",
    "- The agent node contains all the ReAct loop logic\n",
    "- No conditional edges needed since the loop handles decision-making internally\n",
    "- The graph terminates when `react_agent_node` returns the final response\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ab3505",
   "metadata": {},
   "source": [
    "## Part 4: Testing the ReAct Agent\n",
    "\n",
    "Now let's test our agent with different query types. Watch the output carefully to see the Thought ‚Üí Action ‚Üí Observation cycle in action.\n",
    "\n",
    "### Single-Turn Queries\n",
    "\n",
    "First, let's test individual queries to see how the agent reasons. The first query attempts to query for an exact match, while the second query is a topic-based search. Run both code blocks to see the agent's thought process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e650803",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "\n",
    "# Suppress verbose logging\n",
    "workflow_logger = logging.getLogger(\"course-qa-workflow\")\n",
    "original_level = workflow_logger.level\n",
    "workflow_logger.setLevel(logging.WARNING)\n",
    "\n",
    "# Query 1: Exact Match\n",
    "query1 = \"What are the prerequisites for CS013?\"\n",
    "print(f\"Query 1 (Exact Match): {query1}\\n\" + \"=\"*60)\n",
    "\n",
    "start1 = time.perf_counter()\n",
    "result1 = await app.ainvoke({\"input\": query1})\n",
    "\n",
    "\n",
    "# Query 2: Semantic Search\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "query2 = \"I want to learn about neural networks.\"\n",
    "print(f\"Query 2 (Semantic Search): {query2}\\n\" + \"=\"*60)\n",
    "\n",
    "start2 = time.perf_counter()\n",
    "result2 = await app.ainvoke({\"input\": query2})\n",
    "\n",
    "\n",
    "# Restore logging\n",
    "workflow_logger.setLevel(original_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9939de09",
   "metadata": {},
   "source": [
    "### Multi-Turn Conversations with \"Memory\"\n",
    "\n",
    "Now let's test something Stage 3 couldn't handle: multi-turn conversations with references to previous exchanges.\n",
    "\n",
    "We'll use a simple conversation history list that gets passed through the state. This isn't true memory (we'll implement this in the next stage), but it demonstrates how the ReAct agent can reason about conversational context.\n",
    "\n",
    "Watch how the agent handles queries like \"What about that course?\" by analyzing the conversation history to determine which course \"that\" refers to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87215ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML, Markdown\n",
    "\n",
    "# Suppress verbose logging\n",
    "workflow_logger = logging.getLogger(\"course-qa-workflow\")\n",
    "original_level = workflow_logger.level\n",
    "workflow_logger.setLevel(logging.WARNING)\n",
    "\n",
    "# Multi-turn conversation simulation\n",
    "display(HTML(\"<h3>üí¨ Multi-Turn Conversation Demo</h3>\"))\n",
    "\n",
    "# Initialize conversation history\n",
    "conversation_history = []\n",
    "\n",
    "# Turn 1: Initial query\n",
    "display(HTML(\"<div style='background:#e3f2fd; padding:10px; border-radius:8px; margin:8px 0;'><b>üë§ User:</b> Tell me about CS002</div>\"))\n",
    "result1 = await app.ainvoke({\"input\": \"Tell me about CS002\", \"history\": conversation_history})\n",
    "display(HTML(f\"<div style='background:#e8f5e9; padding:12px; border-left:4px solid #4CAF50; border-radius:4px; margin:8px 0;'><b>ü§ñ Agent:</b><br>{result1['final_response']}</div>\"))\n",
    "\n",
    "# Add to history\n",
    "conversation_history.append(f\"User: Tell me about CS002\")\n",
    "conversation_history.append(f\"Agent: {result1['final_response'][:200]}...\")\n",
    "\n",
    "# Turn 2: Follow-up with reference\n",
    "display(HTML(\"<hr style='border:none; border-top:1px dashed #ccc; margin:16px 0;'>\"))\n",
    "display(HTML(\"<div style='background:#e3f2fd; padding:10px; border-radius:8px; margin:8px 0;'><b>üë§ User:</b> What are the prerequisites for that course?</div>\"))\n",
    "result2 = await app.ainvoke({\n",
    "    \"input\": \"What are the prerequisites for that course?\", \n",
    "    \"history\": conversation_history\n",
    "})\n",
    "display(HTML(f\"<div style='background:#e8f5e9; padding:12px; border-left:4px solid #4CAF50; border-radius:4px; margin:8px 0;'><b>ü§ñ Agent:</b><br>{result2['final_response']}</div>\"))\n",
    "\n",
    "# Add to history\n",
    "conversation_history.append(f\"User: What are the prerequisites for that course?\")\n",
    "conversation_history.append(f\"Agent: {result2['final_response'][:200]}...\")\n",
    "\n",
    "# Turn 3: Another follow-up\n",
    "display(HTML(\"<hr style='border:none; border-top:1px dashed #ccc; margin:16px 0;'>\"))\n",
    "display(HTML(\"<div style='background:#e3f2fd; padding:10px; border-radius:8px; margin:8px 0;'><b>üë§ User:</b> What's the difficulty level?</div>\"))\n",
    "result3 = await app.ainvoke({\n",
    "    \"input\": \"What's the difficulty level?\", \n",
    "    \"history\": conversation_history\n",
    "})\n",
    "display(HTML(f\"<div style='background:#e8f5e9; padding:12px; border-left:4px solid #4CAF50; border-radius:4px; margin:8px 0;'><b>ü§ñ Agent:</b><br>{result3['final_response']}</div>\"))\n",
    "\n",
    "# Restore logging\n",
    "workflow_logger.setLevel(original_level)\n",
    "\n",
    "# Summary\n",
    "display(HTML(\"\"\"<div style='margin-top:16px; padding:12px; background:#fff3e0; border-radius:8px; border-left:4px solid #FF9800;'>\n",
    "<b>‚úÖ Multi-turn conversation complete!</b><br><br>\n",
    "<b>Key Observations:</b>\n",
    "<ul style='margin:8px 0 0 0;'>\n",
    "<li>The agent used conversation history to resolve \"that course\" to CS002</li>\n",
    "<li>The agent maintained context across multiple turns</li>\n",
    "<li>This is a simple history-based approach (Stage 5 adds semantic memory)</li>\n",
    "</ul>\n",
    "</div>\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d48d75a",
   "metadata": {},
   "source": [
    "## Wrap Up üèÅ\n",
    "\n",
    "Great job! You've completed Stage 4 and built a complete ReAct agent that represents a fundamental shift from pre-programmed pipelines to dynamic reasoning.\n",
    "\n",
    "In this stage, you learned how to:\n",
    "\n",
    "- Implement the hybrid search tool that combines semantic vector search with exact field filtering\n",
    "- Build the ReAct loop(Thought ‚Üí Action ‚Üí Observation) that enables agents to reason about their information needs\n",
    "- Construct a LangGraph workflow that orchestrates agent execution with state management\n",
    "\n",
    "The key transformation from stage 3 is moving from fixed intent paths to adaptive decision-making. Instead of pre-defining every possible query pattern, your agent reasons about each situation dynamically. This cognitive architecture is what enables ChatGPT, Claude, and production customer support systems to handle the infinite variety of real-world queries.\n",
    "\n",
    "In stages 5 and 6, you'll complete this foundation by adding true memory with Redis. Instead of passing conversation history as a simple list, you'll store and retrieve context from past interactions using Redis Agent Memory Server, enabling the agent to maintain coherent conversations across hundreds of messages and recall relevant information from long dialogue histories."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
