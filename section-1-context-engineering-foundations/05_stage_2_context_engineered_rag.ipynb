{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba3d772d",
   "metadata": {},
   "source": [
    "# Stage 2: The Context-Engineered RAG\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Welcome to the second stage of our Progressive Agents course. In Stage 1, we saw how a \"naive\" RAG agent suffered from Information Overload, wasting thousands of tokens and confusing the LLM with irrelevant data.\n",
    "\n",
    "In this stage, we will apply the Context Engineering techniques we learned in Section 2 to fix these problems.\n",
    "\n",
    "### Learning Objectives\n",
    "In this lesson, you will:\n",
    "1.  Implement Context Engineering: Apply cleaning, transformation, and optimization to your data.\n",
    "2.  Measure the Impact: See a dramatic reduction in token usage (aiming for ~90% reduction).\n",
    "3.  Understand the Trade-offs: Recognize that while we saved tokens, we lost some detail (like syllabi) by applying a \"flat\" strategy.\n",
    "\n",
    "### The Scenario\n",
    "We are still building the Course Advisor Agent.\n",
    "*   The Goal: Answer \"What ML courses are there?\"\n",
    "*   The Change: Instead of dumping raw JSON, we will carefully curate the text we send to the LLM.\n",
    "\n",
    "Let's see how much better we can do."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1816a20",
   "metadata": {},
   "source": [
    "# Setup and Initialization\n",
    "\n",
    "Let's set up our environment and import the Stage 2 agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffa9c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import asyncio\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 1. Configure Paths\n",
    "# We point to 'stage2_context_engineered' this time\n",
    "project_root = Path(\"../../\").resolve()\n",
    "stage2_path = project_root / \"progressive_agents\" / \"stage2_context_engineered\"\n",
    "sys.path.append(str(stage2_path))\n",
    "\n",
    "# Add src to path to import models\n",
    "src_path = project_root / \"src\"\n",
    "sys.path.append(str(src_path))\n",
    "\n",
    "# 2. Load Environment Variables\n",
    "load_dotenv(project_root / \".env\")\n",
    "\n",
    "print(f\"Project Root: {project_root}\")\n",
    "print(f\"Agent Path Added: {stage2_path}\")\n",
    "print(f\"Src Path Added: {src_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37ed621",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent import setup_agent\n",
    "\n",
    "print(\"Initializing Stage 2 Agent...\")\n",
    "# This reuses the same Redis data from Stage 1 (or generates it if missing)\n",
    "workflow, course_manager = setup_agent(auto_load_courses=True)\n",
    "print(\"Agent is ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0017225f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import agent.context_engineering\n",
    "\n",
    "# Inject our function into the agent's module\n",
    "agent.context_engineering.transform_course_to_text = transform_course_to_text\n",
    "\n",
    "print(\"Successfully injected your custom function into the agent!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41696340",
   "metadata": {},
   "source": [
    "## Step 2: Integrate with the Agent\n",
    "\n",
    "Now that we have our logic, let's inject it into the agent. We will \"monkeypatch\" the agent's module to use *our* function instead of the default one. This proves that your code is driving the agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62148423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_course_to_text(course: Course) -> str:\n",
    "    \"\"\"\n",
    "    Transform course object to LLM-optimized text format.\n",
    "    \"\"\"\n",
    "    # Build prerequisites text\n",
    "    prereq_text = \"\"\n",
    "    if course.prerequisites:\n",
    "        prereq_codes = [p.course_code for p in course.prerequisites]\n",
    "        prereq_text = f\"\\nPrerequisites: {', '.join(prereq_codes)}\"\n",
    "\n",
    "    # Build learning objectives text\n",
    "    objectives_text = \"\"\n",
    "    if course.learning_objectives:\n",
    "        objectives_text = f\"\\nLearning Objectives:\\n\" + \"\\n\".join(\n",
    "            f\"  - {obj}\" for obj in course.learning_objectives\n",
    "        )\n",
    "\n",
    "    # Build course text (CLEANED and TRANSFORMED)\n",
    "    course_text = f\"\"\"{course.course_code}: {course.title}\n",
    "Department: {course.department}\n",
    "Credits: {course.credits}\n",
    "Level: {course.difficulty_level.value}\n",
    "Format: {course.format.value}\n",
    "Instructor: {course.instructor}{prereq_text}\n",
    "Description: {course.description}{objectives_text}\"\"\"\n",
    "\n",
    "    return course_text\n",
    "\n",
    "# Test it!\n",
    "print(\"--- Engineered Context (Clean Text) ---\")\n",
    "print(transform_course_to_text(sample_course))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dd355e",
   "metadata": {},
   "source": [
    "### Exercise: Implement Transformation\n",
    "\n",
    "Now, write a function that converts this object into a clean, readable string.\n",
    "*   Include: Code, Title, Department, Credits, Instructor, Description.\n",
    "*   Exclude: ID, timestamps, enrollment numbers.\n",
    "*   Format: Key: Value (Natural Text)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3be2c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from redis_context_course.models import Course, DifficultyLevel, CourseFormat\n",
    "\n",
    "# Create a dummy course for testing\n",
    "sample_course = Course(\n",
    "    id=\"course_12345\",\n",
    "    course_code=\"CS101\",\n",
    "    title=\"Introduction to Computer Science\",\n",
    "    department=\"Computer Science\",\n",
    "    credits=4,\n",
    "    difficulty_level=DifficultyLevel.BEGINNER,\n",
    "    format=CourseFormat.IN_PERSON,\n",
    "    instructor=\"Dr. Alice Smith\",\n",
    "    description=\"A fundamental course covering the basics of programming and algorithms.\",\n",
    "    prerequisites=[],\n",
    "    learning_objectives=[\"Understand variables\", \"Write loops\"],\n",
    "    # Noise fields that we want to remove:\n",
    "    created_at=\"2023-01-01T00:00:00Z\",\n",
    "    updated_at=\"2023-06-01T00:00:00Z\",\n",
    "    enrollment_capacity=100,\n",
    "    current_enrollment=85\n",
    ")\n",
    "\n",
    "print(\"--- Raw Course Data (JSON) ---\")\n",
    "print(sample_course.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da428ba0",
   "metadata": {},
   "source": [
    "## Step 1: Define the Context Engineering Logic\n",
    "\n",
    "Before we run the agent, let's define the logic that will clean and transform our data.\n",
    "\n",
    "We will implement a function `transform_course_to_text` that takes a `Course` object and returns a clean string.\n",
    "\n",
    "First, let's look at what a \"Raw\" course looks like."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a642ca54",
   "metadata": {},
   "source": [
    "## The Experiment: \"What ML courses are available?\"\n",
    "\n",
    "We will run the **exact same query** as in Stage 1. This allows us to make a direct comparison.\n",
    "\n",
    "> *\"What machine learning courses are available?\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd35a055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the user's query\n",
    "query = \"What machine learning courses are available?\"\n",
    "\n",
    "print(f\"User asks: '{query}'\")\n",
    "print(\"Running workflow...\")\n",
    "\n",
    "# Run the graph\n",
    "result = await workflow.ainvoke({\"query\": query})\n",
    "\n",
    "print(\"Workflow complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b377df22",
   "metadata": {},
   "source": [
    "## Analysis: The Power of Context Engineering\n",
    "\n",
    "Let's look at the results. In Stage 1, this query cost us ~6,000 tokens. How did we do this time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4a5821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the Answer\n",
    "print(\"=\"*60)\n",
    "print(f\"Agent Answer:\\n\\n{result['final_answer']}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Display the Metrics\n",
    "courses_found = result.get('courses_found', 0)\n",
    "total_tokens = result.get('total_tokens', 0)\n",
    "\n",
    "print(f\"\\nStatistics:\")\n",
    "print(f\"   Courses Retrieved: {courses_found}\")\n",
    "print(f\"   Total Tokens Used: {total_tokens:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc773e5",
   "metadata": {},
   "source": [
    "### The Comparison\n",
    "\n",
    "| Metric | Stage 1 (Baseline) | Stage 2 (Engineered) | Improvement |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **Total Tokens** | ~6,100 | **~540** | **~91% Reduction** |\n",
    "| **Format** | Raw JSON | Clean Text | Better Readability |\n",
    "| **Noise** | High (Syllabi, IDs) | Low (Relevant info only) | Focused Context |\n",
    "\n",
    "We achieved a **91% reduction in token usage** simply by cleaning and formatting our data!\n",
    "\n",
    "### Inspecting the Engineered Context\n",
    "Let's see what the LLM actually saw this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d3c704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the engineered context\n",
    "engineered_context = result.get('engineered_context', '')\n",
    "\n",
    "print(f\"Total Context Size: {len(engineered_context):,} characters\")\n",
    "print(\"-\" * 40)\n",
    "print(\"PREVIEW OF ENGINEERED CONTEXT\")\n",
    "print(\"-\" * 40)\n",
    "print(engineered_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db7feaf",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Context Engineering is a powerful tool for optimization. By curating our data, we saved money and improved speed.\n",
    "\n",
    "Key Takeaways:\n",
    "1. Clean your data: Remove database artifacts.\n",
    "2. Transform your data: Use formats that are token-efficient.\n",
    "3. Optimize for the task: Summaries are great for search, but maybe not for deep dives.\n",
    "\n",
    "### Next Lesson: Hierarchical Retrieval\n",
    "In **Stage 3**, we will solve the \"Flat Retrieval\" problem. We will build a \"Smart\" agent that:\n",
    "1. Retrieves summaries first (like Stage 2).\n",
    "2. Decides which course is most relevant.\n",
    "3. Fetches the **full syllabus** for *only* that course.\n",
    "\n",
    "This gives us the best of both worlds: Low token usage *and* high detail when needed.\n",
    "\n",
    "See you in Stage 3!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
