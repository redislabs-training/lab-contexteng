{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Redis](https://redis.io/wp-content/uploads/2024/04/Logotype.svg?auto=webp&quality=85,75&width=120)\n",
    "\n",
    "\n",
    "# Introduction\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/redislabs-training/ce-redis-langchain/blob/main/section-1-context-engineering-foundations/01_Introduction_to_context_engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "Over the past few years, AI applications have undergone rapid evolution. Early on, engineers built a polite clerk behind a glass window: users would slide a note - \"draft this email,\" \"explain this code\" — and the clerk would read it, scribble an answer, and slide it back. Their answers were generally good, but not always what we wanted. \n",
    "\n",
    "Users quickly realized that if they *precisely* engineer what the note says, they can, in turn, achieve better results from the clerk. So, they used more precise instructions — \"act as my editor,\" \"use this tone,\" \"return a table\" — and the outputs became sharper. This, in turn, became the practice of prompt engineering. \n",
    "\n",
    "Prompt engineering took users further, but eventually showed its limits — especially with our clerk behind the glass. We kept hoping the wording would stick, but longer notes got slow and contradictory. Tiny phrasing swings changed behavior in ways that were hard to predict or control, and no amount of wordsmithing seemed to fully fix it.\n",
    "\n",
    "For a while, if you were building with these systems, the playbook for solving these issues was simple: upgrade the model. Swap in the latest version and your clerk gets sharper responses, a better grasp of nuance, and enough capability to attempt specialized tasks like research or creative exploration.\n",
    "\n",
    "This did help! The clerk began to catch more nuances in the notes that were passed. It could juggle longer instructions, synthesize more information, and make fewer obvious mistakes. For many teams, it felt like the main knob to turn was simply: use a bigger, smarter model.\n",
    "\n",
    "But under the hood, the old cracks were still there. The clerk was still working mostly from whatever happened to be on the note in front of them. They still forgot everything between one visit and the next. When they didn’t know something, they still guessed instead of checking. In other words, we’d upgraded the clerk, but not the glass, not the office, and not the way work flowed around them.\n",
    "\n",
    "Then came agents.\n",
    "\n",
    "Instead of a clerk answering one note at a time, we started asking that same clerk to run tasks, such as breaking down a goal, fetching information from the internet, and reading and updating complex code. Our polite assistant became a kind of project manager.\n",
    "\n",
    "In our metaphor, it was as if we took the clerk from behind the glass and said: \"Feel free to walk the halls. Use the phone, dig through the filing cabinets, talk to other departments, and come back with a finished result.\"\n",
    "\n",
    "This unlocked striking capabilities — but it also made the old problems impossible to ignore. Small ambiguities in instructions ballooned over ten or twenty steps. Missing background information meant the clerk confidently walked in the wrong direction for minutes at a time. Every task and its associated subtasks came with its own little note — its own tiny prompt — and suddenly the clerk wasn't wrestling with one interaction, but with a swarm of them, all slightly inconsistent.\n",
    "\n",
    "So, what do these issues look like if we were to crack open one of these agentic applications? Where do \"missing background,\" \"forgotten preferences,\" and that \"swarm of tiny prompts\" actually live?\n",
    "\n",
    "In practice, they all appear as distinct components of context surrounding a model call: the state and history you carry forward, the prompts and policies you apply, the memories you load, the documents you retrieve, and the structured outputs you expect to receive back. Visually, it looks something like this:\n",
    "\n",
    "![Context engineering overview](../public/ce-overview.png)\n",
    "\n",
    "Things like user input, operational databases, web APIs, and data warehouses all feed into the application’s context layer. Everything inside that dashed red circle is what we, as engineers, design and control before a single token ever reaches the LLM model. Instead of only asking, \"What’s the right prompt?\" or \"What’s the right model?\", we are now shifting to ask, “What information should be present at every step of this process, and how do we control it?”\n",
    "\n",
    "That shift — from crafting individual notes to deliberately shaping the information surrounding the application — is what has become known as context engineering.\n",
    "\n",
    "Let's now ground this idea in an example application for a Redis University course agent and watch where context engineering makes the difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context Engineering in Action\n",
    "\n",
    "We can imagine, that at most universities today, one of the biggest pain points for learners is the time-suck of researching and selecting their academic classes for the year. In most cases, this involves a tedious process of waiting for their registration time slot to open (as often more senior students have priority), scrolling various pages of courses/descriptions, finding if they meet the prerequisites, and so on. There are even dedicated roles designed to help students decide on what classes are the right fit and assist them with their planning. \n",
    "\n",
    "As an engineer part of the Redis University Innovation Team, our hope is to solve this issue by creating a seamless interface whereby a agent can help expedite the research and selection process of a student's courses. \n",
    "\n",
    "Let's now imagine we did indeed build this agent and are running a pilot of the results with a subset of students. Lets examine a common scenario we want the agent to deal with: A student seeking advice on what classes to take to help build a career in AI. \n",
    "\n",
    "We'll use a sample student profile as our base: \n",
    "\n",
    "- Name: Olivia Jansen\n",
    "- Major: Computer Science\n",
    "- Year: Sophomore\n",
    "- Completed: Intro to Programming (CS101), Data Structures (CS201), Calculus I\n",
    "- Interests: Machine learning, Data science\n",
    "- Preferences: Prefers online courses, learns best with hands-on projects\n",
    "- Goal: Build a career in AI\n",
    "\n",
    "Olivia goes ahead and interacts with the agent and has the following results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>Click the dropdown to review the conversation with the agent</summary>\n",
    "  \n",
    "**Turn 1:**\n",
    "\n",
    "*Student:* \"I'm interested in machine learning courses\"\n",
    "\n",
    "*Agent:* \"Here are all machine learning courses available:\n",
    "- CS301: Introduction to Machine Learning\n",
    "- CS401: Advanced Machine Learning\n",
    "- CS402: Deep Learning\n",
    "- CS403: Natural Language Processing\n",
    "- CS404: Computer Vision\n",
    "\n",
    "All courses meet twice per week on campus.\"\n",
    "\n",
    "---\n",
    "\n",
    "**Turn 2:**\n",
    "\n",
    "*Student:* \"I prefer online courses.\"\n",
    "\n",
    "*Agent:* \"Here are all machine learning courses available:\n",
    "- CS301: Introduction to Machine Learning\n",
    "- CS401: Advanced Machine Learning\n",
    "...\"\n",
    "\n",
    "Notice that the result is the same list, ignoring Olivia's preferences.\n",
    "\n",
    "---\n",
    "\n",
    "**Turn 3:**\n",
    "\n",
    "*Student:* \"Can I take CS401?\"\n",
    "\n",
    "*Agent:* \"CS401 requires CS301 as a prerequisite. Do you meet this requirement?\"\n",
    "\n",
    "The agent does not respond adequately as it doesn't know what courses the student has completed\n",
    "\n",
    "---\n",
    "\n",
    "**Turn 4:**\n",
    "\n",
    "*Student:* \"What about that intro course you mentioned earlier?\"\n",
    "\n",
    "*Agent:* \"I'm not sure which course you're referring to. Could you provide more details?\"\n",
    "\n",
    "The agent does not remember its old replies and has no context on what intro course was mentioned. \n",
    "\n",
    "---\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This advisor is intentionally simple, but its failure modes mirror those of real systems: it has no memory (can’t recall prior turns), no personalization (ignores her preferences and background), and no awareness (doesn’t know her history, can’t check prerequisites, and cannot connect relevant information). The result is a frustrating experience that wastes time and delivers little value to the student.\n",
    "\n",
    "We don't want to leave our students feeling disappointed, so we spend some time applying some common context engineering techniques to our agent to improve the results. Now, let's examine the agent, but with proper context management: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary> Click the dropdown to review the conversation with the agent with proper context management </summary>\n",
    "\n",
    "**Turn 1:**\n",
    "\n",
    "*Student:* \"I'm interested in machine learning courses.\"\n",
    "\n",
    "*Agent:* \"Great! Based on your Computer Science major and the courses you've completed (CS101 and CS201), you're ready for CS301: Introduction to Machine Learning.\n",
    "\n",
    "Since you prefer online courses and hands-on learning, I should mention that CS301 has:\n",
    "- A fully online section is available\n",
    "- Weekly programming assignments with real datasets\n",
    "- A final project where you build your own ML system\n",
    "\n",
    "This course aligns perfectly with your goal of building an AI career and serves as the foundation for more advanced ML courses.\"\n",
    "\n",
    "---\n",
    "\n",
    "**Turn 2:**\n",
    "\n",
    "*Student:* \"That sounds perfect! What comes after that?\"\n",
    "\n",
    "*Agent:* \"After completing CS301, you'll have several great options:\n",
    "\n",
    "**Immediately Available:**\n",
    "- CS402: Deep Learning (Online, project-based)\n",
    "  Focus: Neural networks, CNNs, RNNs\n",
    "  \n",
    "- CS403: Natural Language Processing (Online, project-based)\n",
    "  Focus: Text analysis, transformers, LLMs\n",
    "\n",
    "**Recommended Path for AI Career:**\n",
    "1. CS301 (Introduction) ← Start here\n",
    "2. CS402 (Deep Learning) ← Most relevant to modern AI\n",
    "3. CS403 (NLP) or CS404 (Computer Vision) ← Specialize\n",
    "\n",
    "Given your interest in data science, I'd especially recommend the NLP path - it combines well with your data structures background.\"\n",
    "\n",
    "---\n",
    "\n",
    "**Turn 3:**\n",
    "\n",
    "*Student:* \"How long will that path take?\"\n",
    "\n",
    "*Agent:* \"Let me break it down for you:\n",
    "\n",
    "**CS301:** 14 weeks (3 credits)\n",
    "**CS402:** 14 weeks (3 credits)  \n",
    "**CS403:** 14 weeks (3 credits)\n",
    "\n",
    "If you take one course per semester:\n",
    "- Fall 2024: CS301\n",
    "- Spring 2025: CS402\n",
    "- Fall 2025: CS403\n",
    "\n",
    "Since you're currently a Junior, this timeline would have you completing this sequence before graduation, with one semester remaining for an internship or capstone project.\n",
    "\n",
    "Alternatively, since these are online courses, you could potentially take CS301 this fall and CS402 in a winter intersession to accelerate your path.\"\n",
    "\n",
    "---\n",
    "\n",
    "**Turn 4:**\n",
    "\n",
    "*Student:* \"I like that accelerated option. Can I register now?\"\n",
    "\n",
    "*Agent:* \"Yes! Since you've met the prerequisites for CS301, I can guide you through registration. The online section (CS301-W01) has 15 seats remaining.\n",
    "\n",
    "Would you like me to:\n",
    "1. Reserve a seat for you in CS301-W01 for Fall 2024?\n",
    "2. Add you to the notification list for the Winter CS402 section (registration opens in October)?\n",
    "3. Send you the course syllabus and professor information?\"\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference in this interaction is stark compared to the previous. With proper context engineering, the advisor carries the context instead of the student: it remembers who Olivia is (major, completions, preferences), filters to relevant options (online, project-based ML), checks prerequisites automatically, turns choices into a sequenced plan and timeline, and can even propose recommended actions (register, notify, send syllabi). The result is a fast, personalized, high-confidence experience that actually delivers value.\n",
    "\n",
    "So, while in our example, we waved a magic wand and the agent was suddenly more effective, what actually goes into making this improvement happen? To grasp the techniques used, we must first explore the types of contexts that an AI system manages. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a complete context: the four pillars\n",
    "\n",
    "We can breakdown the context that goes into an AI application into four distinct types: \n",
    "\n",
    "1. System context\n",
    "2. User context\n",
    "3. Conversation context\n",
    "4. Retrieved context \n",
    "\n",
    "Each of these types plays a crucial role in making sure that an AI system has what it needs to properly respond. In this section, we'll explore each context type in more detail and setup a sample context to call a LLM. As you go through, make sure to run each code block that is provided as we build up the context and send it to a LLM at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. System Context: \"What Am I?\"\n",
    "\n",
    "The system context defines the AI's identity, capabilities, and knowledge. It is static, universal, and always present.\n",
    "\n",
    "It typically contains: \n",
    "- A role definition (\"You are a course advisor\")\n",
    "- Available tools and actions (`search_courses(query)`)\n",
    "- Domain knowledge and business rules (\"CS401 requires CS301\")\n",
    "- Behavioral guidelines (\"Ask one clarifying question at a time\")\n",
    "\n",
    "An example of system context (also commonly called the system prompt) for our Redis University agent, might look like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_context = \"\"\"You are a Redis University course advisor.\n",
    "\n",
    "Guidelines:\n",
    "1. Always provide specific course recommendations with clear reasoning\n",
    "2. Consider the student's background, completed courses, and interests\n",
    "3. Ensure prerequisites are met before recommending advanced courses\n",
    "4. Be encouraging and supportive in your guidance\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. User Context: \"Who Are You?\"\n",
    "\n",
    "The user context contains personal information about the specific user. It is typically dynamic, personalized, and retrieved from storage. \n",
    "\n",
    "It typically contains: \n",
    "- Profile information (major, year, background)\n",
    "- Preferences and learning style (\"prefers online/asynchronous\")\n",
    "- History and achievements (\"completed CS101/CS201/Calc I\")\n",
    "- Goals and constraints (\"Tue/Thu availability\")\n",
    "\n",
    "We have already seen an example of user context when we defined the user profile and preferences for Olivia: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create a user profile as a dictionary\n",
    "# Note: In production, this would come from a database, here, we hardcode it for demonstration purposes\n",
    "\n",
    "olivia_profile = {\n",
    "    \"name\": \"Olivia Jansen\",\n",
    "    \"background\": \"Python developer, 2 years experience\",\n",
    "    \"completed_courses\": [\"RU101\"],\n",
    "    \"interests\": [\"machine learning\", \"data science\", \"vector search\"],\n",
    "    \"time_availability\": \"evenings and weekends\",\n",
    "    \"goal\": \"Build a RAG system for my company's documentation\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: In production, the above, would likely from a database, but we have hardcoded it above for demonstration purposes. Additionally, we would likely write a function to construct this profile for our context. Something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_user_context(profile):\n",
    "    \"\"\"Convert user profile dictionary to formatted context string\"\"\"\n",
    "    return f\"\"\"Student Profile:\n",
    "- Name: {profile['name']}\n",
    "- Background: {profile['background']}\n",
    "- Completed Courses: {', '.join(profile['completed_courses'])}\n",
    "- Interests: {', '.join(profile['interests'])}\n",
    "- Availability: {profile['time_availability']}\n",
    "- Goal: {profile['goal']}\n",
    "\"\"\"\n",
    "\n",
    "user_context = format_user_context(olivia_profile)\n",
    "print(user_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Conversation Context: \"What Have We Discussed?\"\n",
    "\n",
    "Conversation context is one of the most important parts of context since it represents the history of the current conversation. Typically this is implemented in the form of short-term memory. It is dynamic, session-specific, and will grow over time. \n",
    "\n",
    "It typically contains: \n",
    "- Previous user messages\n",
    "- Previous AI responses\n",
    "- Decisions and commitments made\n",
    "- Topics explored\n",
    "\n",
    "We have also seen an example of conversation context earlier:\n",
    "```\n",
    "Turn 1:\n",
    "User: \"I'm interested in machine learning courses.\"\n",
    "AI: \"I recommend CS301: Introduction to Machine Learning...\"\n",
    "\n",
    "Turn 2:\n",
    "User: \"What comes after that course?\"\n",
    "[Current query - needs context from Turn 1 to understand \"that course\"]\n",
    "AI: \"After CS301, you can take CS402 or CS403...\"\n",
    "\n",
    "Turn 3:\n",
    "User: \"How long will that path take?\"\n",
    "[Current query - needs context from Turn 2 to understand \"that path\"]\n",
    "```\n",
    "\n",
    "Let's examine a simple implementation of conversation context: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Start with an empty conversation history\n",
    "conversation_history = []\n",
    "\n",
    "# Step 2: Add the first user message\n",
    "conversation_history.append(\n",
    "    {\"role\": \"user\", \"content\": \"What Redis course should I take next?\"}\n",
    ")\n",
    "\n",
    "# Step 3: Add the AI's response (simulated)\n",
    "conversation_history.append(\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"\"\"Based on your Python background and completion of RU101, \n",
    "I recommend RU201: Redis for Python Developers. This course will teach you \n",
    "how to build Redis applications using redis-py, which aligns perfectly with \n",
    "your goal of building a RAG system.\"\"\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Step 4: Add a follow-up question that references previous context\n",
    "conversation_history.append(\n",
    "    {\"role\": \"user\", \"content\": \"How long will that take me to complete?\"}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the user said \"that\" instead of \"RU201\". The AI needs the conversation history to understand what \"that\" refers to. Let's view the complete conversation history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, msg in enumerate(conversation_history, 1):\n",
    "    print(f\"Turn {i} ({msg['role']}):\")\n",
    "    print(f\"{msg['content']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Retrieved Context: \"What Information Is Relevant?\"\n",
    "\n",
    "Lastly, there is retrieved context. This is information fetched on-demand based on the current query. This involves the system retrieving specific and relevant context across other systems. It is dynamic and highly targeted. \n",
    "\n",
    "It typically contains: \n",
    "- Database records (course details, schedules)\n",
    "- Search results (relevant documents, FAQs)\n",
    "- API responses (real-time data, availability)\n",
    "- Computed information (eligibility checks, recommendations)\n",
    "\n",
    "For example, if a student asked the Redis University agent about \"CS301\", the system would need to find any relevant context to respond to the query. For instance, it would call a course catalog database, find the CS301 course and retrieve information like course details (description, prerequisites, format), current availability (X seats in online section), and professor ratings and reviews.\n",
    "\n",
    "Let's simulate what retrieved context will look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Simulate a course database\n",
    "# In production, this would be Redis, etc.\n",
    "course_database = {\n",
    "    \"RU101\": {\n",
    "        \"title\": \"Introduction to Redis Data Structures\",\n",
    "        \"level\": \"Beginner\",\n",
    "        \"description\": \"Master Redis fundamentals: strings, hashes, lists, sets, and sorted sets\",\n",
    "        \"duration\": \"4-6 hours\",\n",
    "        \"prerequisites\": [],\n",
    "        \"topics\": [\"Data structures\", \"Basic commands\", \"Use cases\"],\n",
    "    },\n",
    "    \"RU201\": {\n",
    "        \"title\": \"Redis for Python Developers\",\n",
    "        \"level\": \"Intermediate\",\n",
    "        \"description\": \"Build production Redis applications with Python and redis-py\",\n",
    "        \"duration\": \"6-8 hours\",\n",
    "        \"prerequisites\": [\"RU101\", \"Python experience\"],\n",
    "        \"topics\": [\"redis-py library\", \"Connection pooling\", \"Pipelining\", \"Pub/Sub\"],\n",
    "    },\n",
    "    \"RU202\": {\n",
    "        \"title\": \"Redis for Java Developers\",\n",
    "        \"level\": \"Intermediate\",\n",
    "        \"description\": \"Build production Redis applications with Java and Jedis\",\n",
    "        \"duration\": \"6-8 hours\",\n",
    "        \"prerequisites\": [\"RU101\", \"Java experience\"],\n",
    "        \"topics\": [\n",
    "            \"Jedis library\",\n",
    "            \"Connection pooling\",\n",
    "            \"Transactions\",\n",
    "            \"Redis Streams\",\n",
    "        ],\n",
    "    },\n",
    "    \"RU301\": {\n",
    "        \"title\": \"Vector Similarity Search with Redis\",\n",
    "        \"level\": \"Advanced\",\n",
    "        \"description\": \"Implement semantic search and RAG systems with Redis vector capabilities\",\n",
    "        \"duration\": \"8-10 hours\",\n",
    "        \"prerequisites\": [\"RU201 or RU202\", \"ML/AI interest\"],\n",
    "        \"topics\": [\n",
    "            \"Vector embeddings\",\n",
    "            \"Semantic search\",\n",
    "            \"RAG architecture\",\n",
    "            \"Hybrid search\",\n",
    "        ],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's simulate retrieving course information based on a query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create a retrieval function\n",
    "\n",
    "def retrieve_course_info(course_code):\n",
    "    \"\"\"Retrieve detailed information about a specific course\"\"\"\n",
    "    course = course_database.get(course_code)\n",
    "    if not course:\n",
    "        return None\n",
    "\n",
    "    return f\"\"\"Course Details:\n",
    "        Code: {course_code}\n",
    "        Title: {course['title']}\n",
    "        Level: {course['level']}\n",
    "        Description: {course['description']}\n",
    "        Duration: {course['duration']}\n",
    "        Prerequisites: {', '.join(course['prerequisites']) if course['prerequisites'] else 'None'}\n",
    "        Topics Covered: {', '.join(course['topics'])}\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "# Retrieve information about RU201\n",
    "retrieved_context = retrieve_course_info(\"RU201\")\n",
    "print(retrieved_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bringing It All Together: Complete Context Integration\n",
    "\n",
    "Now that we understand each context type individually, let's see how they work together to create an intelligent, personalized response.\n",
    "\n",
    "Here's how all four context types combine in a single LLM call:\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────┐\n",
    "│           COMPLETE LLM REQUEST              │\n",
    "├─────────────────────────────────────────────┤\n",
    "│ 1. SYSTEM CONTEXT (Static)                  │\n",
    "│    - Role: \"You are a course advisor\"       │\n",
    "│    - Domain: Available courses              │\n",
    "│    - Rules: Guidelines and constraints      │\n",
    "├─────────────────────────────────────────────┤\n",
    "│ 2. USER CONTEXT (Dynamic - User Specific)   │\n",
    "│    - Profile: Sarah Chen, Python dev        │\n",
    "│    - History: Completed RU101               │\n",
    "│    - Goal: Build RAG system                 │\n",
    "├─────────────────────────────────────────────┤\n",
    "│ 3. CONVERSATION CONTEXT (Dynamic - Session) │\n",
    "│    - User: \"What course should I take?\"     │\n",
    "│    - AI: \"I recommend RU201...\"             │\n",
    "│    - User: \"How long will that take?\"       │\n",
    "├─────────────────────────────────────────────┤\n",
    "│ 4. RETRIEVED CONTEXT (Dynamic - Query)      │\n",
    "│    - RU201 course details                   │\n",
    "│    - Duration, prerequisites, topics        │\n",
    "├─────────────────────────────────────────────┤\n",
    "│ RESULT: Personalized, context-aware answer  │\n",
    "└─────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "Let's add them together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Start with system context\n",
    "messages = [{\"role\": \"system\", \"content\": system_context}]\n",
    "\n",
    "# Step 2: Add user context\n",
    "messages.append({\"role\": \"system\", \"content\": user_context})\n",
    "\n",
    "# Step 3: Add conversation history\n",
    "messages.extend(conversation_history)\n",
    "\n",
    "# Step 4: Add retrieved context\n",
    "messages.append({\"role\": \"system\", \"content\": retrieved_context})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, we can use the context to call the LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Make the LLM call with complete context\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\", messages=messages, temperature=0.7\n",
    ")\n",
    "\n",
    "answer = response.choices[0].message.content\n",
    "print(\"AI Response:\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LLM received all four context types and used them to generate a personalized response:\n",
    "\n",
    "1. **System Context** told it to act as a course advisor and provided course information\n",
    "2. **User Context** gave it Sarah's background, interests, and goals\n",
    "3. **Conversation Context** showed that \"that\" refers to RU201\n",
    "4. **Retrieved Context** provided detailed information about RU201's duration and topics\n",
    "\n",
    "The result is a response that:\n",
    "- Understands what course \"that\" refers to\n",
    "- Considers Sarah's available time (evenings and weekends)\n",
    "- Relates the duration to her specific situation\n",
    "- Stays aligned with her goal of building a RAG system\n",
    "\n",
    "When building complex AI systems, you'll be working with all four of these context types and will have to find ways to engineer them to make the system more effective. \n",
    "That said, every model has one the bottleneck never moves: what fits in the model’s context window."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Fundamental Challenge: Context Windows\n",
    "\n",
    "Even the most powerful AI models can only process a fixed amount of text in a single request. This is called the **context window**, which is essentially the size of our anecdotal clerk's desk. Here are the context window sizes of some of the most popular models available:\n",
    "\n",
    "| Model | Context Window |\n",
    "|-------|----------------|\n",
    "| GPT-4o | 128,000 tokens (~96,000 words) |\n",
    "| GPT-4o-mini | 128,000 tokens (~96,000 words) |\n",
    "| Claude 3.5 Sonnet | 200,000 tokens (~150,000 words) |\n",
    "\n",
    "This limit might look generous, but when we break it down, we have a ton of different context competing for space. Here is an example context budget breakdown for a single turn using a modeL:\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────┐\n",
    "│   CONTEXT WINDOW - 128K tokens      │\n",
    "├─────────────────────────────────────┤\n",
    "│ System Context    │ 2,000 tokens    │  ← AI's role and rules\n",
    "│ User Context      │ 1,000 tokens    │  ← Your profile\n",
    "│ Conversation      │ 4,000 tokens    │  ← What we've discussed\n",
    "│ Retrieved Info    │ 5,000 tokens    │  ← Relevant data\n",
    "│ Your Query        │ 100 tokens      │  ← Current question\n",
    "│ Response Space    │ 4,000 tokens    │  ← AI's answer\n",
    "├─────────────────────────────────────┤\n",
    "│ TOTAL TOKENS      │ 16,100 tokens   │\n",
    "│ REMAINING TOKENS  │ 111,900 tokens  │\n",
    "└─────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "That remaining space (111,900) might look comforting but remember this is just one turn. Our inputs will likely only grow longer (especially around conversation history), and as they do models have a harder time producing effective results. In fact [Chroma](https://www.trychroma.com/) revealed a critical challenge in working with LLMs: [context rot](https://research.trychroma.com/context-rot) - the phenomenon where LLM performance degrades non-uniformly as input context length increases, even on simple tasks.\n",
    "\n",
    "If we summarized the research findings around the size of context in a AI system, it would break out into the following: \n",
    "\n",
    "1. Longer context ≠ better context: Reliability drops and accelerates as inputs grow. This means we should treat the window like working memory; budget tokens when possible and keep the slice small.\n",
    "\n",
    "2. Relevance rules: High semantic match drives accuracy; loosely related text hurts. We should prioritize optimizing retrieval precision (rerank, tighten filters, rewrite queries).\n",
    "\n",
    "3. Distractors are toxic: Similar but wrong snippets do disproportionate damage as length increases. To reduce distractors, we should aggressively filter/threshold, dedupe, and avoid “just in case” context.\n",
    "\n",
    "4. Placement & structure matter: Models attend unevenly across the window; key facts can be missed when buried. We should surface essentials early, chunk clearly, and summarize instead of pasting raw dumps. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Remember, every token spent on one thing is a token NOT available for another. This means you must constantly decide:\n",
    "\n",
    "- Which context is most relevant?\n",
    "- What can be omitted without hurting quality?\n",
    "- When to retrieve more vs. use what you have?\n",
    "- How to compress long conversations?\n",
    "\n",
    "This makes context engineering a practice of optimization within constraints. As conversations grow longer, systems accumulate more data, and applications become more sophisticated, context management becomes increasingly critical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Challenges\n",
    "\n",
    "While managing the size of your context window is critical, simply fitting everything in isn't the only hurdle. As D. Breunig highlights in [How Contexts Fail (and How to Fix Them)](https://www.dbreunig.com/2025/06/22/how-contexts-fail-and-how-to-fix-them.html), there are several other ways that context can degrade the performance of your agent, even when you are well within the token limits.\n",
    "\n",
    "He mentions four key failure modes to watch out for:\n",
    "\n",
    "1.  **Context Poisoning**: This occurs when an error or hallucination makes its way into your context (e.g., conversation history) and is then treated as fact in subsequent turns. The model \"learns\" the wrong information from its own previous output, leading to a loop of compounding errors.\n",
    "\n",
    "2.  **Context Distraction**: Sometimes, having *too much* history can be detrimental. If an agent has a massive log of past actions, it may start to over-focus on repeating those past behaviors rather than reasoning about the current, novel situation. It relies on its \"contextual habit\" instead of its training.\n",
    "\n",
    "3.  **Context Confusion**: This happens when the context is cluttered with superfluous information—such as too many available tools or irrelevant document snippets. Even if the model *could* ignore them, the mere presence of these \"distractors\" increases the probability of the model getting confused or trying to use a tool that isn't needed.\n",
    "\n",
    "4.  **Context Clash**: This is when different parts of your context contradict each other. For example, your system prompt might say one thing, but a retrieved document or an early turn in the conversation history says the opposite. When the model faces this internal conflict, its reasoning capabilities often degrade significantly.\n",
    "\n",
    "Understanding these failure modes reinforces why context engineering is not just about *compression*—it's about *curation*. We must actively manage, clean, and sometimes even \"forget\" context to keep our agents sharp.\n",
    "\n",
    "In this course, we will not solve every one of these failure modes. Some, like context poisoning, remain as complex open research problems in AI. However, we will systematically dismantle the most common ones by building a series of \"progressive agents,\" each designed to overcome specific context limitations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
